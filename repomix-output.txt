This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: R/**/*.R, R/**/*.r, *.Rmd, *.rmd, DESCRIPTION, tests/**/*.R, tests/**/*.r
- Files matching patterns in .gitignore are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
R/
  deconv.R
  mppi_adv_methods.R
  mppi_axes.R
  mppi_band.R
  mppi_basis.R
  mppi_beta.R
  mppi_decompose.R
  mppi_deconv_dct.R
  mppi_design_interface.R
  mppi_fit_whitened.R
  mppi_fit.R
  mppi_fuse.R
  mppi_group_ebayes.R
  mppi_helpers.R
  mppi_hrf_adapt.R
  mppi_inference.R
  mppi_lag.R
  mppi_neural.R
  mppi_partial.R
  mppi_rank_cv.R
  mppi_rest.R
  mppi_s3.R
  mppi_scale.R
  mppi_sim_rest.R
  mppi_utils.R
  mppi_viz.R
  RcppExports.R
  zzz.R
tests/
  testthat/
    test_adv_methods.R
    test_algorithms.R
    test_band_beta_hrf.R
    test_band_partial.R
    test_basis.R
    test_beta_lag.R
    test_core.R
    test_design_interface.R
    test_gap_fill.R
    test_group_glm.R
    test_group.R
    test_helpers.R
    test_hrf.R
    test_mechanistic.R
    test_neural.R
    test_permutation.R
    test_rest_misc.R
    test_rest_sim.R
    test_rest.R
    test_scale_axes.R
    test_sim_multippi.R
    test_utils_extra.R
DESCRIPTION
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="R/deconv.R">
#' @keywords internal
.mppi_default_spm <- function(TR, L = 32) {
  t <- seq(0, L, by = TR)
  a1 <- 6; a2 <- 16; b1 <- 1; b2 <- 1; c <- 1 / 6
  h <- (t^(a1 - 1) * exp(-t / b1) / (b1^a1 * gamma(a1))) -
       c * (t^(a2 - 1) * exp(-t / b2) / (b2^a2 * gamma(a2)))
  as.numeric(h)
}

#' @keywords internal
.mppi_hrf_to_vec <- function(hrf_obj, TR) {
  if (is.null(hrf_obj)) return(.mppi_default_spm(TR))
  if (is.numeric(hrf_obj)) return(as.numeric(hrf_obj))
  if (is.function(hrf_obj)) {
    h <- try(hrf_obj(TR = TR), silent = TRUE)
    if (!inherits(h, "try-error") && is.numeric(h)) return(as.numeric(h))
  }
  if (requireNamespace("fmrihrf", quietly = TRUE)) {
    out <- try(fmrihrf::spm_hrf(TR), silent = TRUE)
    if (!inherits(out, "try-error")) return(as.numeric(out))
  }
  .mppi_default_spm(TR)
}

#' MAP/Tikhonov deconvolution in neural domain
#'
#' @param Y Numeric matrix (time x series)
#' @param TR Repetition time in seconds
#' @param hrf Optional haemodynamic response specification (numeric, function, or NULL)
#' @param lambda Tikhonov weight (default 10)
#' @return Time x series matrix of neural-domain estimates
#' @export
mppi_deconv <- function(Y, TR, hrf = NULL, lambda = 10) {
  if (!is.matrix(Y)) stop("mppi_deconv: Y must be a matrix.", call. = FALSE)
  if (!is.numeric(TR) || length(TR) != 1L || !is.finite(TR) || TR <= 0) {
    stop("mppi_deconv: TR must be a positive scalar.", call. = FALSE)
  }
  h <- .mppi_hrf_to_vec(hrf, TR)
  h <- h[h != 0]
  if (!length(h)) stop("mppi_deconv: HRF vector is empty after removing zeros.", call. = FALSE)
  if (length(h) > nrow(Y)) h <- h[seq_len(nrow(Y))]
  mppi_deconv_map(Y, h = h, lambda = lambda)
}
</file>

<file path="R/mppi_adv_methods.R">
# Advanced mechanistic helpers ------------------------------------------------

#' Protected-band innovations (iPPI companion)
#'
#' @param U matrix of neural/basis time-series (T x r)
#' @param TR repetition time in seconds (needed for protect = "lowHz")
#' @param protect slow-band strategy: "none", "lowK", or "lowHz"
#' @param K_keep number of DCT components to retain when protect = "lowK"
#' @param f_cut low-frequency cutoff in Hz when protect = "lowHz"
#' @param ar_order "auto" (AIC) or "fixed"
#' @param p maximum AR order when ar_order = "auto" or fixed order otherwise
#' @param center logical; center columns before whitening
#' @return matrix of innovations with attributes `orders` and `phis`
#' @export
mppi_innovations <- function(U, TR = NULL,
                             protect = c("none", "lowK", "lowHz"),
                             K_keep = 8L, f_cut = 0.03,
                             ar_order = c("auto", "fixed"), p = 4L,
                             center = TRUE) {
  stopifnot(is.matrix(U))
  protect <- match.arg(protect)
  ar_order <- match.arg(ar_order)
  Tn <- nrow(U); r <- ncol(U)
  if (center) U <- scale(U, center = TRUE, scale = FALSE)
  if (protect == "lowK") {
    U_low <- .mppi_adv_project_lowK(U, K_keep)
    U_high <- U - U_low
  } else if (protect == "lowHz") {
    if (is.null(TR)) stop("TR required for protect='lowHz'.")
    U_low <- .mppi_adv_bandlimit(U, TR, f_cut, which = "low")
    U_high <- U - U_low
  } else {
    U_low <- 0 * U
    U_high <- U
  }
  E_high <- matrix(0, Tn, r)
  orders <- integer(r)
  phis <- vector("list", r)
  for (j in seq_len(r)) {
    x <- U_high[, j]
    if (ar_order == "auto") {
      fit <- try(stats::ar(x, aic = TRUE, order.max = max(1L, p), method = "yw"), silent = TRUE)
      if (inherits(fit, "try-error")) {
        orders[j] <- 0L
        phi <- numeric(0)
      } else {
        orders[j] <- fit$order
        phi <- if (orders[j] > 0) as.numeric(fit$ar) else numeric(0)
      }
    } else {
      orders[j] <- as.integer(p)
      if (p > 0) {
        fit <- try(stats::ar(x, aic = FALSE, order.max = p, method = "yw"), silent = TRUE)
        phi <- if (inherits(fit, "try-error")) rep(0, p) else as.numeric(fit$ar)
      } else {
        phi <- numeric(0)
      }
    }
    phis[[j]] <- phi
    E_high[, j] <- .mppi_adv_ar_resid(x, phi)
  }
  E <- U_low + E_high
  attr(E, "orders") <- orders
  attr(E, "phis") <- phis
  E
}

#' Spectral summary of task-modulated covariance
#'
#' @param fit object returned by `mppi_fit` (basis or ROI space)
#' @param k condition index (1-based)
#' @param templates optional named list of template vectors for eigenvector alignment
#' @return list with eigenvalues, first eigenvector, lambda1 share, effective rank, etc.
#' @export
mppi_spectral_summary <- function(fit, k, templates = NULL) {
  Mk <- .mppi_adv_Mk(fit, k)
  Mk <- 0.5 * (Mk + t(Mk))
  eig <- eigen(Mk, symmetric = TRUE)
  lam <- eig$values
  V <- eig$vectors
  lam2 <- lam^2
  total <- sum(lam2) + 1e-12
  share1 <- lam2[1] / total
  eff_rank <- exp(-sum((lam2 / total) * log((lam2 / total) + 1e-12)))
  v1 <- V[, 1]
  sign_balance <- max(mean(v1 >= 0), mean(v1 <= 0))
  net_proj <- NULL
  if (!is.null(templates)) {
    net_proj <- vapply(templates, function(tmpl) {
      u <- as.numeric(tmpl)
      u <- u / sqrt(sum(u^2) + 1e-12)
      sum(v1 * u) / sqrt(sum(v1^2) + 1e-12)
    }, numeric(1))
  }
  list(lambda = lam, v1 = v1, lambda1_share = share1,
       effrank = eff_rank, sign_balance = sign_balance,
       net_proj = net_proj)
}

#' Precision-domain perturbation via baseline gating
#'
#' @param fit multiPPI fit
#' @param k condition index
#' @param lambda ridge parameter for baseline precision
#' @return list with `dTheta`, `Theta0`, and off-diagonal energy
#' @export
mppi_precision_delta <- function(fit, k, lambda = 1e-3) {
  X <- .mppi_adv_X(fit)
  S0 <- crossprod(X) / nrow(X)
  p <- ncol(S0)
  Theta0 <- solve(S0 + diag(lambda, p))
  Mk <- .mppi_adv_Mk(fit, k, X)
  dTheta <- -Theta0 %*% Mk %*% Theta0
  off <- dTheta - diag(diag(dTheta))
  list(dTheta = dTheta, Theta0 = Theta0,
       offdiag_energy = sqrt(sum(off^2)))
}

#' Short-lag task-gated coupling matrices
#'
#' @param fit multiPPI fit
#' @param k condition index
#' @param lags integer vector of TR lags
#' @param mode "neural" uses stored series; "innov" applies `mppi_innovations`
#' @param protect strategy for innovations
#' @param K_keep DCT components when protect = "lowK"
#' @param f_cut Hz cutoff when protect = "lowHz"
#' @param TR repetition time for protect = "lowHz"
#' @param ar_order AR order mode for innovations
#' @param p maximum AR order
#' @return list with matrices per lag and routing index R
#' @rdname mppi_lagged
#' @method mppi_lagged mppi_fit
#' @export
mppi_lagged.mppi_fit <- function(fit, k, lags = -2:2, mode = c("neural", "innov"),
                                 protect = "lowK", K_keep = 8L, f_cut = 0.03,
                                 TR = NULL, ar_order = "auto", p = 4L) {
  mode <- match.arg(mode)
  X <- .mppi_adv_X(fit)
  if (!is.null(attr(X, "TR"))) TR <- attr(X, "TR")
  pk <- .mppi_adv_pk(fit, k)
  if (mode == "innov") {
    X <- mppi_innovations(X, TR = TR, protect = protect,
                          K_keep = K_keep, f_cut = f_cut,
                          ar_order = ar_order, p = p, center = FALSE)
  }
  M_by_lag <- setNames(vector("list", length(lags)), as.character(lags))
  pos_energy <- 0
  neg_energy <- 0
  for (ii in seq_along(lags)) {
    lg <- as.integer(lags[ii])
    Mk <- .mppi_adv_lagged_cross(X, pk, lg)
    M_by_lag[[ii]] <- Mk
    e <- sqrt(sum(Mk^2, na.rm = TRUE))
    if (lg > 0) pos_energy <- pos_energy + e
    if (lg < 0) neg_energy <- neg_energy + e
  }
  denom <- pos_energy + neg_energy + 1e-12
  R <- (pos_energy - neg_energy) / denom
  list(M_lag = M_by_lag, R = R,
       energy_pos = pos_energy, energy_neg = neg_energy)
}

#' Gain vs routing classifier (G/C/I/R indices)
#'
#' @param fit multiPPI fit
#' @param k condition index
#' @param templates optional list of template vectors
#' @param lambda ridge parameter for precision delta
#' @param lags lags for routing index
#' @param mode innovations mode passed to `mppi_lagged`
#' @param B number of permutations for null distribution
#' @param seed RNG seed
#' @return list with indices, p-values, and label
#' @export
mppi_classify <- function(fit, k, templates = NULL, lambda = 1e-3,
                          lags = -2:2, mode = c("neural", "innov"),
                          B = 200L, seed = 1L) {
  mode <- match.arg(mode)
  spec <- mppi_spectral_summary(fit, k, templates)
  prec <- mppi_precision_delta(fit, k, lambda)
  lag <- mppi_lagged(fit, k, lags = lags, mode = mode)
  X <- .mppi_adv_X(fit)
  pk <- .mppi_adv_pk(fit, k)
  Mk_neural <- crossprod(X, pk * X) / (sum(pk^2) + 1e-12)
  Mk_innov <- if (mode == "innov") {
    Xi <- mppi_innovations(X, TR = attr(X, "TR") %||% NULL,
                           protect = "lowK", K_keep = 8L,
                           ar_order = "auto", p = 4L,
                           center = FALSE)
    crossprod(Xi, pk * Xi) / (sum(pk^2) + 1e-12)
  } else Mk_neural
  I_ratio <- sqrt(sum(Mk_innov^2)) / (sqrt(sum(Mk_neural^2)) + 1e-12)
  set.seed(seed)
  perm <- .mppi_adv_perm_shift(pk, B)
  G_null <- C_null <- I_null <- R_null <- numeric(B)
  TR_attr <- attr(X, "TR") %||% NULL
  for (b in seq_len(B)) {
    sb <- perm[, b]
    Mb <- crossprod(X, sb * X) / (sum(sb^2) + 1e-12)
    lam_b <- eigen(0.5 * (Mb + t(Mb)), symmetric = TRUE)$values
    lam2_b <- lam_b^2
    G_null[b] <- lam2_b[1] / (sum(lam2_b) + 1e-12)
    dTheta_b <- -prec$Theta0 %*% Mb %*% prec$Theta0
    off_b <- dTheta_b - diag(diag(dTheta_b))
    C_null[b] <- sqrt(sum(off_b^2))
    if (mode == "innov") {
      Xi_b <- mppi_innovations(X, TR = TR_attr, protect = "lowK",
                               K_keep = 8L, ar_order = "auto",
                               p = 4L, center = FALSE)
      Mb_i <- crossprod(Xi_b, sb * Xi_b) / (sum(sb^2) + 1e-12)
      I_null[b] <- sqrt(sum(Mb_i^2)) / (sqrt(sum(Mb^2)) + 1e-12)
    } else {
      I_null[b] <- 1
    }
    pos <- neg <- 0
    for (lg in lags) {
      Ml <- .mppi_adv_lagged_cross(X, sb, lg)
      e <- sqrt(sum(Ml^2, na.rm = TRUE))
      if (lg > 0) pos <- pos + e
      if (lg < 0) neg <- neg + e
    }
    R_null[b] <- (pos - neg) / (pos + neg + 1e-12)
  }
  G_obs <- spec$lambda1_share
  C_obs <- prec$offdiag_energy
  R_obs <- lag$R
  pG <- mean(G_null >= G_obs)
  pC <- mean(C_null >= C_obs)
  pI <- mean(I_null >= I_ratio)
  pR <- mean(abs(R_null) >= abs(R_obs))
  label <- if (G_obs > 0.5 && pC > 0.05 && pI > 0.05 && pR > 0.05) {
    "Gain-dominant"
  } else if (G_obs <= 0.5 && pC <= 0.05 && pI <= 0.05 && pR <= 0.05) {
    "Routing-dominant"
  } else {
    "Mixed/Ambiguous"
  }
  list(G = G_obs, pG = pG,
       C = C_obs, pC = pC,
       I = I_ratio, pI = pI,
       R = R_obs, pR = pR,
       label = label,
       spectrum = spec, precision = prec, lagged = lag)
}

#' Trial-resolved state-dependent PPI analysis
#'
#' @param fit multiPPI fit (neural or BOLD domain)
#' @param k condition index
#' @param onsets_idx integer TR indices for events
#' @param runs run label per TR
#' @param Wpre number of TRs in pre-event window
#' @param Wpost number of TRs in post-event window
#' @param mode "neural" or "innov"
#' @param TR repetition time (needed when innovations protect = "lowHz")
#' @param protect innovations strategy
#' @param K_keep DCT components when protect = "lowK"
#' @param f_cut Hz cutoff when protect = "lowHz"
#' @param ar_order innovations AR mode
#' @param p maximum AR order
#' @param nuisance_ts named list of nuisance timeseries (length T)
#' @return list with trial data, models, and cross-validated correlation
#' @export
mppi_sdppi_fit <- function(fit, k, onsets_idx, runs,
                           Wpre = 8L, Wpost = 12L,
                           mode = c("neural", "innov"),
                           TR = NULL, protect = "lowK", K_keep = 8L,
                           f_cut = 0.03, ar_order = "auto", p = 4L,
                           nuisance_ts = NULL) {
  mode <- match.arg(mode)
  X <- .mppi_adv_X(fit)
  if (!is.null(attr(X, "TR"))) TR <- attr(X, "TR")
  stopifnot(length(runs) == nrow(X))
  if (mode == "innov") {
    X <- mppi_innovations(X, TR = TR, protect = protect,
                          K_keep = K_keep, f_cut = f_cut,
                          ar_order = ar_order, p = p, center = FALSE)
  }
  Tn <- nrow(X)
  r <- ncol(X)
  Theta0 <- solve(crossprod(X) / Tn + diag(1e-3, r))
  rows <- list()
  out_runs <- integer(0)
  for (idx in seq_along(onsets_idx)) {
    t0 <- as.integer(onsets_idx[idx])
    pre_idx <- .mppi_adv_window(Tn, t0, Wpre, pre = TRUE)
    post_idx <- .mppi_adv_window(Tn, t0, Wpost, pre = FALSE)
    if (length(pre_idx) < 3 || length(post_idx) < 3) next
    Sw <- crossprod(X[pre_idx, , drop = FALSE]) / length(pre_idx)
    eig <- eigen(0.5 * (Sw + t(Sw)), symmetric = TRUE)
    lam <- eig$values
    lam2 <- lam^2
    total <- sum(lam2) + 1e-12
    pre_lambda1_share <- lam2[1] / total
    pre_effrank <- exp(-sum((lam2 / total) * log((lam2 / total) + 1e-12)))
    v1 <- eig$vectors[, 1]
    pre_sign_balance <- max(mean(v1 >= 0), mean(v1 <= 0))
    Mk_post <- crossprod(X, (.mppi_adv_indicator(Tn, post_idx) * X)) /
      (length(post_idx) + 1e-12)
    dTheta_post <- -Theta0 %*% Mk_post %*% Theta0
    Mk_pre <- crossprod(X, (.mppi_adv_indicator(Tn, pre_idx) * X)) /
      (length(pre_idx) + 1e-12)
    dTheta_pre <- -Theta0 %*% Mk_pre %*% Theta0
    ppi_energy <- sqrt(sum(Mk_post^2))
    cond_energy <- sqrt(sum((dTheta_post - diag(diag(dTheta_post)))^2))
    ppi_delta <- ppi_energy - sqrt(sum(Mk_pre^2))
    cond_delta <- cond_energy - sqrt(sum((dTheta_pre - diag(diag(dTheta_pre)))^2))
    nuis <- .mppi_adv_nuisance(nuisance_ts, pre_idx)
    row <- c(pre_lambda1_share = pre_lambda1_share,
             pre_effrank = pre_effrank,
             pre_sign_balance = pre_sign_balance,
             ppi_energy = ppi_energy,
             cond_energy = cond_energy,
             ppi_energy_delta = ppi_delta,
             cond_energy_delta = cond_delta,
             nuis)
    rows[[length(rows) + 1L]] <- row
    out_runs <- c(out_runs, runs[t0])
  }
  if (!length(rows)) stop("No valid trials for sdPPI analysis.")
  mat <- do.call(rbind, rows)
  data <- as.data.frame(mat)
  data$run <- out_runs
  resp_vars <- c("ppi_energy", "cond_energy", "ppi_energy_delta", "cond_energy_delta")
  predictors <- setdiff(colnames(data), c("run", resp_vars))
  lm_ppi <- stats::lm(ppi_energy ~ ., data = data[, c("ppi_energy", predictors), drop = FALSE])
  lm_cond <- stats::lm(cond_energy ~ ., data = data[, c("cond_energy", predictors), drop = FALSE])
  lm_ppi_delta <- stats::lm(ppi_energy_delta ~ ., data = data[, c("ppi_energy_delta", predictors), drop = FALSE])
  lm_cond_delta <- stats::lm(cond_energy_delta ~ ., data = data[, c("cond_energy_delta", predictors), drop = FALSE])
  cv_r <- .mppi_adv_cv_r(data, runs = data$run, response = "ppi_energy", predictors = predictors)
  list(data = data,
       model_ppi = lm_ppi,
       model_cond = lm_cond,
       model_ppi_delta = lm_ppi_delta,
       model_cond_delta = lm_cond_delta,
       cv_r = cv_r)
}

#' Generate matched null onsets away from real events
#'
#' @param Tlen number of TRs
#' @param onsets_idx observed event indices
#' @param n number of null events
#' @param guard guard width in TRs
#' @return sorted integer vector of null onset indices
#' @export
mppi_make_null_onsets <- function(Tlen, onsets_idx, n = length(onsets_idx), guard = 8L) {
  forbid <- rep(FALSE, Tlen)
  for (t0 in onsets_idx) {
    lo <- max(1L, t0 - guard)
    hi <- min(Tlen, t0 + guard)
    forbid[lo:hi] <- TRUE
  }
  cand <- which(!forbid)
  if (length(cand) < n) stop("Not enough candidate TRs for null onsets; reduce guard.")
  sort(sample(cand, n, replace = FALSE))
}

#' Cross-validated mapping from pre-state predictors to anchors
#'
#' @param sd_df output data frame from `mppi_sdppi_fit`
#' @param y response vector (numeric or binary factor)
#' @param runs run ids for cross-validation
#' @param family "gaussian" for lm, "binomial" for logistic
#' @return list with cv_r (gaussian) or cv_auc (binomial)
#' @export
mppi_state_predict <- function(sd_df, y, runs = NULL,
                               family = c("gaussian", "binomial")) {
  family <- match.arg(family)
  X <- sd_df[, grepl("^pre_", names(sd_df)), drop = FALSE]
  if (is.null(runs)) runs <- sd_df$run %||% rep(1L, nrow(sd_df))
  runs <- as.integer(runs)
  uniq <- sort(unique(runs))
  preds <- numeric(0)
  obs <- y[0]
  for (rr in uniq) {
    idx_tr <- which(runs != rr)
    idx_te <- which(runs == rr)
    if (length(idx_tr) < 5 || length(idx_te) < 1) next
    dat_tr <- data.frame(y = y[idx_tr], X[idx_tr, , drop = FALSE])
    dat_te <- data.frame(y = y[idx_te], X[idx_te, , drop = FALSE])
    if (family == "gaussian") {
      fit <- stats::lm(y ~ ., data = dat_tr)
      mm <- model.matrix(~ ., data = dat_te)[, -1, drop = FALSE]
      preds <- c(preds, as.numeric(coef(fit)[1] + mm %*% coef(fit)[-1]))
      obs <- c(obs, y[idx_te])
    } else {
      fit <- stats::glm(y ~ ., family = stats::binomial(), data = dat_tr)
      preds <- c(preds, as.numeric(stats::predict(fit, newdata = dat_te, type = "response")))
      obs <- c(obs, y[idx_te])
    }
  }
  if (family == "gaussian") {
    cv_r <- if (length(preds) > 1) stats::cor(preds, obs) else NA_real_
    list(cv_r = cv_r)
  } else {
    if (length(unique(obs)) != 2) return(list(cv_auc = NA_real_))
    ranks <- rank(preds)
    pos <- obs == max(obs)
    n_pos <- sum(pos)
    n_neg <- sum(!pos)
    if (n_pos == 0 || n_neg == 0) return(list(cv_auc = NA_real_))
    auc <- (sum(ranks[pos]) - n_pos * (n_pos + 1) / 2) / (n_pos * n_neg)
    list(cv_auc = auc)
  }
}

#' Baseline precision metrics
#'
#' @param Theta0 precision matrix (positive definite)
#' @return list with algebraic connectivity, effective rank, Qmax, and mean communicability
#' @export
mppi_theta_metrics <- function(Theta0) {
  p <- nrow(Theta0)
  A <- -Theta0
  diag(A) <- 0
  A[A < 0] <- 0
  deg <- rowSums(A)
  L <- diag(deg, p) - A
  eigL <- eigen(0.5 * (L + t(L)), symmetric = TRUE)$values
  alg_conn <- if (length(eigL) >= 2) eigL[2] else NA_real_
  eigA <- eigen(0.5 * (A + t(A)), symmetric = TRUE)$values
  eigA[eigA < 0] <- 0
  lam2 <- eigA^2
  total <- sum(lam2) + 1e-12
  effrankA <- exp(-sum((lam2 / total) * log((lam2 / total) + 1e-12)))
  m <- sum(A) / 2
  if (m > 0) {
    P <- (deg %*% t(deg)) / (2 * m)
    B <- A - P
    lamB <- eigen(0.5 * (B + t(B)), symmetric = TRUE)$values
    Qmax <- sum(pmax(lamB, 0)) / (2 * m + 1e-12)
  } else {
    Qmax <- NA_real_
  }
  C <- .mppi_adv_expm_sym(A)
  comm_avg <- (sum(C) - sum(diag(C))) / (p * (p - 1) + 1e-12)
  list(alg_conn = alg_conn,
       effrankA = effrankA,
       Qmax = Qmax,
       comm_avg = comm_avg)
}

#' Examine how baseline precision gates gain vs routing
#'
#' @param fits list of `mppi_fit` objects
#' @param k condition index
#' @param lambda ridge parameter for Theta0
#' @param controls optional data frame of control variables (rows align with fits)
#' @return list with combined data and lm objects for G and C
#' @export
mppi_gate_by_theta <- function(fits, k, lambda = 1e-3, controls = NULL) {
  stopifnot(is.list(fits), length(fits) >= 1)
  rows <- vector("list", length(fits))
  for (i in seq_along(fits)) {
    fit <- fits[[i]]
    X <- .mppi_adv_X(fit)
    S0 <- crossprod(X) / nrow(X)
    Theta0 <- solve(S0 + diag(lambda, ncol(S0)))
    mts <- mppi_theta_metrics(Theta0)
    spec <- mppi_spectral_summary(fit, k)
    prec <- mppi_precision_delta(fit, k, lambda = lambda)
    rows[[i]] <- c(G = spec$lambda1_share,
                   C = prec$offdiag_energy,
                   alg_conn = mts$alg_conn,
                   effrankA = mts$effrankA,
                   Qmax = mts$Qmax,
                   comm_avg = mts$comm_avg)
  }
  df <- as.data.frame(do.call(rbind, rows))
  if (!is.null(controls)) {
    stopifnot(nrow(controls) == nrow(df))
    df <- cbind(df, controls)
  }
  fm <- reformulate(setdiff(names(df), c("G", "C")), response = "G")
  model_G <- stats::lm(fm, data = df)
  fmC <- reformulate(setdiff(names(df), c("G", "C")), response = "C")
  model_C <- stats::lm(fmC, data = df)
  list(data = df, model_G = model_G, model_C = model_C)
}

# Internal utilities ---------------------------------------------------------

.mppi_adv_X <- function(fit) {
  if (!is.null(fit$U)) return(fit$U)
  if (!is.null(fit$Z)) return(fit$Z)
  if (!is.null(fit$R)) return(fit$R)
  stop("fit must carry U, Z, or R time-series.")
}

.mppi_adv_pk <- function(fit, k) {
  stopifnot(!is.null(fit$pk), k >= 1, k <= length(fit$pk))
  as.numeric(fit$pk[[k]])
}

.mppi_adv_Mk <- function(fit, k, X = NULL) {
  pk <- .mppi_adv_pk(fit, k)
  if (is.null(X)) X <- .mppi_adv_X(fit)
  denom <- sum(pk^2) + 1e-12
  crossprod(X, pk * X) / denom
}

.mppi_adv_lagged_cross <- function(X, pk, lag) {
  lag <- as.integer(lag)
  Tn <- nrow(X)
  if (lag == 0L) return(.mppi_adv_Mk_list(X, pk))
  if (abs(lag) >= Tn) return(matrix(NA_real_, ncol(X), ncol(X)))
  if (lag > 0) {
    idx <- seq_len(Tn - lag)
    X0 <- X[idx, , drop = FALSE]
    X1 <- X[idx + lag, , drop = FALSE]
    w <- pk[idx]
  } else {
    shift <- abs(lag)
    idx <- seq_len(Tn - shift)
    X0 <- X[idx + shift, , drop = FALSE]
    X1 <- X[idx, , drop = FALSE]
    w <- pk[idx]
  }
  denom <- sum(w^2) + 1e-12
  crossprod(X0, w * X1) / denom
}

.mppi_adv_Mk_list <- function(X, pk) {
  denom <- sum(pk^2) + 1e-12
  crossprod(X, pk * X) / denom
}

.mppi_adv_perm_shift <- function(pk, B) {
  Tn <- length(pk)
  vapply(seq_len(B), function(i) {
    s <- sample.int(Tn, 1)
    c(tail(pk, -s), head(pk, s))
  }, numeric(Tn))
}

.mppi_adv_window <- function(Tn, center, width, pre = TRUE) {
  if (pre) {
    seq.int(max(1L, center - width), max(1L, center - 1L))
  } else {
    seq.int(center, min(Tn, center + width - 1L))
  }
}

.mppi_adv_indicator <- function(Tn, idx) {
  v <- numeric(Tn)
  v[idx] <- 1
  v
}

.mppi_adv_nuisance <- function(nuisance_ts, idx) {
  if (is.null(nuisance_ts) || !length(nuisance_ts)) return(numeric(0))
  out <- vapply(nuisance_ts, function(ts) {
    vals <- ts[idx]
    c(mean(vals), stats::sd(vals), if (length(vals) > 1) stats::coef(stats::lm(vals ~ seq_along(vals)))[2] else 0)
  }, numeric(3))
  as.numeric(out)
}

.mppi_adv_cv_r <- function(data, runs, response, predictors) {
  runs <- as.integer(runs)
  uniq <- sort(unique(runs))
  preds <- numeric(0)
  obs <- numeric(0)
  for (rr in uniq) {
    idx_tr <- which(runs != rr)
    idx_te <- which(runs == rr)
    if (length(idx_tr) < 5 || length(idx_te) < 1) next
    fit <- stats::lm(reformulate(predictors, response), data = data[idx_tr, , drop = FALSE])
    mm <- model.matrix(reformulate(predictors), data = data[idx_te, , drop = FALSE])
    preds <- c(preds, as.numeric(mm %*% coef(fit)))
    obs <- c(obs, data[[response]][idx_te])
  }
  if (length(preds) > 1) stats::cor(preds, obs) else NA_real_
}

.mppi_adv_dct_matrix <- function(Tn, K) {
  k <- 0:(K - 1)
  n <- 0:(Tn - 1)
  M <- outer(n + 0.5, k, function(nn, kk) cos(pi * nn * kk / Tn))
  M[, 1] <- M[, 1] / sqrt(Tn)
  if (K > 1) M[, -1] <- M[, -1] * sqrt(2 / Tn)
  M
}

.mppi_adv_project_lowK <- function(X, K) {
  Tn <- nrow(X)
  K <- min(as.integer(K), Tn)
  if (K <= 0) return(0 * X)
  D <- .mppi_adv_dct_matrix(Tn, K)
  D %*% crossprod(D, X)
}

.mppi_adv_bandlimit <- function(X, TR, f_cut, which = c("low", "high")) {
  which <- match.arg(which)
  Tn <- nrow(X)
  K <- max(1L, min(Tn, floor(2 * Tn * TR * f_cut)))
  XL <- .mppi_adv_project_lowK(X, K)
  if (which == "low") XL else X - XL
}

.mppi_adv_ar_resid <- function(x, phi) {
  p <- length(phi)
  if (p == 0) return(x)
  Tn <- length(x)
  if (p >= Tn) p <- Tn - 1L
  res <- numeric(Tn)
  res[seq_len(p)] <- x[seq_len(p)]
  for (t in (p + 1):Tn) {
    res[t] <- x[t] - sum(phi * x[(t - 1):(t - p)])
  }
  res
}

.mppi_adv_expm_sym <- function(A) {
  eig <- eigen(0.5 * (A + t(A)), symmetric = TRUE)
  V <- eig$vectors
  L <- eig$values
  V %*% (diag(exp(pmax(pmin(L, 50), -50)), length(L))) %*% t(V)
}
</file>

<file path="R/mppi_axes.R">
# Gain-routing axes ---------------------------------------------------------

#' Summarise conditions along gain and routing axes
#'
#' @param fit `mppi_fit` object
#' @param lags integer vector of lags (excluding zero) used for routing; defaults to stored lags
#' @param mode scale view for the interaction matrices
#' @param use_cached reuse stored lagged matrices when available
#' @return data.frame with condition name, gain, and routing indices
#' @export
mppi_axes <- function(fit, lags = NULL, mode = c("normalized", "amplitude", "raw"), use_cached = TRUE) {
  stopifnot(inherits(fit, "mppi_fit"))
  mode <- match.arg(mode)
  cond_names <- fit$names
  if (is.null(cond_names)) cond_names <- paste0("k", seq_along(fit$Delta))
  Sigma0 <- fit$Sigma0
  if (is.null(Sigma0)) {
    stop("Baseline covariance (Sigma0) not stored in fit; refit with scale='cov'.", call. = FALSE)
  }
  Sigma_sym <- 0.5 * (Sigma0 + t(Sigma0))
  eig_base <- eigen(Sigma_sym, symmetric = TRUE)
  v1 <- eig_base$vectors[, 1]
  if (is.null(lags)) {
    if (!is.null(fit$lags)) {
      lags <- setdiff(sort(unique(as.integer(fit$lags))), 0L)
    } else {
      lags <- integer(0)
    }
  } else {
    lags <- setdiff(sort(unique(as.integer(lags))), 0L)
  }
  eps <- 1e-12
  rows <- vector("list", length(cond_names))

  get_lag_mats <- function(k_idx) {
    if (!length(lags)) return(list())
    if (use_cached && !is.null(fit$lagged) && !is.null(fit$lags) && all(lags %in% as.integer(fit$lags))) {
      lag_store <- fit$lagged[[k_idx]]
      if (is.null(lag_store)) lag_store <- fit$lagged[[cond_names[k_idx]]]
      if (is.null(lag_store)) return(list())
      lapply(as.character(lags), function(lg) lag_store[[lg]])
    } else {
      lagged <- mppi_lagged(fit, k = k_idx, lags = sort(unique(c(0L, lags))))
      lapply(as.character(lags), function(lg) lagged$M_lag[[lg]])
    }
  }

  for (k_idx in seq_along(cond_names)) {
    Mk <- mppi_get_M_scaled(fit, k_idx, mode = mode)
    Sk <- 0.5 * (Mk + t(Mk))
    fnorm <- sqrt(sum(Sk^2, na.rm = TRUE))
    gain <- if (fnorm < eps) NA_real_ else as.numeric((t(v1) %*% Sk %*% v1) / fnorm)
    if (!is.na(gain)) gain <- max(min(gain, 1), -1)

    lag_mats <- get_lag_mats(k_idx)
    if (length(lag_mats)) {
      pos_sum <- 0
      neg_sum <- 0
      for (i in seq_along(lags)) {
        lg <- lags[i]
        Mk_lag <- lag_mats[[i]]
        if (is.null(Mk_lag)) next
        e <- sqrt(sum(Mk_lag^2, na.rm = TRUE))
        if (lg > 0) pos_sum <- pos_sum + e
        if (lg < 0) neg_sum <- neg_sum + e
      }
      routing <- (pos_sum - neg_sum) / (pos_sum + neg_sum + eps)
    } else {
      routing <- NA_real_
    }
    rows[[k_idx]] <- data.frame(condition = cond_names[k_idx],
                                gain = gain,
                                routing = routing,
                                scale = mode,
                                stringsAsFactors = FALSE)
  }
  do.call(rbind, rows)
}
</file>

<file path="R/mppi_band.R">
# Frequency-specific variants ---------------------------------------------

#' Simple bandpass using stats::filter or signal::butter if available
#' @param x T x V matrix
#' @param low highpass cutoff in (0, 0.5) cycles/TR; NULL for none
#' @param high lowpass cutoff in (0, 0.5); NULL for none
#' @param order filter order for Butterworth if 'signal' present
mppi_bandpass <- function(x, low = NULL, high = 0.1, order = 2L) {
  stopifnot(is.matrix(x))
  if (!is.null(low) || !is.null(high)) {
    if (requireNamespace("signal", quietly = TRUE)) {
      fs <- 1  # sample freq (per TR unit)
      Wc <- c(ifelse(is.null(low), 0, low), ifelse(is.null(high), 0.499, high))
      if (is.null(low)) { # lowpass
        bf <- signal::butter(order, Wc[2], type = "low")
      } else if (is.null(high)) { # highpass
        bf <- signal::butter(order, Wc[1], type = "high")
      } else { # bandpass
        bf <- signal::butter(order, Wc, type = "pass")
      }
      y <- apply(x, 2, function(col) as.numeric(signal::filtfilt(bf, col)))
      return(matrix(y, nrow = nrow(x), ncol = ncol(x)))
    } else {
      # Fallback: simple moving-average detrend / low-pass via running mean
      if (!is.null(high)) {
        k <- max(3L, round(1/(2*high)))
        w <- rep(1/k, k)
        y <- apply(x, 2, function(col) as.numeric(stats::filter(col, w, sides = 2, circular = FALSE)))
        y[is.na(y)] <- 0
        return(matrix(y, nrow = nrow(x), ncol = ncol(x)))
      } else {
        return(x)
      }
    }
  }
  x
}

#' Fit ΔΣ per frequency band and optionally combine
#' @param bands list of lists: each with low, high, name
mppi_fit_multi_band <- function(Y, X, psych_idx, bands,
                                zero_diag = TRUE, scale = c("cov","corr")) {
  res <- list()
  for (bd in bands) {
    Yb <- mppi_bandpass(Y, low = bd$low, high = bd$high)
    fit <- mppi_fit(Yb, X, psych_idx, zero_diag = zero_diag, scale = scale)
    res[[bd$name]] <- fit
  }
  res
}
</file>

<file path="R/mppi_basis.R">
# Basis utilities ----------------------------------------------------------

#' Create an mPPI basis object
#' @param V matrix (V x r) whose columns span the desired subspace
#' @param name optional label for reporting
#' @param orthonormalize logical; orthonormalize columns via QR (default TRUE)
#' @return object of class 'mppi_basis'
as_mppi_basis <- function(V, name = "basis", orthonormalize = TRUE) {
  V <- as.matrix(V)
  if (orthonormalize) {
    qrV <- qr(V)
    Q <- qr.Q(qrV)
    rank <- qrV$rank
    V <- Q[, seq_len(rank), drop = FALSE]
  }
  structure(list(V = V, name = name, r = ncol(V)), class = "mppi_basis")
}

# Internal helper: PCA basis (columns span low-rank subspace in ROI space)
.mppi_pca_basis <- function(Y, r = NULL, center = TRUE, scale = FALSE, name = "pca") {
  stopifnot(is.matrix(Y))
  n_time <- nrow(Y)
  n_space <- ncol(Y)
  if (n_space == 0L) stop("Cannot compute a PCA basis on a matrix with zero columns.")
  r_max <- min(n_time, n_space)
  if (is.null(r)) r <- min(50L, r_max)
  r <- as.integer(r)
  if (!is.finite(r) || r <= 0L) r <- min(50L, r_max)
  r <- min(r, r_max)
  if (center || scale) {
    Yc <- scale(Y, center = center, scale = scale)
    if (!is.matrix(Yc)) Yc <- as.matrix(Yc)
  } else {
    Yc <- Y
  }
  sv <- La.svd(Yc, nu = 0L, nv = r)
  V <- t(sv$vt)
  if (ncol(V) > r) V <- V[, seq_len(r), drop = FALSE]
  basis_name <- sprintf("%s(r=%d)", name, ncol(V))
  as_mppi_basis(V, name = basis_name)
}

.mppi_resolve_basis <- function(Y, basis, r = NULL, dataset = NULL, design = NULL) {
  stopifnot(is.matrix(Y))
  coalesce <- function(...) {
    for (val in list(...)) {
      if (!is.null(val)) return(val)
    }
    NULL
  }

  # Already a concrete basis specification
  if (inherits(basis, "mppi_basis")) {
    if (is.null(basis$source)) basis$source <- "provided"
    return(basis)
  }
  if (is.matrix(basis) || (is.list(basis) && !is.null(basis$V))) {
    obj <- .mppi_check_basis(basis, ncol(Y))
    obj$source <- "provided"
    return(obj)
  }

  basis_spec <- basis
  basis_type <- "auto"
  basis_rank <- r

  if (is.list(basis_spec) && is.null(basis_spec$V)) {
    basis_type <- coalesce(basis_spec$type, basis_type)
    basis_rank <- coalesce(basis_spec$r, basis_rank)
  } else if (is.character(basis_spec)) {
    basis_type <- basis_spec[[1L]]
  } else if (!is.null(basis_spec)) {
    stop("Unsupported basis specification; provide a matrix, mppi_basis, character key, or list with type/r.")
  }

  basis_type <- tolower(basis_type)
  allowed_types <- c("auto", "pca", "roi", "none")
  basis_type <- match.arg(basis_type, allowed_types)

  if (is.null(basis_rank)) {
    basis_rank <- min(50L, min(nrow(Y), ncol(Y)))
  }
  basis_rank <- as.integer(basis_rank)
  if (!is.finite(basis_rank) || basis_rank <= 0L) {
    basis_rank <- min(50L, min(nrow(Y), ncol(Y)))
  }

  take_existing <- function(obj) {
    if (is.null(obj)) return(NULL)
    cand <- coalesce(obj$basis, obj$V, attr(obj, "basis"))
    if (is.null(cand) && is.list(obj) && !is.null(obj$basis) && is.list(obj$basis)) {
      cand <- obj$basis
    }
    cand
  }

  if (identical(basis_type, "auto")) {
    candidate <- coalesce(take_existing(dataset), take_existing(design))
    if (!is.null(candidate)) {
      obj <- .mppi_check_basis(candidate, ncol(Y))
      obj$source <- "auto"
      return(obj)
    }
    basis_type <- "pca"
  }

  if (basis_type %in% c("roi", "none")) {
    return(NULL)
  }

  if (identical(basis_type, "pca")) {
    obj <- .mppi_pca_basis(Y, r = basis_rank)
    obj$source <- "pca"
    return(obj)
  }

  stop(sprintf("Unsupported basis type '%s'.", basis_type))
}

#' Extract a basis-space interaction matrix
mppi_get_M <- function(fit, k) {
  if (is.character(k)) idx <- match(k, fit$names) else idx <- k
  if (is.na(idx) || idx < 1 || idx > length(fit$Delta)) stop("Invalid regressor index")
  D <- fit$Delta[[idx]]
  if (is.list(D) && !is.null(D$values)) {
    .mppi_unpack_upper(D)
  } else {
    D
  }
}

#' Extract a lagged interaction matrix
#' @param fit An `mppi_fit` object.
#' @param k Regressor index or name.
#' @param lag Integer lag τ (τ = 0 returns the contemporaneous matrix).
#' @return Matrix representing the interaction at lag τ in the working space.
#' @export
mppi_get_M_lag <- function(fit, k, lag = 0L) {
  lag <- as.integer(lag)
  if (lag == 0L) return(mppi_get_M(fit, k))
  if (is.null(fit$lagged)) {
    stop("Fit does not store lagged interactions; refit with lags != 0.", call. = FALSE)
  }
  if (is.character(k)) idx <- match(k, fit$names) else idx <- as.integer(k)
  if (is.na(idx) || idx < 1 || idx > length(fit$lagged)) {
    stop("Invalid regressor index for lag extraction.", call. = FALSE)
  }
  per_reg <- fit$lagged[[idx]]
  if (is.null(per_reg)) per_reg <- fit$lagged[[fit$names[idx]]]
  if (is.null(per_reg)) {
    stop("Requested regressor does not have lagged matrices stored.", call. = FALSE)
  }
  Mk <- per_reg[[as.character(lag)]]
  if (is.null(Mk)) {
    stop(sprintf("No lagged matrix stored for lag %s.", lag), call. = FALSE)
  }
  if (is.list(Mk) && !is.null(Mk$values)) {
    Mk <- .mppi_unpack_upper(Mk)
  }
  Mk
}

#' Reconstruct a submatrix of Δ from a basis fit
mppi_reconstruct_delta <- function(fit, k, rows = NULL, cols = NULL) {
  if (is.null(fit$basis)) {
    D <- mppi_get_M(fit, k)
    if (!is.null(rows) || !is.null(cols)) {
      if (is.null(rows)) rows <- seq_len(nrow(D))
      if (is.null(cols)) cols <- seq_len(ncol(D))
      D <- D[rows, cols, drop = FALSE]
    }
    return(D)
  }
  V <- fit$basis$V
  M <- mppi_get_M(fit, k)
  if (is.null(rows)) rows <- seq_len(nrow(V))
  if (is.null(cols)) cols <- seq_len(nrow(V))
  V_rows <- V[rows, , drop = FALSE]
  V_cols <- V[cols, , drop = FALSE]
  full <- V_rows %*% M %*% t(V_cols)
  if (length(rows) == length(cols) && all(rows == cols)) diag(full) <- 0
  full
}

#' Compute a single edge from a basis fit
mppi_edge <- function(fit, k, i, j) {
  if (is.null(fit$basis)) stop("mppi_edge() requires a basis-aware fit.")
  V <- fit$basis$V
  M <- mppi_get_M(fit, k)
  as.numeric(V[i, , drop = FALSE] %*% M %*% t(V[j, , drop = FALSE]))
}
</file>

<file path="R/mppi_beta.R">
# Beta-series versions -----------------------------------------------------

#' Coerce fmrilss output to a trial x V beta matrix
#' @param obj matrix, data.frame with (trial, roi, beta), or list of numeric vectors
mppi_coerce_beta <- function(obj) {
  if (is.matrix(obj)) return(obj)
  if (is.data.frame(obj)) {
    req <- c("trial","roi","beta")
    if (!all(req %in% names(obj))) stop("data.frame must have columns: trial, roi, beta")
    tab <- xtabs(beta ~ trial + roi, data = obj)
    B <- as.matrix(tab)
    # Order trials numerically if rownames are numeric
    rn <- suppressWarnings(as.integer(rownames(B)))
    if (all(!is.na(rn))) B <- B[order(rn), , drop = FALSE]
    return(B)
  }
  if (is.list(obj) && all(vapply(obj, is.numeric, TRUE))) {
    lens <- vapply(obj, length, 1L)
    if (length(unique(lens)) != 1L) stop("All vectors in the list must have the same length (V).")
    return(do.call(rbind, obj))
  }
  stop("Can't coerce object to a trial x V beta matrix.")
}

#' Beta-series Matrix-PPI (β-mPPI)
#' @param B nTrials x V beta matrix
#' @param Pbeta nTrials x K psychological regressors (trial-level)
#' @param Cbeta optional nTrials x q trial-level confounds
#' @return list with Delta, names, RB, pk (residualized regressors), and meta information per regressor
mppi_fit_beta <- function(B, Pbeta, Cbeta = NULL, runs = NULL,
                          zero_diag = TRUE, scale = c("cov","corr"),
                          center_by = c("none","run"), na_action = c("omit_tr","error"),
                          backend = c("blas","accumulate","chunked"), packed = FALSE,
                          chunk_size = NULL) {
  stopifnot(is.matrix(B), is.matrix(Pbeta), nrow(B) == nrow(Pbeta))
  if (!is.null(runs)) stopifnot(length(runs) == nrow(B))
  scale <- match.arg(scale)
  center_by <- match.arg(center_by)
  na_action <- match.arg(na_action)
  backend <- match.arg(backend)
  if (center_by == "run" && is.null(runs)) {
    warning("center_by='run' requested but 'runs' is NULL; skipping run centering.", call. = FALSE)
    center_by <- "none"
  }
  Zb <- if (is.null(Cbeta)) cbind(1, Pbeta) else cbind(1, Cbeta, Pbeta)
  prep <- .mppi_handle_na(B, Zb, runs, na_action = na_action)
  B <- prep$Y; Zb <- prep$X; runs <- prep$runs
  if (prep$dropped > 0) {
    keep <- setdiff(seq_len(nrow(Pbeta)), prep$dropped_idx)
    Pbeta <- Pbeta[keep, , drop = FALSE]
    if (!is.null(Cbeta)) Cbeta <- Cbeta[keep, , drop = FALSE]
  }
  RB <- B - Zb %*% qr.coef(qr(Zb), B)
  if (scale == "corr") {
    s <- matrixStats::colSds(RB)
    s[s == 0] <- 1
    RB <- sweep(RB, 2, s, "/")
  }
  K <- ncol(Pbeta)
  out <- vector("list", K)
  pks <- vector("list", K)
  meta <- vector("list", K)
  denoms <- numeric(K)
  pNms <- colnames(Pbeta)
  if (is.null(pNms)) pNms <- paste0("psych", seq_len(K))
  denom_warn <- function(name) {
    warning(sprintf("Beta regressor '%s' has near-zero variance after residualization; returning NA matrix.",
                    name), call. = FALSE)
  }
  for (ii in seq_len(K)) {
    Qb <- if (is.null(Cbeta)) cbind(1, Pbeta[, -ii, drop = FALSE])
          else                cbind(1, Cbeta, Pbeta[, -ii, drop = FALSE])
    Qqr <- qr(Qb)
    raw_col <- Pbeta[, ii]
    pk <- as.numeric(raw_col - Qb %*% qr.coef(Qqr, raw_col))
    if (center_by == "run" && !is.null(runs)) pk <- .mppi_center_by_run(pk, runs)
    denom <- sum(pk^2)
    denoms[ii] <- denom
    Dk <- if (denom < .Machine$double.eps) {
      denom_warn(pNms[ii])
      naMat <- matrix(NA_real_, ncol(B), ncol(B))
      if (packed) .mppi_pack_upper(naMat) else naMat
    } else {
      Dfull <- .mppi_crossprod(RB, pk, backend = backend, chunk_size = chunk_size) / denom
      if (packed) .mppi_pack_upper(Dfull) else Dfull
    }
    if (!packed && zero_diag) diag(Dk) <- 0
    if (packed && zero_diag) {
      Dtemp <- .mppi_unpack_upper(Dk)
      diag(Dtemp) <- 0
      Dk <- .mppi_pack_upper(Dtemp)
    }
    out[[ii]] <- Dk
    pks[[ii]] <- pk
    meta[[ii]] <- list(Q = Qb, qr = Qqr, raw = as.numeric(raw_col),
                       is_binary = all(raw_col %in% c(0, 1)))
  }
  names(out) <- pNms
  names(pks) <- pNms
  names(meta) <- pNms
  names(denoms) <- pNms
  res <- list(Delta = out, names = pNms, RB = RB, pk = pks, meta = meta,
              dropped = prep$dropped, runs = runs, center_by = center_by,
              scale = scale, denom = denoms, backend = backend,
              n_used = nrow(RB), packed = packed, chunk_size = chunk_size)
  class(res) <- c("mppi_fit_beta", "list")
  res
}

#' Permutation for β-mPPI omnibus per regressor
mppi_beta_permute <- function(B, Pbeta, Cbeta = NULL, run_trial = NULL,
                              blksize = NULL, Bperm = 999L, zero_diag = TRUE,
                              seed = NULL, method = c("auto","block_flip","permute")) {
  method <- match.arg(method)
  fit <- mppi_fit_beta(B, Pbeta, Cbeta, zero_diag = zero_diag, scale = "cov")
  Tn <- nrow(B)
  make_blocks <- function() {
    if (!is.null(run_trial)) {
      split(seq_len(Tn), run_trial)
    } else if (!is.null(blksize)) {
      split(seq_len(Tn), ceiling(seq_len(Tn)/blksize))
    } else {
      list(seq_len(Tn))
    }
  }
  idx_blocks <- make_blocks()
  res <- vector("list", length(fit$names))
  names(res) <- fit$names
  rng_pre <- RNGkind()
  seed_pre <- if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) get(".Random.seed", envir = .GlobalEnv, inherits = FALSE) else NULL
  if (!is.null(seed)) set.seed(seed)
  rng_used <- RNGkind()
  init_seed <- if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) get(".Random.seed", envir = .GlobalEnv, inherits = FALSE) else NULL
  on.exit({
    do.call(RNGkind, as.list(rng_pre))
    if (is.null(seed_pre)) {
      if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE))
        rm(".Random.seed", envir = .GlobalEnv)
    } else {
      assign(".Random.seed", seed_pre, envir = .GlobalEnv)
    }
  }, add = TRUE)
  for (nm in fit$names) {
    pk0 <- fit$pk[[nm]]
    denom0 <- sum(pk0^2)
    if (denom0 < .Machine$double.eps) {
      V <- ncol(fit$RB)
      res[[nm]] <- list(D = matrix(NA_real_, V, V), Q = NA_real_, Qnull = rep(NA_real_, Bperm),
                        p_global = NA_real_, note = "pk has near-zero variance; cannot evaluate permutations")
      next
    }
    D0 <- crossprod(fit$RB, pk0 * fit$RB) / denom0
    if (zero_diag) diag(D0) <- 0
    Q0 <- sum(D0^2, na.rm = TRUE)
    meta <- fit$meta[[nm]]
    Qb <- rep(NA_real_, Bperm)
    permute_block <- function(vec) {
      out <- vec
      for (g in idx_blocks) {
        out[g] <- sample(out[g])
      }
      out
    }
    signflip_block <- function(vec) {
      out <- vec
      sgn <- sample(c(-1,1), length(idx_blocks), replace = TRUE)
      jj <- 1L
      for (g in idx_blocks) {
        out[g] <- sgn[jj] * out[g]
        jj <- jj + 1L
      }
      out
    }
    for (b in seq_len(Bperm)) {
      if (meta$is_binary || method == "permute") {
        pk_raw <- permute_block(meta$raw)
        pkb <- as.numeric(pk_raw - meta$Q %*% qr.coef(meta$qr, pk_raw))
      } else {
        pkb <- signflip_block(pk0)
      }
      denomb <- sum(pkb^2)
      if (denomb < .Machine$double.eps) {
        next
      }
      Db <- crossprod(fit$RB, pkb * fit$RB) / denomb
      if (zero_diag) diag(Db) <- 0
      Qb[b] <- sum(Db^2, na.rm = TRUE)
    }
    valid <- !is.na(Qb)
    p_global <- if (!any(valid)) {
      NA_real_
    } else {
      (1 + sum(Qb[valid] >= Q0)) / (sum(valid) + 1)
    }
    res[[nm]] <- list(D = D0, Q = Q0, Qnull = Qb, p_global = p_global)
  }
  final_seed <- if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) get(".Random.seed", envir = .GlobalEnv, inherits = FALSE) else NULL
  attr(res, "rng") <- list(kind = rng_used, seed = init_seed, final_seed = final_seed,
                            method = method, seed_arg = seed)
  res
}
</file>

<file path="R/mppi_decompose.R">
# Variance-correlation decomposition --------------------------------------

#' Decompose ΔCov into correlation change and variance terms
#' @param R residualized time series (optionally per-condition bins)
#' @param pk residualized psychological regressor
#' @param DeltaSigma covariance slope matrix
#' @return list with Delta_rho (approx), var_terms (matrix), and note
mppi_decompose_variance <- function(R, pk, DeltaSigma) {
  # Approximate Δrho by standardizing R first
  s <- apply(R, 2, sd); s[s == 0] <- 1
  Rc <- sweep(R, 2, s, "/")
  pk_vec <- as.numeric(pk)
  denom <- sum(pk_vec^2)
  Dcorr <- if (denom < .Machine$double.eps) matrix(0, ncol(R), ncol(R)) else crossprod(Rc, pk_vec * Rc) / denom
  # Variance contributions are residual term
  var_terms <- DeltaSigma - (Dcorr * (s %o% s))
  list(Delta_rho = Dcorr, variance_terms = var_terms,
       note = "DeltaSigma ≈ (s ⊗ s) * Delta_rho + variance_terms")
}
</file>

<file path="R/mppi_deconv_dct.R">
#' DCT-regularized hemodynamic deconvolution (fast, vectorized via Rcpp)
#'
#' Implements a DCT-basis deconvolution with Tikhonov/frequency prior as advocated by
#' Gitelman et al. (2003) for forming interaction terms in neural space. Operates column-wise
#' on a T x R matrix and chooses the penalty per column by generalized cross-validation.
#'
#' @param Y numeric matrix T x R (prewhitened residuals, or basis-projected components)
#' @param h numeric vector HRF kernel (in TR units)
#' @param K integer, number of DCT components (default 64 or T/2)
#' @param method "gcv" (default) for per-column GCV lambda, or "fixed"
#' @param lambda fixed ridge if method="fixed"
#' @param q optional length-K vector of frequency prior weights (diagonal of Q); default uniform
#' @return list with U (T x R neural estimates), beta (K x R coefficients), lambda (R vector)
#' @examples
#' \dontrun{
#'   library(mppiDeconv)
#'   TR <- 2; T <- 300; t <- seq(0, (T-1))*TR
#'   h <- fmrihrf::spm_hrf(TR)  # or any HRF kernel vector
#'   Y <- matrix(rnorm(T*10), T, 10)  # 10 components or voxels
#'   out <- mppi_deconv_dct(Y, h, K = 64, method = "gcv")
#'   U   <- out$U
#' }
#' @export
mppi_deconv_dct <- function(Y, h, K = NULL, method = c("gcv","fixed"),
                            lambda = 1e-1, q = NULL) {
  stopifnot(is.matrix(Y), is.numeric(h))
  if (is.null(K)) K <- min(64L, floor(nrow(Y)/2L))
  method <- match.arg(method)
  q_in <- if (is.null(q)) NULL else as.numeric(q)
  deconv_dct_multi(Y, h = as.numeric(h), K = as.integer(K), q_in = q_in,
                   method = method, lambda_fixed = lambda)
}
</file>

<file path="R/mppi_design_interface.R">
# High-level design interface ---------------------------------------------

.mppi_null_coalesce <- function(a, b) if (!is.null(a)) a else b
.mppi_stopif <- function(cond, msg) if (!cond) stop(msg, call. = FALSE)

.mppi_as_matrix <- function(obj) {
  if (is.null(obj)) return(NULL)
  if (is.matrix(obj)) return(obj)
  if (inherits(obj, "tbl_df")) obj <- as.data.frame(obj)
  as.matrix(obj)
}

# Generics -----------------------------------------------------------------

mppi_tr <- function(x, ...) UseMethod("mppi_tr")
mppi_runs <- function(x, ...) UseMethod("mppi_runs")
mppi_psych <- function(x, ...) UseMethod("mppi_psych")
mppi_task <- function(x, ...) UseMethod("mppi_task")
mppi_nuisance <- function(x, ...) UseMethod("mppi_nuisance")
mppi_hrf <- function(x, ...) UseMethod("mppi_hrf")
mppi_pk <- function(x, ...) UseMethod("mppi_pk")
mppi_design <- function(x, ...) UseMethod("mppi_design")

mppi_tr.default <- function(x, ...) stop(sprintf("No mppi_tr() method for class %s", paste(class(x), collapse = ", ")), call. = FALSE)
mppi_runs.default <- function(x, ...) stop(sprintf("No mppi_runs() method for class %s", paste(class(x), collapse = ", ")), call. = FALSE)
mppi_psych.default <- function(x, ...) stop(sprintf("No mppi_psych() method for class %s", paste(class(x), collapse = ", ")), call. = FALSE)
mppi_task.default <- function(x, ...) stop(sprintf("No mppi_task() method for class %s", paste(class(x), collapse = ", ")), call. = FALSE)
mppi_nuisance.default <- function(x, ...) stop(sprintf("No mppi_nuisance() method for class %s", paste(class(x), collapse = ", ")), call. = FALSE)
mppi_hrf.default <- function(x, ...) NULL
mppi_pk.default <- function(x, ...) stop(sprintf("No mppi_pk() method for class %s", paste(class(x), collapse = ", ")), call. = FALSE)
mppi_design.default <- function(x, ...) stop(sprintf("No mppi_design() method for class %s", paste(class(x), collapse = ", ")), call. = FALSE)

mppi_tr.mppi_design <- function(x, ...) mppi_tr(x$event_model)

mppi_runs.mppi_design <- function(x, T = NULL, ...) {
  if (!is.null(x$runs)) return(as.integer(x$runs))
  mppi_runs(x$event_model, T = T)
}

mppi_psych.mppi_design <- function(x, T, TR = mppi_tr(x), runs = mppi_runs(x, T), ...) {
  mat <- x$X[, x$psych_idx, drop = FALSE]
  if (!is.null(T)) .mppi_stopif(nrow(mat) == T, "Design has incompatible number of rows.")
  mat
}

mppi_task.mppi_design <- function(x, ...) x$X[, x$psych_idx, drop = FALSE]

mppi_nuisance.mppi_design <- function(x, T, ...) {
  other_idx <- setdiff(seq_len(ncol(x$X)), x$psych_idx)
  if (!length(other_idx)) return(matrix(0, nrow(x$X), 0))
  mat <- x$X[, other_idx, drop = FALSE]
  if (!is.null(T)) .mppi_stopif(nrow(mat) == T, "Design has incompatible number of rows.")
  mat
}

mppi_hrf.mppi_design <- function(x, ...) mppi_hrf(x$event_model)

mppi_design.mppi_design <- function(x, T = NULL, ...) {
  TR <- mppi_tr(x)
  runs_vec <- mppi_runs(x, T)
  res <- list(TR = TR,
              runs = runs_vec,
              X_task = mppi_task(x),
              hrf = mppi_hrf(x))
  if (!is.null(T)) {
    res$S <- mppi_psych(x, T = T, TR = TR, runs = runs_vec)
    res$nuisance <- mppi_nuisance(x, T = T)
  }
  res
}

# event_model / baseline_model support ------------------------------------

mppi_tr.event_model <- function(x, ...) {
  sf <- .mppi_null_coalesce(x$sampling_frame, attr(x, "sampling_frame"))
  if (!is.null(sf) && !is.null(sf$TR)) return(as.numeric(sf$TR[1]))
  NA_real_
}

mppi_runs.event_model <- function(x, T = NULL, ...) {
  if (!requireNamespace("fmridesign", quietly = TRUE)) return(NULL)
  sf <- .mppi_null_coalesce(x$sampling_frame, attr(x, "sampling_frame"))
  if (!is.null(sf$blocklens)) {
    return(as.integer(rep(seq_along(sf$blocklens), sf$blocklens)))
  }
  if (!is.null(T)) rep_len(1L, T) else NULL
}

mppi_psych.event_model <- function(x, T, TR = mppi_tr(x), runs = mppi_runs(x, T), ...) {
  if (!requireNamespace("fmridesign", quietly = TRUE)) stop("fmridesign not available.")
  S <- .mppi_as_matrix(fmridesign::design_matrix(x))
  if (!is.null(T)) .mppi_stopif(nrow(S) == T, "event_model design has incompatible number of rows.")
  S
}

mppi_hrf.event_model <- function(x, ...) {
  if (!requireNamespace("fmridesign", quietly = TRUE)) return(NULL)
  spec <- tryCatch(fmridesign::hrf(x), error = function(e) NULL)
  if (!is.null(spec$hrf)) spec$hrf else NULL
}

mppi_tr.baseline_model <- function(x, ...) {
  sf <- .mppi_null_coalesce(x$sampling_frame, attr(x, "sampling_frame"))
  if (!is.null(sf) && !is.null(sf$TR)) return(as.numeric(sf$TR[1]))
  NA_real_
}

mppi_runs.baseline_model <- function(x, T = NULL, ...) {
  if (!requireNamespace("fmridesign", quietly = TRUE)) return(NULL)
  sf <- .mppi_null_coalesce(x$sampling_frame, attr(x, "sampling_frame"))
  if (!is.null(sf$blocklens)) return(as.integer(rep(seq_along(sf$blocklens), sf$blocklens)))
  if (!is.null(T)) rep_len(1L, T) else NULL
}

mppi_nuisance.baseline_model <- function(x, T, ...) {
  if (!requireNamespace("fmridesign", quietly = TRUE)) stop("fmridesign not available.")
  N <- .mppi_as_matrix(fmridesign::design_matrix(x))
  if (!is.null(T)) .mppi_stopif(nrow(N) == T, "baseline_model design has incompatible number of rows.")
  N
}

# fmridesign composite -----------------------------------------------------

mppi_tr.fmridesign <- function(x, ...) {
  if (!is.null(x$event_model)) return(mppi_tr(x$event_model))
  out <- .mppi_null_coalesce(attr(x, "TR"), .mppi_null_coalesce(x$TR, x$tr))
  .mppi_stopif(length(out) > 0, "fmridesign object is missing TR.")
  as.numeric(out)
}

mppi_runs.fmridesign <- function(x, T = NULL, ...) {
  if (!is.null(x$event_model)) {
    r <- mppi_runs(x$event_model, T)
    if (!is.null(r)) return(r)
  }
  r <- .mppi_null_coalesce(attr(x, "runs"), .mppi_null_coalesce(x$runs, x$run))
  if (!length(r)) {
    if (!is.null(T)) return(rep_len(1L, T))
    return(NULL)
  }
  as.integer(r)
}

mppi_psych.fmridesign <- function(x, T, TR = mppi_tr(x), runs = mppi_runs(x, T), ...) {
  if (!is.null(x$event_model)) return(mppi_psych(x$event_model, T = T, TR = TR, runs = runs))
  S <- .mppi_null_coalesce(x$S, attr(x, "S"))
  if (!is.null(S)) {
    .mppi_stopif(nrow(S) == T, "fmridesign$S has incompatible number of rows.")
    return(as.matrix(S))
  }
  stop("Unable to recover psychological design from fmridesign object.")
}

mppi_task.fmridesign <- function(x, ...) {
  if (!is.null(x$event_model)) return(mppi_psych(x$event_model, T = NULL))
  X <- .mppi_null_coalesce(x$X_task, .mppi_null_coalesce(attr(x, "X_task"), .mppi_null_coalesce(x$X, attr(x, "X"))))
  .mppi_stopif(is.matrix(X), "fmridesign object is missing task design (X_task/X).")
  as.matrix(X)
}

mppi_nuisance.fmridesign <- function(x, T, ...) {
  if (!is.null(x$baseline_model)) return(mppi_nuisance(x$baseline_model, T = T))
  N <- .mppi_null_coalesce(x$nuisance, .mppi_null_coalesce(attr(x, "nuisance"), .mppi_null_coalesce(x$confounds, attr(x, "confounds"))))
  if (is.null(N)) return(matrix(0, T, 0))
  .mppi_stopif(nrow(N) == T, "fmridesign nuisance/confounds have incompatible number of rows.")
  as.matrix(N)
}

mppi_hrf.fmridesign <- function(x, ...) {
  if (!is.null(x$event_model)) return(mppi_hrf(x$event_model))
  .mppi_null_coalesce(x$hrf, attr(x, "hrf"))
}

mppi_pk.fmridesign <- function(x, T, TR = mppi_tr(x), runs = mppi_runs(x, T),
                          center = TRUE, span_space = TRUE,
                          include_nuisance = TRUE, include_intercept = TRUE, ...) {
  if (is.null(T)) stop("pk(): 'T' (number of TRs) must be supplied.", call. = FALSE)
  S <- mppi_psych(x, T = T, TR = TR, runs = runs)
  N <- if (include_nuisance) mppi_nuisance(x, T = T) else matrix(0, T, 0)
  K <- ncol(S)
  out <- vector("list", K)
  names(out) <- colnames(S)
  for (kk in seq_len(K)) {
    s_k <- S[, kk]
    if (center) s_k <- s_k - mean(s_k)
    others <- if (span_space && K > 1) S[, setdiff(seq_len(K), kk), drop = FALSE] else NULL
    intercept_col <- if (include_intercept) matrix(1, T, 1) else NULL
    Qs <- cbind(others, N, intercept_col)
    if (ncol(Qs)) {
      qr_obj <- qr(Qs)
      s_k <- s_k - qr.fitted(qr_obj, s_k)
    }
    out[[kk]] <- as.numeric(s_k)
  }
  out
}

mppi_design.fmridesign <- function(x, T = NULL, ...) {
  TR <- mppi_tr(x)
  runs_vec <- mppi_runs(x, T)
  res <- list(TR = TR,
              runs = runs_vec,
              X_task = mppi_task(x),
              hrf = mppi_hrf(x))
  if (!is.null(T)) {
    res$S <- mppi_psych(x, T = T, TR = TR, runs = runs_vec)
    res$nuisance <- mppi_nuisance(x, T = T)
  }
  res
}

# mppi_design constructor --------------------------------------------------

as_mppi_design <- function(event, baseline = NULL, confounds = NULL,
                           include_intercept = TRUE, runs = NULL, basis = NULL) {
  if (!requireNamespace("fmridesign", quietly = TRUE)) {
    stop("fmridesign not available. Install via remotes::install_github('bbuchsbaum/fmridesign').")
  }
  event_X <- .mppi_as_matrix(fmridesign::design_matrix(event))
  event_colnames <- colnames(event_X)
  base_X <- if (!is.null(baseline)) .mppi_as_matrix(fmridesign::design_matrix(baseline)) else NULL
  conf_X <- .mppi_as_matrix(confounds)
  if (!is.null(base_X) && nrow(base_X) != nrow(event_X)) {
    stop("baseline design must have the same number of rows as the event design.")
  }
  if (!is.null(conf_X) && nrow(conf_X) != nrow(event_X)) {
    stop("confounds matrix must have the same number of rows as the event design.")
  }
  pieces <- Filter(Negate(is.null), list(base_X, conf_X))
  base_conf <- if (length(pieces)) do.call(cbind, pieces) else NULL
  X <- if (is.null(base_conf)) event_X else cbind(base_conf, event_X)
  psych_idx <- seq(ncol(X) - ncol(event_X) + 1L, ncol(X))
  if (include_intercept) {
    has_int <- any(apply(X, 2, function(col) all(abs(col - 1) < 1e-8)))
    if (!has_int) {
      X <- cbind(`(Intercept)` = 1, X)
      psych_idx <- psych_idx + 1L
    }
  }
  if (is.null(runs)) runs <- mppi_runs(event, T = nrow(event_X))
  structure(list(
    X = as.matrix(X),
    psych_idx = psych_idx,
    event_model = event,
    baseline_model = baseline,
    runs = runs,
    basis = basis
  ), class = "mppi_design")
}

mppi_model <- function(event_model, baseline_model = NULL,
                       nuisance = NULL, runs = NULL,
                       include_intercept = TRUE) {
  as_mppi_design(event = event_model, baseline = baseline_model,
                 confounds = nuisance, include_intercept = include_intercept,
                 runs = runs)
}

# Print / summary ----------------------------------------------------------

print.mppi_design <- function(x, ...) {
  cat(sprintf("mppi_design: %d time points x %d regressors (%d psychological)\n",
              nrow(x$X), ncol(x$X), length(x$psych_idx)))
  if (!is.null(colnames(x$X))) {
    preview <- head(colnames(x$X)[x$psych_idx], 5L)
    cat("Psychological columns: ", paste(preview, collapse = ", "))
    if (length(x$psych_idx) > length(preview)) cat(", ...")
    cat("\n")
  }
  invisible(x)
}
</file>

<file path="R/mppi_fit_whitened.R">
# Prewhitened estimator (fmriAR) ------------------------------------------

#' mPPI with fmriAR prewhitening
#' @param Y T x V data
#' @param X T x q design
#' @param runs vector of run labels (length T)
#' @param psych_idx indices of psychological columns
#' @param ar_method "ar" or "arma"; @param p AR order or "auto"
mppi_fit_whitened <- function(Y, X, runs, psych_idx,
                              ar_method = "ar", p = "auto",
                              zero_diag = TRUE, scale = c("cov","corr"),
                              center_by = c("none","run"), na_action = c("omit_tr","error"),
                              backend = c("blas","accumulate","chunked"), chunk_size = NULL,
                              packed = FALSE, basis = NULL,
                              domain = c("bold","neural"),
                              project_backend = c("blas","chunked"), project_chunk_cols = NULL,
                              lags = 0L, lag_blocklens = NULL) {
  if (!requireNamespace("fmriAR", quietly = TRUE)) {
    stop("fmriAR not available. Install via remotes::install_github('bbuchsbaum/fmriAR').")
  }
  stopifnot(length(runs) == nrow(Y), nrow(X) == nrow(Y))
  scale <- match.arg(scale)
  domain <- match.arg(domain)
  center_by <- match.arg(center_by)
  na_action <- match.arg(na_action)
  backend <- match.arg(backend)
  project_backend <- match.arg(project_backend)
  # Initial residuals for noise fit
  qrX <- qr(X)
  res  <- Y - X %*% qr.coef(qrX, Y)
  plan <- fmriAR::fit_noise(res, runs = runs, method = ar_method, p = p)
  xyw  <- fmriAR::whiten_apply(plan, X = X, Y = Y, runs = runs)
  mppi_fit(Y = xyw$Y, X = xyw$X, psych_idx = psych_idx, runs = runs,
           zero_diag = zero_diag, scale = scale,
           center_by = center_by, na_action = na_action,
           backend = backend, chunk_size = chunk_size, packed = packed,
           basis = basis, project_backend = project_backend,
           project_chunk_cols = project_chunk_cols,
           domain = domain,
           lags = lags, lag_blocklens = lag_blocklens)
}
</file>

<file path="R/mppi_fit.R">
# Core estimators ----------------------------------------------------------

.mppi_prepare_fit_inputs <- function(Y, X, psych_idx, runs = NULL,
                                     basis = NULL,
                                     na_action = c("omit_tr", "error")) {
  stopifnot(is.matrix(Y), is.matrix(X))
  if (is.null(psych_idx) || !length(psych_idx)) {
    stop("psych_idx must be a non-empty vector of column indices.", call. = FALSE)
  }
  if (!is.null(runs) && length(runs) != nrow(Y)) {
    stop("Length of 'runs' must match number of rows in Y.", call. = FALSE)
  }
  na_action <- match.arg(na_action)
  design_prep <- .mppi_prepare_design_matrix(X, psych_idx)
  X_use <- design_prep$X
  p_idx <- design_prep$psych_idx
  prep <- .mppi_handle_na(Y, X_use, runs, na_action = na_action)
  basis_info <- .mppi_check_basis(basis, ncol(prep$Y))
  list(
    Y = prep$Y,
    X = prep$X,
    runs = prep$runs,
    psych_idx = p_idx,
    base_idx = setdiff(seq_len(ncol(prep$X)), p_idx),
    dropped = prep$dropped,
    dropped_idx = prep$dropped_idx,
    basis = basis_info
  )
}

.mppi_resolve_deconv_config <- function(domain, deconv, default_tr = 1,
                                        default_duration = 32,
                                        default_oversample = 1) {
  if (!identical(domain, "neural")) {
    return(list(active = FALSE, domain = "bold"))
  }
  cfg <- if (is.null(deconv)) list() else deconv
  tr_val <- cfg$tr
  if (is.null(tr_val)) tr_val <- cfg$TR
  if (is.null(tr_val)) tr_val <- default_tr
  duration_val <- cfg$duration
  if (is.null(duration_val)) duration_val <- default_duration
  oversample_val <- cfg$oversample
  if (is.null(oversample_val)) oversample_val <- default_oversample
  hrf_input <- cfg$hrf
  if (is.function(hrf_input)) {
    hrf_vec <- as.numeric(hrf_input(tr = tr_val, duration = duration_val, oversample = oversample_val))
  } else if (is.null(hrf_input)) {
    hrf_vec <- mppi_default_hrf(tr = tr_val, duration = duration_val, oversample = oversample_val)
  } else {
    hrf_vec <- as.numeric(hrf_input)
  }
  if (!length(hrf_vec) || any(!is.finite(hrf_vec))) {
    stop("Resolved HRF for neural domain must be finite and non-empty.", call. = FALSE)
  }
  list(
    active = TRUE,
    domain = "neural",
    type = tolower(cfg$type %||% "dct"),
    hrf = hrf_vec,
    tr = tr_val,
    duration = duration_val,
    oversample = oversample_val,
    groups = cfg$groups,
    lambda = cfg$lambda,
    method = cfg$method,
    K = cfg$K,
    q = cfg$q,
    sticks = cfg$psych
  )
}

#' Matrix-PPI estimator from raw matrices
#' @param Y T x V matrix of time series (preprocessed)
#' @param X T x q design matrix (intercept + confounds + psychological mains)
#' @param psych_idx integer indices of psychological columns in X
#' @param zero_diag logical; zero the diagonal of ΔΣ
#' @param scale "cov" (default) or "corr" to standardize R to unit SD
#' @param lags Integer vector of lags τ to compute (τ = 0 yields contemporaneous slopes).
#' @param lag_blocklens Optional run lengths for lagged computations when `runs` is unavailable.
#' @return list with contemporaneous and lagged slope matrices plus residual metadata.
mppi_fit <- function(Y, X, psych_idx, runs = NULL,
                     zero_diag = TRUE, scale = c("cov","corr"),
                     center_by = c("none","run"), na_action = c("omit_tr","error"),
                     backend = c("blas","accumulate","chunked"), packed = FALSE,
                     chunk_size = NULL, basis = NULL,
                     project_backend = c("blas","chunked"), project_chunk_cols = NULL,
                     domain = c("bold","neural"), deconv = NULL,
                     lags = 0L, lag_blocklens = NULL) {
  stopifnot(is.matrix(Y), is.matrix(X))
  scale <- match.arg(scale)
  center_by <- match.arg(center_by)
  na_action_choice <- match.arg(na_action)
  backend <- match.arg(backend)
  project_backend_choice <- match.arg(project_backend)
  domain <- match.arg(domain)

  inputs <- .mppi_prepare_fit_inputs(Y, X, psych_idx, runs = runs,
                                     basis = basis, na_action = na_action_choice)
  Y <- inputs$Y
  X <- inputs$X
  runs <- inputs$runs
  p_idx <- sort(unique(inputs$psych_idx))
  base_idx <- inputs$base_idx
  Tn <- nrow(X)
  stopifnot(nrow(Y) == Tn)
  basis_info <- inputs$basis
  if (center_by == "run" && is.null(runs)) {
    warning("center_by='run' requested but 'runs' is NULL; skipping run centering.", call. = FALSE)
    center_by <- "none"
  }
  project_backend <- if (is.null(basis_info)) "blas" else project_backend_choice
  lags <- sort(unique(as.integer(lags)))
  if (!length(lags)) lags <- 0L
  if (!0L %in% lags) lags <- c(0L, lags)
  if (!is.null(lag_blocklens)) {
    lag_blocklens <- as.integer(lag_blocklens)
    if (any(lag_blocklens <= 0)) {
      stop("lag_blocklens must contain positive lengths.", call. = FALSE)
    }
    if (sum(lag_blocklens) != Tn) {
      stop("Sum of lag_blocklens must match number of usable time points.", call. = FALSE)
    }
  } else if (!is.null(runs)) {
    lag_blocklens <- rle(runs)$lengths
  }

  R <- .mppi_residualize(Y, X)
  if (!is.null(basis_info)) {
    R_unscaled <- .mppi_project_basis(R, basis_info$V, backend = project_backend,
                                      chunk_cols = project_chunk_cols)
  } else {
    R_unscaled <- R
  }
  R_work <- R_unscaled
  sigma_unscaled <- matrixStats::colSds(R_unscaled)
  deconv_cfg <- .mppi_resolve_deconv_config(domain, deconv)
  deconv_info <- list(domain = domain)

  denom_warn <- function(name) {
    warning(sprintf("Regressor '%s' has near-zero variance after residualization; returning NA matrix.",
                    name), call. = FALSE)
  }

  pNms <- if (is.null(colnames(X))) paste0("psych", seq_along(p_idx)) else colnames(X)[p_idx]
  deconv_psych <- NULL
  neural_lambda <- NULL
  n_psych <- length(p_idx)
  if (isTRUE(deconv_cfg$active)) {
    groups <- deconv_cfg$groups
    if (is.null(groups)) {
      groups <- tryCatch(mppi_group_hrf_columns(X[, p_idx, drop = FALSE]),
                         error = function(e) NULL)
    }
    deconv_type <- tolower(deconv_cfg$type %||% "dct")
    if (identical(deconv_type, "map")) {
      lambda_map <- deconv_cfg$lambda
      if (is.null(lambda_map)) lambda_map <- 10
      R_unscaled <- mppi_deconv(R_unscaled, TR = deconv_cfg$tr, hrf = deconv_cfg$hrf, lambda = lambda_map)
      R_work <- R_unscaled
      if (is.null(deconv_cfg$sticks)) {
        S_map <- mppi_deconv(X[, p_idx, drop = FALSE], TR = deconv_cfg$tr, hrf = deconv_cfg$hrf, lambda = lambda_map)
        if (!is.null(groups)) {
          grp_names <- character(length(groups))
          Slist <- vector("list", length(groups))
          for (g in seq_along(groups)) {
            idx <- intersect(groups[[g]], seq_len(ncol(S_map)))
            if (!length(idx)) stop("Empty group in 'groups'.")
            Ug <- S_map[, idx, drop = FALSE]
            norms <- sqrt(colSums(Ug^2)); norms[norms == 0] <- 1
            Ug <- sweep(Ug, 2, norms, "/")
            Slist[[g]] <- rowMeans(Ug)
            if (!is.null(colnames(X))) {
              grp_names[g] <- paste0("s:", paste(colnames(X)[p_idx][idx], collapse = "+"))
            } else {
              grp_names[g] <- paste0("s:grp", g)
            }
          }
          deconv_psych <- do.call(cbind, Slist)
          colnames(deconv_psych) <- grp_names
        } else {
          deconv_psych <- S_map
          colnames(deconv_psych) <- if (!is.null(colnames(X))) paste0("s:", colnames(X)[p_idx]) else paste0("s", seq_len(ncol(S_map)))
        }
        for (ii in seq_len(ncol(deconv_psych))) {
          Qs <- cbind(1, deconv_psych[, setdiff(seq_len(ncol(deconv_psych)), ii), drop = FALSE])
          deconv_psych[, ii] <- deconv_psych[, ii] - Qs %*% qr.coef(qr(Qs), deconv_psych[, ii])
        }
        pNms <- colnames(deconv_psych)
      } else {
        deconv_psych <- as.matrix(deconv_cfg$sticks)
        if (nrow(deconv_psych) != nrow(X)) stop("deconv$psych must have same rows as design.")
        if (!is.null(colnames(deconv_psych))) pNms <- colnames(deconv_psych)
      }
      neural_lambda <- rep(lambda_map, ncol(deconv_psych))
      n_psych <- ncol(deconv_psych)
      deconv_info <- c(deconv_info,
                       list(type = "map", lambda = lambda_map, lambda_psych = neural_lambda,
                            hrf = deconv_cfg$hrf, groups = groups, psych_names = pNms,
                            tr = deconv_cfg$tr, duration = deconv_cfg$duration,
                            oversample = deconv_cfg$oversample,
                            sticks = deconv_psych))
    } else {
      K <- deconv_cfg$K
      if (is.null(K)) K <- min(64L, floor(nrow(R_unscaled) / 2L))
      method_deconv <- deconv_cfg$method
      if (is.null(method_deconv)) method_deconv <- "gcv"
      lambda_fixed <- deconv_cfg$lambda
      if (is.null(lambda_fixed)) lambda_fixed <- 1e-1
      q_vec <- deconv_cfg$q
      dec_out <- mppi_deconv_dct(R_unscaled, h = deconv_cfg$hrf, K = K,
                                 method = method_deconv, lambda = lambda_fixed, q = q_vec)
      R_unscaled <- dec_out$U
      R_work <- R_unscaled
      if (is.null(deconv_cfg$sticks)) {
        ps <- mppi_psych_neural_from_X(X, p_idx, h = deconv_cfg$hrf, K = K,
                                       method = method_deconv, lambda = lambda_fixed,
                                       groups = groups)
        deconv_psych <- ps$S
        pNms <- ps$names
        neural_lambda <- ps$lambda
      } else {
        deconv_psych <- as.matrix(deconv_cfg$sticks)
        if (nrow(deconv_psych) != nrow(X)) stop("deconv$psych must have same rows as design.")
        if (!is.null(colnames(deconv_psych))) pNms <- colnames(deconv_psych)
      }
      n_psych <- ncol(deconv_psych)
      deconv_info <- c(deconv_info,
                       list(type = "dct", method = method_deconv, K = K, lambda = dec_out$lambda,
                            lambda_psych = neural_lambda, hrf = deconv_cfg$hrf, q = q_vec,
                            groups = groups, psych_names = pNms, tr = deconv_cfg$tr,
                            duration = deconv_cfg$duration, oversample = deconv_cfg$oversample,
                            sticks = deconv_psych))
    }
  }

  if (scale == "corr") {
    s <- matrixStats::colSds(R_work)
    s[s == 0] <- 1
    R_work <- sweep(R_work, 2, s, "/")
  }

  out  <- vector("list", n_psych)
  pks  <- vector("list", n_psych)
  denoms <- numeric(n_psych)

  if (isTRUE(deconv_cfg$active)) {
    idx_seq <- seq_len(n_psych)
    for (ii in idx_seq) {
      sk <- deconv_psych[, ii]
      S_neural <- cbind(X[, base_idx, drop = FALSE],
                        if (n_psych > 1) deconv_psych[, setdiff(idx_seq, ii), drop = FALSE] else NULL)
      if (is.null(S_neural) || ncol(S_neural) == 0) {
        pk <- sk
      } else {
        pk <- .mppi_residualize_vec(sk, as.matrix(S_neural))
      }
      if (center_by == "run" && !is.null(runs)) {
        pk <- .mppi_center_by_run(pk, runs)
      }
      denom <- sum(pk^2)
      denoms[ii] <- denom
      if (denom < .Machine$double.eps) {
        denom_warn(pNms[ii])
        mat_dim <- if (is.null(basis_info)) ncol(Y) else basis_info$r
        naMat <- matrix(NA_real_, mat_dim, mat_dim)
        Dk <- if (packed) .mppi_pack_upper(naMat) else naMat
      } else {
        Dfull <- .mppi_crossprod(R_work, pk, backend = backend, chunk_size = chunk_size) / denom
        if (zero_diag) diag(Dfull) <- 0
        Dk <- if (packed) .mppi_pack_upper(Dfull) else Dfull
      }
      out[[ii]] <- Dk
      pks[[ii]] <- pk
    }
  } else {
    for (ii in seq_len(n_psych)) {
      k  <- p_idx[ii]
      Q  <- X[, c(base_idx, setdiff(p_idx, k)), drop = FALSE]
      pk <- .mppi_residualize_vec(X[, k], Q)
      if (center_by == "run" && !is.null(runs)) {
        pk <- .mppi_center_by_run(pk, runs)
      }
      denom <- sum(pk^2)
      denoms[ii] <- denom
      if (denom < .Machine$double.eps) {
        denom_warn(pNms[ii])
        mat_dim <- if (is.null(basis_info)) ncol(Y) else basis_info$r
        naMat <- matrix(NA_real_, mat_dim, mat_dim)
        Dk <- if (packed) .mppi_pack_upper(naMat) else naMat
      } else {
        Dfull <- .mppi_crossprod(R_work, pk, backend = backend, chunk_size = chunk_size) / denom
        if (zero_diag) diag(Dfull) <- 0
        Dk <- if (packed) .mppi_pack_upper(Dfull) else Dfull
      }
      out[[ii]] <- Dk
      pks[[ii]] <- pk
    }
  }
  names(out) <- pNms
  names(pks) <- pNms
  names(denoms) <- pNms
  lag_store <- setNames(vector("list", length(out)), pNms)
  nonzero_lags <- setdiff(lags, 0L)
  for (ii in seq_along(out)) {
    lag_list <- list()
    lag_list[["0"]] <- out[[ii]]
    if (length(nonzero_lags)) {
      pk_vec <- pks[[ii]]
      for (lg in nonzero_lags) {
        Mk_lag <- .mppi_crossprod_lagged(R_work, pk_vec, lg,
                                         blocklens = lag_blocklens,
                                         backend = backend, chunk_size = chunk_size)
        if (!all(is.na(Mk_lag))) {
          if (zero_diag) diag(Mk_lag) <- 0
        }
        Mk_obj <- if (packed) .mppi_pack_upper(Mk_lag) else Mk_lag
        lag_list[[as.character(lg)]] <- Mk_obj
      }
    }
    lag_store[[ii]] <- lag_list
  }
  cov_matrix_source <- if (scale == "corr") R_work else R_unscaled
  Sigma0 <- crossprod(cov_matrix_source) / nrow(cov_matrix_source)
  partial_lambda <- 1e-3
  var_list <- NULL
  partial_list <- NULL
  Theta0 <- NULL
  if (scale == "cov") {
    Theta0 <- solve(Sigma0 + partial_lambda * diag(ncol(Sigma0)))
    var_list <- vector("list", length(out))
    partial_list <- vector("list", length(out))
    for (ii in seq_along(out)) {
      Delta_full <- if (packed) .mppi_unpack_upper(out[[ii]]) else out[[ii]]
      if (all(is.na(Delta_full))) {
        var_list[ii] <- list(NULL)
        partial_list[ii] <- list(NULL)
        next
      }
      dec <- mppi_decompose_variance(R_unscaled, pks[[ii]], Delta_full)
      var_list[[ii]] <- dec
      DeltaTheta <- mppi_to_partial(Sigma0, Delta_full, lambda = partial_lambda)
      partial_list[[ii]] <- list(DeltaTheta = DeltaTheta,
                                 DeltaRho = mppi_delta_partial(Theta0, DeltaTheta))
    }
    names(var_list) <- pNms
    names(partial_list) <- pNms
  }
  if (!is.null(basis_info)) {
    basis_info$project_backend <- project_backend
    basis_info$project_chunk_cols <- project_chunk_cols
  }
  res <- list(Delta = out, names = pNms, R = R_work, R_raw = R_unscaled,
              sigma = sigma_unscaled, pk = pks,
              scale = scale, dropped = inputs$dropped, center_by = center_by,
              runs = runs, denom = denoms, backend = backend,
              n_used = nrow(R_work), Sigma0 = Sigma0, partial_lambda = partial_lambda,
              Theta0 = Theta0, variance = var_list, partial = partial_list,
              lags = lags, lagged = lag_store, lag_blocklens = lag_blocklens,
              AIC_total = rep(NA_real_, length(out)),
              packed = packed, chunk_size = chunk_size, basis = basis_info,
              project_backend = project_backend,
              project_chunk_cols = project_chunk_cols,
              domain = domain, deconv = deconv_info)
  if (!is.null(basis_info)) res$Z <- R_work
  if (identical(domain, "neural")) res$U <- R_unscaled
  if (!is.null(res$AIC_total)) names(res$AIC_total) <- pNms
  class(res) <- c("mppi_fit", "list")
  res
}

#' Convenience wrapper when using fmrireg objects
#' @param fmodel fmri_model (from fmrireg)
#' @param dataset fmrireg dataset supplying Y
#' @param psych regex patterns or indices
#' @param scale "cov" or "corr"
mppi_fit_from_fmrireg <- function(fmodel, dataset, psych, scale = c("cov","corr"), zero_diag = TRUE,
                                  runs = NULL, center_by = c("none","run"), na_action = c("omit_tr","error"),
                                  backend = c("blas","accumulate","chunked"), chunk_size = NULL,
                                  packed = FALSE, basis = NULL,
                                  project_backend = c("blas","chunked"), project_chunk_cols = NULL,
                                  domain = c("bold","neural"), deconv = NULL,
                                  lags = 0L, lag_blocklens = NULL) {
  if (!requireNamespace("fmrireg", quietly = TRUE)) {
    stop("fmrireg not available. Install via remotes::install_github('bbuchsbaum/fmrireg').")
  }
  X <- fmrireg::design_matrix(fmodel)
  if (is.null(colnames(X)) && is.character(psych)) stop("Design has no column names; supply indices for 'psych'.")
  pidx <- if (is.numeric(psych)) psych else mppi_select_psych(X, patterns = psych)
  Y <- fmrireg::get_data_matrix(dataset)
  mppi_fit(Y, X, pidx, runs = runs, zero_diag = zero_diag, scale = match.arg(scale),
           center_by = match.arg(center_by), na_action = match.arg(na_action),
           backend = match.arg(backend), packed = packed, chunk_size = chunk_size,
           basis = basis, project_backend = match.arg(project_backend),
           project_chunk_cols = project_chunk_cols,
           domain = match.arg(domain), deconv = deconv,
           lags = lags, lag_blocklens = lag_blocklens)
}
</file>

<file path="R/mppi_fuse.R">
# Fusion of time-domain and beta-domain -----------------------------------

#' Precision-weighted fusion of ΔΣ maps from time and trial domains
#' @param D_time VxV matrix
#' @param D_beta VxV matrix
#' @param var_time scalar variance estimate for D_time (use omnibus null var)
#' @param var_beta scalar variance estimate for D_beta
mppi_fuse_time_beta <- function(D_time, D_beta, var_time, var_beta) {
  w_t <- 1/var_time; w_b <- 1/var_beta
  (w_t*D_time + w_b*D_beta) / (w_t + w_b)
}
</file>

<file path="R/mppi_group_ebayes.R">
# Group-level empirical Bayes (limma) -------------------------------------

#' Moderated one-sample tests on vectorized ΔΣ across subjects
#' @param Delta_list list of VxV matrices (same V), one per subject
#' @param use_limma logical; if TRUE and limma present, use eBayes
#' @return list with t, p, and (if limma) moderated stats
mppi_group_ebayes <- function(Delta_list, use_limma = TRUE) {
  stopifnot(is.list(Delta_list), length(Delta_list) >= 2)
  V <- nrow(Delta_list[[1]])
  U <- upper.tri(matrix(0, V, V), diag = FALSE)
  X <- do.call(rbind, lapply(Delta_list, function(D) as.numeric(D[U])))
  # One-sample vs zero
  if (use_limma && requireNamespace("limma", quietly = TRUE)) {
    design <- cbind(Intercept = 1)
    fit <- limma::lmFit(t(X), design)
    fit <- limma::eBayes(fit)
    tstat <- fit$t[,1]; pval <- fit$p.value[,1]
  } else {
    m <- colMeans(X); s <- apply(X, 2, sd); n <- nrow(X)
    tstat <- m / (s / sqrt(n))
    # two-sided p-values using Student t with n-1 df
    pval <- 2*pt(-abs(tstat), df = n-1)
  }
  list(t = tstat, p = pval, idx_upper = which(U, arr.ind = FALSE), V = V)
}
#' Stack subject-level ΔΣ matrices into an edge matrix
#' @param fits List of `mppi_fit` objects (one per subject).
#' @param k Regressor index or name to extract.
#' @param lag Integer lag τ to extract (defaults to contemporaneous, τ = 0).
#' @param include_diag Logical; include diagonal elements when stacking.
#' @return Object of class `mppi_stack` with the stacked matrix and edge metadata.
#' @export
mppi_stack <- function(fits, k = 1L, lag = 0L, include_diag = FALSE) {
  stopifnot(is.list(fits), length(fits) >= 1)
  lag <- as.integer(lag)
  first <- fits[[1]]
  Mk0 <- mppi_get_M_lag(first, k, lag)
  dims <- dim(Mk0)
  mask <- upper.tri(Mk0, diag = include_diag)
  edges <- which(mask, arr.ind = TRUE)
  edge_labels <- apply(edges, 1, function(idx) {
    rn <- rownames(Mk0); cn <- colnames(Mk0)
    left <- if (!is.null(rn)) rn[idx[1]] else idx[1]
    right <- if (!is.null(cn)) cn[idx[2]] else idx[2]
    paste(left, right, sep = "|")
  })
  stack_mat <- matrix(NA_real_, nrow = length(fits), ncol = sum(mask))
  for (i in seq_along(fits)) {
    Mk <- mppi_get_M_lag(fits[[i]], k, lag)
    if (!all(dim(Mk) == dims)) {
      stop("All fits must have matching matrix dimensions.", call. = FALSE)
    }
    stack_mat[i, ] <- Mk[mask]
  }
  subj_names <- names(fits)
  if (is.null(subj_names)) subj_names <- paste0("subj", seq_along(fits))
  rownames(stack_mat) <- subj_names
  colnames(stack_mat) <- edge_labels
  res <- list(matrix = stack_mat,
              edges = edges,
              mask = mask,
              lag = lag,
              include_diag = include_diag,
              regressor = if (is.character(k)) k else first$names[as.integer(k)],
              dimension = dims,
              subjects = subj_names)
  class(res) <- c("mppi_stack", "list")
  res
}

#' Group-level GLM/limma inference on stacked ΔΣ edges
#' @param fits Either an `mppi_stack` object or list of `mppi_fit` objects.
#' @param design Design matrix (subjects × predictors).
#' @param contrast Optional contrast vector (length = ncol(design)).
#' @param coef Optional coefficient index/name when `contrast` is `NULL`.
#' @param method Fitting backend: `"limma"` (default) or plain `"lm"`.
#' @param k Regressor index/name (used when `fits` is a list of fits).
#' @param lag Lag τ to analyse (passed to `mppi_stack`).
#' @param include_diag Logical; include diagonal elements when stacking.
#' @param adjust Multiple-comparison correction method for `p.adjust`.
#' @return Data frame with edge-level estimates, test statistics, p- and q-values.
#' @export
mppi_group_glm <- function(fits, design, contrast = NULL, coef = NULL,
                           method = c("limma", "lm"), k = 1L, lag = 0L,
                           include_diag = FALSE, adjust = "fdr") {
  method <- match.arg(method)
  stack_obj <- if (inherits(fits, "mppi_stack")) {
    fits
  } else {
    mppi_stack(fits, k = k, lag = lag, include_diag = include_diag)
  }
  Y <- stack_obj$matrix
  design <- as.matrix(design)
  if (nrow(design) != nrow(Y)) {
    stop("design must have one row per subject in the stack.", call. = FALSE)
  }
  subj_names <- stack_obj$subjects
  if (!is.null(subj_names)) {
    rownames(Y) <- subj_names
    if (!is.null(rownames(design))) {
      idx <- match(subj_names, rownames(design))
      if (any(is.na(idx))) stop("Design rows must be named for all subjects in the stack.", call. = FALSE)
      design <- design[idx, , drop = FALSE]
    }
  }
  edge_labels <- colnames(Y)
  edges <- stack_obj$edges
  if (!is.null(contrast)) {
    contrast <- as.numeric(contrast)
    if (length(contrast) != ncol(design)) {
      stop("contrast must have length equal to ncol(design).", call. = FALSE)
    }
  }
  if (!is.null(coef) && !is.null(contrast)) {
    warning("Ignoring 'coef' because 'contrast' was supplied.", call. = FALSE)
    coef <- NULL
  }
  if (method == "limma") {
    if (!requireNamespace("limma", quietly = TRUE)) {
      stop("limma package is required for method='limma'.", call. = FALSE)
    }
    fit <- limma::lmFit(t(Y), design)
    if (!is.null(contrast)) {
      fit <- limma::contrasts.fit(fit, contrast)
      fit <- limma::eBayes(fit)
      beta <- fit$coefficients[, 1, drop = TRUE]
      tstat <- fit$t[, 1, drop = TRUE]
      pval <- fit$p.value[, 1, drop = TRUE]
    } else {
      coef_idx <- if (is.null(coef)) ncol(design) else {
        if (is.character(coef)) match(coef, colnames(design)) else as.integer(coef)
      }
      if (is.na(coef_idx) || coef_idx < 1 || coef_idx > ncol(design)) {
        stop("Invalid 'coef' specification for limma output.", call. = FALSE)
      }
      fit <- limma::eBayes(fit)
      beta <- fit$coefficients[, coef_idx]
      tstat <- fit$t[, coef_idx]
      pval <- fit$p.value[, coef_idx]
    }
    estimate <- beta
    df_val <- if (length(fit$df.total) == 1) fit$df.total else fit$df.total[1]
  } else {
    qrX <- qr(design)
    if (qrX$rank < ncol(design)) {
      stop("Design matrix is rank deficient.", call. = FALSE)
    }
    beta_mat <- qr.coef(qrX, Y)
    resid <- Y - design %*% beta_mat
    df_val <- nrow(Y) - qrX$rank
    sigma2 <- colSums(resid^2) / df_val
    XtX_inv <- chol2inv(qr.R(qrX))
    if (!is.null(contrast)) {
      cvec <- contrast
    } else {
      coef_idx <- if (is.null(coef)) ncol(design) else {
        if (is.character(coef)) match(coef, colnames(design)) else as.integer(coef)
      }
      if (is.na(coef_idx) || coef_idx < 1 || coef_idx > ncol(design)) {
        stop("Invalid 'coef' specification for lm output.", call. = FALSE)
      }
      cvec <- rep(0, ncol(design)); cvec[coef_idx] <- 1
    }
    estimate <- as.numeric(cvec %*% beta_mat)
    var_c <- as.numeric(t(cvec) %*% XtX_inv %*% cvec)
    se <- sqrt(pmax(var_c, 0) * sigma2)
    zero_var <- se == 0
    se[zero_var] <- NA_real_
    tstat <- estimate / se
    pval <- 2 * stats::pt(-abs(tstat), df = df_val)
  }
  padj <- stats::p.adjust(pval, method = adjust)
  result <- data.frame(edge = edge_labels,
                       i = edges[, 1],
                       j = edges[, 2],
                       estimate = estimate,
                       statistic = tstat,
                       df = rep(df_val, length(estimate)),
                       p = pval,
                       q = padj,
                       lag = stack_obj$lag,
                       regressor = stack_obj$regressor,
                       stringsAsFactors = FALSE)
  attr(result, "stack") <- stack_obj
  attr(result, "method") <- method
  result
}
</file>

<file path="R/mppi_helpers.R">
# Helper utilities -----------------------------------------------------------

# Internal lower-triangle vectoriser
.mppi_vec_lower <- function(M, diag = FALSE) {
  if (!is.matrix(M)) stop("Expected a matrix input.", call. = FALSE)
  M[lower.tri(M, diag = diag)]
}

.mppi_sym <- function(M) 0.5 * (M + t(M))

.mppi_asym <- function(M) 0.5 * (M - t(M))

.mppi_frob <- function(M) sqrt(sum(M * M, na.rm = TRUE))

.mppi_safe_pos <- function(x, eps = 1e-12) {
  x[is.na(x)] <- 0
  x[x < eps] <- eps
  x
}

.mppi_effective_rank <- function(M) {
  if (!is.matrix(M)) stop("Expected a matrix input.", call. = FALSE)
  sv <- suppressWarnings(svd(M, nu = 0L, nv = 0L)$d)
  if (!length(sv)) return(0)
  sv <- abs(sv)
  total <- sum(sv)
  if (!is.finite(total) || total <= 0) return(0)
  p <- sv / total
  p <- p[p > 0]
  if (!length(p)) return(0)
  exp(-sum(p * log(.mppi_safe_pos(p))))
}

.mppi_first_eigvec <- function(S) {
  if (!is.matrix(S)) stop("Expected a matrix input.", call. = FALSE)
  eig <- suppressWarnings(eigen(.mppi_sym(S), symmetric = TRUE))
  eig$vectors[, 1, drop = FALSE]
}

# Parametric psychological modulators ----------------------------------------

#' Build parametric psychological vectors for multi-condition gPPI
#'
#' @param fd `fmridesign` object supplying design information
#' @param T integer number of TRs (rows)
#' @param mods named list of numeric vectors (length `T`) containing trial-wise modulators
#' @param select optional regular expression to restrict conditions (columns of `psych(fd, ...)`)
#' @param center logical; demean each modulator within run
#' @param span_space logical; residualize against other conditions (gPPI default)
#' @param use_nuisance logical; include nuisance regressors when residualising
#' @param include_intercept logical; include an intercept during residualisation
#' @return named list of vectors ready to append to `pk()` output
#' @export
mppi_parametric <- function(fd, T, mods,
                            select = NULL,
                            center = TRUE,
                            span_space = TRUE,
                            use_nuisance = TRUE,
                            include_intercept = TRUE) {
  if (!inherits(fd, c("fmridesign", "event_model", "mppi_design"))) {
    stop("fd must be an fmridesign/event_model/mppi_design object.", call. = FALSE)
  }
  if (!is.list(mods) || !length(mods)) stop("mods must be a non-empty named list.", call. = FALSE)
  runs <- tryCatch(mppi_runs(fd, T = T), error = function(e) NULL)
  TR <- tryCatch(mppi_tr(fd), error = function(e) NULL)
  if (is.null(runs)) runs <- rep_len(1L, T)
  if (is.null(TR) || !is.finite(TR)) TR <- 1
  S <- mppi_psych(fd, T = T, TR = TR, runs = runs)
  if (!is.null(select)) {
    keep <- grepl(select, colnames(S))
    if (!any(keep)) stop("No psychological regressors match 'select'.", call. = FALSE)
    S <- S[, keep, drop = FALSE]
  }
  if (!ncol(S)) return(list())
  N <- if (use_nuisance) tryCatch(mppi_nuisance(fd, T = T), error = function(e) matrix(0, T, 0)) else matrix(0, T, 0)
  out <- list()
  for (mname in names(mods)) {
    v <- mods[[mname]]
    if (length(v) != T) stop(sprintf("Modulator '%s' has length %d (expected %d).", mname, length(v), T), call. = FALSE)
    v <- as.numeric(v)
    if (center) v <- .mppi_center_by_run(v, runs)
    for (j in seq_len(ncol(S))) {
      s_col <- S[, j]
      pk_vec <- s_col * v
      others <- if (span_space && ncol(S) > 1) S[, -j, drop = FALSE] else NULL
      Xres <- cbind(others, if (ncol(N)) N else NULL,
                    if (include_intercept) matrix(1, T, 1) else NULL)
      if (ncol(Xres)) {
        pk_vec <- pk_vec - qr.fitted(qr(Xres), pk_vec)
      }
      out[[paste0(colnames(S)[j], "::", mname)]] <- as.numeric(pk_vec)
    }
  }
  out
}

# Communication reinstatement -------------------------------------------------

#' Encode/recall reinstatement of task-gated connectivity patterns
#'
#' @param fit `mppi_fit` object
#' @param enc_pattern regex identifying encoding conditions
#' @param rec_pattern regex identifying recall conditions
#' @param mode interaction scale (`"normalized"`, `"amplitude"`, or `"raw"`)
#' @param id_fun function mapping condition names to identity labels
#' @return list with within-identity, between-identity similarities and their contrast
#' @export
mppi_reinstatement <- function(fit,
                               enc_pattern = "^enc_",
                               rec_pattern = "^rec_",
                               mode = c("normalized", "amplitude", "raw"),
                               id_fun = function(s) sub(".*?(\\d+)$", "\\1", s)) {
  mode <- match.arg(mode)
  if (!inherits(fit, "mppi_fit")) stop("fit must be an mppi_fit object.", call. = FALSE)
  cond_names <- fit$names %||% paste0("k", seq_along(fit$Delta))
  enc_names <- grep(enc_pattern, cond_names, value = TRUE)
  rec_names <- grep(rec_pattern, cond_names, value = TRUE)
  if (!length(enc_names) || !length(rec_names)) {
    stop("No encoding/recall conditions matched the supplied patterns.", call. = FALSE)
  }
  enc_ids <- setNames(enc_names, vapply(enc_names, id_fun, character(1)))
  rec_ids <- setNames(rec_names, vapply(rec_names, id_fun, character(1)))
  common <- intersect(names(enc_ids), names(rec_ids))
  if (!length(common)) {
    stop("No shared identities between encoding and recall conditions.", call. = FALSE)
  }
  vec_lower <- function(name) {
    Mk <- mppi_get_M_scaled(fit, name, mode = mode)
    .mppi_vec_lower(Mk, diag = FALSE)
  }
  within <- vapply(common, function(id) {
    enc_vec <- vec_lower(enc_ids[[id]])
    rec_vec <- vec_lower(rec_ids[[id]])
    stats::cor(enc_vec, rec_vec, use = "pairwise.complete.obs")
  }, numeric(1))
  between <- numeric(0)
  if (length(common) > 1) {
    comb <- utils::combn(common, 2L)
    between <- apply(comb, 2L, function(pair) {
      enc_vec <- vec_lower(enc_ids[[pair[1]]])
      rec_vec <- vec_lower(rec_ids[[pair[2]]])
      stats::cor(enc_vec, rec_vec, use = "pairwise.complete.obs")
    })
  }
  list(within = within,
       between = between,
       stat = mean(within, na.rm = TRUE) - mean(between, na.rm = TRUE))
}

# Trial-level sdPPI summaries -------------------------------------------------

#' Trial-level state-dependent PPI summaries
#'
#' @param fit `mppi_fit` object
#' @param fd `fmridesign` supplying event sticks (used to locate trials)
#' @param select optional regex restricting conditions
#' @param pre_window number of TRs before event onset for baseline features
#' @param lags integer lags for routing index (excluding zero)
#' @param mode interaction scale (`"normalized"`, `"amplitude"`, or `"raw"`)
#' @return data frame with per-trial summaries (condition, trial index, onset, magnitude, gain, routing, effective rank, v1 dominance)
#' @export
mppi_sdppi <- function(fit, fd,
                       select = NULL,
                       pre_window = 10L,
                       lags = -2:2,
                       mode = c("normalized", "amplitude", "raw")) {
  mode <- match.arg(mode)
  if (!inherits(fit, "mppi_fit")) stop("fit must be an mppi_fit object.", call. = FALSE)
  if (!inherits(fd, c("fmridesign", "event_model", "mppi_design"))) {
    stop("fd must be an fmridesign/event_model/mppi_design object.", call. = FALSE)
  }
  U <- fit$U %||% fit$R
  if (is.null(U)) stop("Trial-level summaries require the fit to store time-series (fit$U or fit$R).", call. = FALSE)
  Tn <- nrow(U)
  runs <- fit$runs %||% tryCatch(mppi_runs(fd, T = Tn), error = function(e) NULL) %||% rep_len(1L, Tn)
  if (length(runs) != Tn) stop("Run vector length mismatch.", call. = FALSE)
  TR <- fit$deconv$tr %||% fit$deconv$TR %||% tryCatch(mppi_tr(fd), error = function(e) NULL)
  if (is.null(TR) || !is.finite(TR)) TR <- 1
  S <- mppi_psych(fd, T = Tn, TR = TR, runs = runs)
  if (!is.null(select)) {
    keep <- grepl(select, colnames(S))
    if (!any(keep)) stop("No psychological regressors match 'select'.", call. = FALSE)
    S <- S[, keep, drop = FALSE]
  }
  if (!ncol(S)) stop("Design has zero matching psychological regressors.", call. = FALSE)
  sigma <- fit$sigma %||% matrixStats::colSds(fit$R)
  Sigma0 <- fit$Sigma0 %||% crossprod(U) / Tn
  v1 <- .mppi_first_eigvec(Sigma0)
  lag_vec <- setdiff(sort(unique(as.integer(lags))), 0L)
  blocklens <- fit$lag_blocklens %||% if (!is.null(fit$runs)) rle(fit$runs)$lengths else NULL
  results <- list()
  for (j in seq_len(ncol(S))) {
    stick <- S[, j]
    cond_name <- colnames(S)[j]
    starts <- which(stick > 0 & c(TRUE, diff(stick)) > 0)
    if (!length(starts)) {
      starts <- which(stick > 0 & c(1, diff(stick)) != 0)
    }
    if (!length(starts)) next
    trial_counter <- 0L
    for (s_idx in starts) {
      end_idx <- s_idx
      while (end_idx <= Tn && stick[end_idx] > 0) end_idx <- end_idx + 1L
      idx_range <- s_idx:(end_idx - 1L)
      s_event <- numeric(Tn)
      s_event[idx_range] <- stick[idx_range]
      denom <- sum(s_event^2)
      if (denom < 1e-10) next
      trial_counter <- trial_counter + 1L
      M_raw <- crossprod(U, s_event * U) / denom
      M_scaled <- if (mode == "raw") M_raw else .mppi_scale_matrix(M_raw, sigma, mode)
      Sk <- .mppi_sym(M_scaled)
      magnitude <- .mppi_frob(M_scaled)
      gain <- if (magnitude < 1e-8) NA_real_ else as.numeric((t(v1) %*% Sk %*% v1) / (.mppi_frob(Sk) + 1e-12))
      routing <- NA_real_
      if (length(lag_vec)) {
        pos <- neg <- 0
        for (lag in lag_vec) {
          Mk_lag <- .mppi_crossprod_lagged(U, s_event, lag, blocklens = blocklens)
          Mk_lag <- if (mode == "raw") Mk_lag else .mppi_scale_matrix(Mk_lag, sigma, mode)
          e <- .mppi_frob(Mk_lag)
          if (lag > 0) pos <- pos + e else neg <- neg + e
        }
        routing <- (pos - neg) / (pos + neg + 1e-12)
      }
      run_label <- runs[s_idx]
      run_idx <- which(runs == run_label)
      pre_start <- max(min(run_idx), s_idx - pre_window)
      pre_end <- max(pre_start, s_idx - 1L)
      if (pre_end - pre_start + 1L >= 2L) {
        Upre <- U[pre_start:pre_end, , drop = FALSE]
        Sp <- stats::cov(Upre)
        erank <- .mppi_effective_rank(Sp)
        v1dom <- as.numeric((t(v1) %*% Sp %*% v1) / (sum(diag(Sp)) + 1e-12))
      } else {
        erank <- NA_real_
        v1dom <- NA_real_
      }
      results[[length(results) + 1L]] <- data.frame(
        condition = cond_name,
        trial = trial_counter,
        onset = s_idx,
        magnitude = magnitude,
        gain = gain,
        routing = routing,
        effective_rank = erank,
        v1_dominance = v1dom,
        run = run_label,
        stringsAsFactors = FALSE
      )
    }
  }
  if (!length(results)) {
    stop("No trials detected for the requested conditions.", call. = FALSE)
  }
  do.call(rbind, results)
}

# Precision gating -----------------------------------------------------------

#' Precision gating summary \eqn{\Delta\Theta_k = -\Theta_0 M_k \Theta_0}
#'
#' @param fit `mppi_fit` object
#' @param mode interaction scale (`"normalized"`, `"amplitude"`, or `"raw"`)
#' @param Theta0 optional baseline precision matrix; defaults to the inverse of `fit$Sigma0`
#' @param ridge small positive ridge added to the baseline covariance before inversion
#' @return list with per-condition precision deltas and a summary data frame
#' @export
mppi_precision_gate <- function(fit,
                                mode = c("normalized", "amplitude", "raw"),
                                Theta0 = NULL,
                                ridge = 1e-4) {
  mode <- match.arg(mode)
  if (!inherits(fit, "mppi_fit")) stop("fit must be an mppi_fit object.", call. = FALSE)
  Sigma0 <- fit$Sigma0
  if (is.null(Sigma0)) stop("fit does not store baseline covariance (Sigma0).", call. = FALSE)
  if (is.null(Theta0)) {
    p <- ncol(Sigma0)
    Theta0 <- solve(Sigma0 + ridge * diag(p))
  }
  cond_names <- fit$names %||% paste0("k", seq_along(fit$Delta))
  Delta_list <- vector("list", length(cond_names))
  summary_rows <- vector("list", length(cond_names))
  names(Delta_list) <- cond_names
  for (ii in seq_along(cond_names)) {
    Mk <- mppi_get_M_scaled(fit, ii, mode = mode)
    DeltaTheta <- -Theta0 %*% Mk %*% Theta0
    Delta_list[[ii]] <- DeltaTheta
    off <- DeltaTheta
    diag(off) <- 0
    summary_rows[[ii]] <- data.frame(
      condition = cond_names[ii],
      dtheta_energy = .mppi_frob(DeltaTheta),
      offdiag_ratio = sum(abs(off)) / (sum(abs(diag(DeltaTheta))) + 1e-12),
      stringsAsFactors = FALSE
    )
  }
  list(Delta = Delta_list,
       summary = do.call(rbind, summary_rows),
       Theta0 = Theta0,
       mode = mode)
}
</file>

<file path="R/mppi_hrf_adapt.R">
# HRF-adaptive combination -------------------------------------------------

#' Combine multiple ΔΣ from an HRF basis using energy-maximizing weights
#' @param deltas_list list of VxV slope matrices for the same psychological effect but different HRF basis columns
#' @param pk_norms optional vector of ||pk||^2 to normalize columns
#' @param normalize logical; if TRUE, normalize Gram by pk_norms
#' @return list with Delta (combined), weights, Gram matrix M
mppi_hrf_adapt <- function(deltas_list, pk_norms = NULL, normalize = TRUE) {
  stopifnot(is.list(deltas_list), length(deltas_list) >= 1)
  B <- length(deltas_list)
  M <- matrix(0, B, B)
  for (i in seq_len(B)) for (j in i:B) {
    v <- sum(deltas_list[[i]] * deltas_list[[j]], na.rm = TRUE)
    M[i,j] <- M[j,i] <- v
  }
  if (normalize && !is.null(pk_norms)) {
    D <- diag(1/sqrt(pk_norms), nrow = B, ncol = B)
    M <- D %*% M %*% D
  }
  ev <- eigen(M, symmetric = TRUE)
  a  <- ev$vectors[,1,drop = TRUE]
  if (normalize && !is.null(pk_norms)) a <- a / sqrt(pk_norms)
  Delta_star <- Reduce(`+`, Map(function(w, D) w*D, a, deltas_list))
  list(Delta = Delta_star, weights = a, M = M)
}
</file>

<file path="R/mppi_inference.R">
# Inference: omnibus + permutations ---------------------------------------

#' Omnibus test for each psychological regressor via block sign-flips
#' @param fit result of mppi_fit()
#' @param blksize integer block length (TRs)
#' @param B number of permutations
#' @param wild "none","rademacher","mammen"
#' @return list per regressor with D, Q, Qnull, p_global
mppi_omnibus <- function(fit, blksize = 10L, B = 999L, wild = c("none","rademacher","mammen"),
                         method = c("block_flip","phase","freedman_lane"), seed = NULL) {
  wild <- match.arg(wild)
  method <- match.arg(method)
  if (method %in% c("phase","freedman_lane") && wild != "none") {
    warning("wild weights ignored when method='phase' or 'freedman_lane'.", call. = FALSE)
    wild <- "none"
  }
  out <- vector("list", length(fit$names)); names(out) <- fit$names
  Tn <- nrow(fit$R)
  idx <- split(seq_len(Tn), ceiling(seq_len(Tn)/blksize))
  runs_phase <- if (!is.null(fit$runs)) fit$runs else rep(1L, Tn)
  gen_weights <- function() {
    if (wild == "none") return(rep(1, length(idx)))
    if (wild == "rademacher") return(sample(c(-1,1), length(idx), replace = TRUE))
    # Mammen two-point weights
    p <- (sqrt(5)+1)/(2*sqrt(5))
    a <- (1 - sqrt(5))/2; b <- (1 + sqrt(5))/2
    sample(c(a,b), length(idx), replace = TRUE, prob = c(1-p, p))
  }
  rng_pre <- RNGkind()
  seed_pre <- if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) get(".Random.seed", envir = .GlobalEnv, inherits = FALSE) else NULL
  if (!is.null(seed)) set.seed(seed)
  rng_used <- RNGkind()
  init_seed <- if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) get(".Random.seed", envir = .GlobalEnv, inherits = FALSE) else NULL
  on.exit({
    do.call(RNGkind, as.list(rng_pre))
    if (is.null(seed_pre)) {
      if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE))
        rm(".Random.seed", envir = .GlobalEnv)
    } else {
      assign(".Random.seed", seed_pre, envir = .GlobalEnv)
    }
  }, add = TRUE)
  if (method == "freedman_lane") {
    V <- ncol(fit$R)
    outer_centered <- .mppi_row_outer_packed(fit$R)
    col_means <- colMeans(outer_centered)
    outer_centered <- sweep(outer_centered, 2, col_means, "-")
  }
  for (i in seq_along(fit$names)) {
    pk0 <- fit$pk[[i]]
    denom0 <- sum(pk0^2)
    if (method == "freedman_lane") {
      pkc <- pk0 - mean(pk0)
      beta_obs_vec <- drop(crossprod(pkc, outer_centered) / denom0)
      D0_full <- .mppi_unpack_upper(list(values = beta_obs_vec, dim = ncol(fit$R)))
      diag(D0_full) <- 0
      D0 <- if (isTRUE(fit$packed)) .mppi_pack_upper(D0_full) else D0_full
      Q0 <- .mppi_frob2(D0)
      perm_fun <- function() {
        perm_idx <- unlist(sample(idx))
        beta_vec <- drop(crossprod(pkc, outer_centered[perm_idx, , drop = FALSE]) / denom0)
        full <- .mppi_unpack_upper(list(values = beta_vec, dim = ncol(fit$R)))
        diag(full) <- 0
        if (isTRUE(fit$packed)) .mppi_pack_upper(full) else full
      }
      Qb <- numeric(B)
      for (b in seq_len(B)) {
        Db <- perm_fun()
        Qb[b] <- .mppi_frob2(Db)
      }
      p_global <- (1 + sum(Qb >= Q0)) / (B + 1)
      out[[i]] <- list(D = D0, Q = Q0, Qnull = Qb, p_global = p_global)
      next
    }
    D0 <- .mppi_wcp(fit$R, pk0) / denom0; diag(D0) <- 0
    Q0 <- sum(D0^2, na.rm = TRUE)
    Qb <- numeric(B)
    for (b in seq_len(B)) {
      if (method == "phase") {
        pkb <- .mppi_phase_randomize(pk0, runs_phase)
      } else {
        w <- gen_weights()
        pkb <- numeric(Tn); jj <- 1L
        for (g in idx) { pkb[g] <- w[jj]*pk0[g]; jj <- jj + 1L }
      }
      Db <- .mppi_wcp(fit$R, pkb) / sum(pkb^2)
      Qb[b] <- sum(Db^2, na.rm = TRUE)
    }
    p_global <- (1 + sum(Qb >= Q0)) / (B + 1)
    out[[i]] <- list(D = D0, Q = Q0, Qnull = Qb, p_global = p_global)
  }
  final_seed <- if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) get(".Random.seed", envir = .GlobalEnv, inherits = FALSE) else NULL
  attr(out, "rng") <- list(kind = rng_used, seed = init_seed, final_seed = final_seed,
                            method = method, seed_arg = seed)
  out
}

#' Edgewise permutations with optional studentization (experimental)
#' Returns p-values matrix for a given regressor index
mppi_permute <- function(fit, k = 1L, blksize = 10L, B = 999L,
                         wild = c("none","rademacher","mammen"), studentize = TRUE,
                         method = c("block_flip","phase","freedman_lane"), seed = NULL) {
  wild <- match.arg(wild)
  method <- match.arg(method)
  if (method %in% c("phase","freedman_lane") && wild != "none") {
    warning("wild weights ignored when method='phase' or 'freedman_lane'.", call. = FALSE)
    wild <- "none"
  }
  Tn <- nrow(fit$R)
  idx <- split(seq_len(Tn), ceiling(seq_len(Tn)/blksize))
  runs_phase <- if (!is.null(fit$runs)) fit$runs else rep(1L, Tn)
  gen_weights <- function() {
    if (wild == "none") return(rep(1, length(idx)))
    if (wild == "rademacher") return(sample(c(-1,1), length(idx), replace = TRUE))
    p <- (sqrt(5)+1)/(2*sqrt(5)); a <- (1 - sqrt(5))/2; b <- (1 + sqrt(5))/2
    sample(c(a,b), length(idx), replace = TRUE, prob = c(1-p, p))
  }
  pk0 <- fit$pk[[k]]
  denom0 <- sum(pk0^2)
  V <- ncol(fit$R)
  rng_pre <- RNGkind()
  seed_pre <- if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) get(".Random.seed", envir = .GlobalEnv, inherits = FALSE) else NULL
  if (!is.null(seed)) set.seed(seed)
  rng_used <- RNGkind()
  init_seed <- if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) get(".Random.seed", envir = .GlobalEnv, inherits = FALSE) else NULL
  on.exit({
    do.call(RNGkind, as.list(rng_pre))
    if (is.null(seed_pre)) {
      if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE))
        rm(".Random.seed", envir = .GlobalEnv)
    } else {
      assign(".Random.seed", seed_pre, envir = .GlobalEnv)
    }
  }, add = TRUE)
  if (method == "freedman_lane") {
    if (studentize) warning("studentize ignored for method='freedman_lane'.", call. = FALSE)
    outer_centered <- .mppi_row_outer_packed(fit$R)
    col_means <- colMeans(outer_centered)
    outer_centered <- sweep(outer_centered, 2, col_means, "-")
    pkc <- pk0 - mean(pk0)
    obs_vec <- drop(crossprod(pkc, outer_centered) / denom0)
    D0_full <- .mppi_unpack_upper(list(values = obs_vec, dim = V))
    diag(D0_full) <- 0
    count <- matrix(0, V, V)
    abs_obs <- abs(D0_full)
    for (b in seq_len(B)) {
      perm_idx <- unlist(sample(idx))
      perm_vec <- drop(crossprod(pkc, outer_centered[perm_idx, , drop = FALSE]) / denom0)
      Dperm <- .mppi_unpack_upper(list(values = perm_vec, dim = V))
      diag(Dperm) <- 0
      count <- count + (abs(Dperm) >= abs_obs)
    }
    pmat <- (1 + count) / (B + 1)
    diag(pmat) <- NA_real_
    attr(pmat, "rng") <- list(kind = rng_used, seed = init_seed, final_seed = if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) get(".Random.seed", envir = .GlobalEnv, inherits = FALSE) else NULL,
                               method = method, seed_arg = seed)
    return(pmat)
  }
  D0 <- .mppi_wcp(fit$R, pk0) / denom0; diag(D0) <- 0
  if (studentize) {
    S <- .mppi_wcp(fit$R, pk0^2) / denom0
    S[S <= 0] <- min(S[S > 0], na.rm = TRUE)
    Z0 <- D0 / sqrt(S)
  } else {
    Z0 <- D0
  }
  Zb <- array(0, dim = c(V,V,B))
  for (b in seq_len(B)) {
    if (method == "phase") {
      pkb <- .mppi_phase_randomize(pk0, runs_phase)
    } else {
      w <- gen_weights()
      pkb <- numeric(Tn); jj <- 1L
      for (g in idx) { pkb[g] <- w[jj]*pk0[g]; jj <- jj + 1L }
    }
    Db <- .mppi_wcp(fit$R, pkb) / sum(pkb^2); diag(Db) <- 0
    if (studentize) {
      Sb <- .mppi_wcp(fit$R, pkb^2) / sum(pkb^2)
      Sb[Sb <= 0] <- min(Sb[Sb > 0], na.rm = TRUE)
      Zb[,,b] <- Db / sqrt(Sb)
    } else {
      Zb[,,b] <- Db
    }
  }
  pmat <- matrix(NA_real_, V, V)
  for (i in seq_len(V)) for (j in seq_len(V)) {
    if (i == j) { pmat[i,j] <- NA_real_; next }
    z0 <- Z0[i,j]
    zb <- Zb[i,j,]
    pmat[i,j] <- (1 + sum(abs(zb) >= abs(z0))) / (B + 1)
  }
  final_seed <- if (exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) get(".Random.seed", envir = .GlobalEnv, inherits = FALSE) else NULL
  attr(pmat, "rng") <- list(kind = rng_used, seed = init_seed, final_seed = final_seed,
                             method = method, seed_arg = seed)
  pmat
}
</file>

<file path="R/mppi_lag.R">
# Lagged / directed variants ----------------------------------------------

#' Lagged Matrix-PPI (directed)
#' @param Y T x V data
#' @param X T x q design
#' @param psych_idx indices of psychological main effects
#' @param lags integer vector of lags (e.g., -2:2). Positive = delay p_k.
#' @param blocklens integer vector of run lengths (TR units) to prevent cross-run spillover
mppi_lagged <- function(x, ...) UseMethod("mppi_lagged")

#' @rdname mppi_lagged
#' @export
mppi_lagged.default <- function(Y, X, psych_idx, lags = -2:2, blocklens = NULL,
                                zero_diag = TRUE, scale = c("cov","corr")) {
  scale <- match.arg(scale)
  design_prep <- .mppi_prepare_design_matrix(X, psych_idx)
  X <- design_prep$X
  p_idx <- sort(unique(design_prep$psych_idx))
  all_idx <- seq_len(ncol(X))
  base_idx <- setdiff(all_idx, p_idx)
  # Residualize once
  R <- .mppi_residualize(Y, X)
  if (scale == "corr") {
    s <- apply(R, 2, sd); s[s == 0] <- 1
    R <- sweep(R, 2, s, "/")
  }
  out <- list()
  for (ii in seq_along(p_idx)) {
    k  <- p_idx[ii]
    Q  <- X[, c(base_idx, setdiff(p_idx, k)), drop = FALSE]
    pk0 <- .mppi_residualize_vec(X[, k], Q)
    for (lg in lags) {
      pk <- if (is.null(blocklens)) {
        # simple shift without wrap
        if (lg == 0) pk0 else {
          z <- rep(0, length(pk0))
          if (lg > 0) { z[(lg+1):length(z)] <- pk0[1:(length(z)-lg)] }
          else        { z[1:(length(z)+lg)] <- pk0[(1-lg):length(pk0)] }
          z
        }
      } else .mppi_shift_by_run(pk0, lg, blocklens)
      denom <- sum(pk^2)
      Dk <- if (denom < .Machine$double.eps) matrix(NA_real_, ncol(Y), ncol(Y))
            else .mppi_wcp(R, pk) / denom
      if (zero_diag) diag(Dk) <- 0
      out[[paste0(colnames(X)[k], "_lag", lg)]] <- Dk
    }
  }
  out
}

#' Select lag by maximizing omnibus statistic with permutations
#' @param lags vector of candidate lags
#' @param B number of permutations
#' @param targets optional subset of psychological regressors (names or indices)
#' @param zero_diag logical; zero the diagonal of returned matrices
mppi_lag_select <- function(Y, X, psych_idx, lags = -2:2, blocklens = NULL, B = 499L,
                            blksize = 10L, scale = c("cov","corr"), targets = NULL,
                            zero_diag = TRUE) {
  scale <- match.arg(scale)
  fit <- mppi_fit(Y, X, psych_idx, zero_diag = FALSE, scale = scale)
  Tn <- nrow(fit$R)
  V <- ncol(fit$R)
  p_names <- fit$names
  if (length(p_names) == 0) stop("No psychological regressors supplied via 'psych_idx'.")
  pick_targets <- function(x) {
    if (is.null(x)) return(seq_along(p_names))
    if (is.numeric(x)) {
      if (!all(x %in% seq_along(p_names))) stop("'targets' indices out of range.")
      return(x)
    }
    match_idx <- match(x, p_names)
    if (any(is.na(match_idx))) stop("Unable to match targets: ", paste(x[is.na(match_idx)], collapse = ", "))
    match_idx
  }
  tgt_idx <- pick_targets(targets)
  if (!is.null(blocklens)) {
    if (sum(blocklens) != Tn) stop("Sum(blocklens) must equal number of time points.")
  }
  shift_no_block <- function(x, lag) {
    if (lag == 0) return(x)
    n <- length(x)
    out <- numeric(n)
    if (lag > 0) {
      if (lag < n) out[(lag+1):n] <- x[1:(n-lag)]
    } else {
      lag <- abs(lag)
      if (lag < n) out[1:(n-lag)] <- x[(lag+1):n]
    }
    out
  }
  make_perm_blocks <- function() {
    if (!is.null(blksize)) {
      split(seq_len(Tn), ceiling(seq_len(Tn)/blksize))
    } else if (!is.null(blocklens)) {
      ends <- cumsum(blocklens)
      starts <- c(1, head(ends, -1) + 1)
      Map(seq, starts, ends)
    } else {
      list(seq_len(Tn))
    }
  }
  idx_blocks <- make_perm_blocks()
  signflip_block <- function(vec) {
    out <- vec
    sgn <- sample(c(-1, 1), length(idx_blocks), replace = TRUE)
    jj <- 1L
    for (g in idx_blocks) {
      out[g] <- sgn[jj] * out[g]
      jj <- jj + 1L
    }
    out
  }
  results <- vector("list", length(tgt_idx))
  names(results) <- p_names[tgt_idx]
  for (ii in seq_along(tgt_idx)) {
    pk0 <- fit$pk[[tgt_idx[ii]]]
    lag_vals <- setNames(rep(NA_real_, length(lags)), paste0("lag", lags))
    D_per_lag <- vector("list", length(lags))
    for (jj in seq_along(lags)) {
      lg <- lags[jj]
      pk_lag <- if (is.null(blocklens)) shift_no_block(pk0, lg) else .mppi_shift_by_run(pk0, lg, blocklens)
      denom <- sum(pk_lag^2)
      if (denom < .Machine$double.eps) {
        D_per_lag[[jj]] <- matrix(NA_real_, V, V)
        next
      }
      Dk <- .mppi_wcp(fit$R, pk_lag) / denom
      if (zero_diag) diag(Dk) <- 0
      D_per_lag[[jj]] <- Dk
      lag_vals[jj] <- sum(Dk^2, na.rm = TRUE)
    }
    if (all(is.na(lag_vals))) {
      results[[ii]] <- list(best_lag = NA_integer_, Q = NA_real_, Qnull = rep(NA_real_, B),
                            p = NA_real_, Qobs = lag_vals, Dbest = matrix(NA_real_, V, V))
      next
    }
    best_idx <- which.max(lag_vals)
    best_lag <- lags[best_idx]
    Dbest <- D_per_lag[[best_idx]]
    Qbest <- lag_vals[best_idx]
    pk_best <- if (is.null(blocklens)) shift_no_block(pk0, best_lag) else .mppi_shift_by_run(pk0, best_lag, blocklens)
    denom_best <- sum(pk_best^2)
    if (denom_best < .Machine$double.eps) {
      results[[ii]] <- list(best_lag = best_lag, Q = NA_real_, Qnull = rep(NA_real_, B),
                            p = NA_real_, Qobs = lag_vals, Dbest = Dbest)
      next
    }
    Qnull <- rep(NA_real_, B)
    for (b in seq_len(B)) {
      pk_perm <- signflip_block(pk_best)
      denomb <- sum(pk_perm^2)
      if (denomb < .Machine$double.eps) next
      Db <- .mppi_wcp(fit$R, pk_perm) / denomb
      if (zero_diag) diag(Db) <- 0
      Qnull[b] <- sum(Db^2, na.rm = TRUE)
    }
    valid <- !is.na(Qnull)
    pval <- if (!any(valid)) NA_real_ else (1 + sum(Qnull[valid] >= Qbest)) / (sum(valid) + 1)
    results[[ii]] <- list(best_lag = best_lag, Q = Qbest, Qnull = Qnull,
                          p = pval, Qobs = lag_vals, Dbest = Dbest)
  }
  if (length(results) == 1) results[[1]] else results
}
</file>

<file path="R/mppi_neural.R">
# Neural-domain helpers ----------------------------------------------------

#' Default canonical HRF used for neural-domain fits
#'
#' Provides a double-gamma haemodynamic response similar to SPM's canonical
#' kernel so `mppi_fit(..., domain = "neural")` can operate without an
#' explicit HRF from the caller. Oversampling lets callers request smoother
#' kernels but the default returns one value per TR.
#'
#' @param tr Repetition time (seconds).
#' @param duration Total length of the HRF support (seconds).
#' @param oversample Optional oversampling factor relative to `tr`.
#' @return Numeric vector containing the canonical HRF sampled at `tr`.
#' @export
mppi_default_hrf <- function(tr = 1, duration = 32, oversample = 1) {
  stopifnot(tr > 0, duration > 0)
  oversample <- as.integer(oversample)
  if (oversample < 1) stop("oversample must be >= 1")
  dt <- tr / oversample
  t <- seq(0, duration, by = dt)
  a1 <- 6; a2 <- 16
  b1 <- 1; b2 <- 1
  c <- 1 / 6
  h <- stats::dgamma(t, shape = a1, scale = b1) - c * stats::dgamma(t, shape = a2, scale = b2)
  if (sum(h) != 0) h <- h / sum(h)
  idx <- seq(1, length(h), by = oversample)
  h[idx]
}

# Internal helpers ------------------------------------------------------

.mppi_match_regressor <- function(fit, k) {
  idx <- if (is.character(k)) match(k, fit$names) else as.integer(k)
  if (is.na(idx) || idx < 1 || idx > length(fit$pk)) {
    stop("Invalid regressor index", call. = FALSE)
  }
  idx
}

.mppi_residual_matrix <- function(fit) {
  if (!is.null(fit$basis) && !is.null(fit$Z)) return(fit$Z)
  if (!is.null(fit$R)) return(fit$R)
  if (!is.null(fit$U)) return(fit$U)
  stop("Fit must expose residuals in $R, $Z, or $U for mechanistic helpers.", call. = FALSE)
}

.mppi_full_slope <- function(fit, idx) {
  pk <- fit$pk[[idx]]
  if (is.null(pk)) stop("Fit does not store pk for requested regressor.", call. = FALSE)
  X <- .mppi_residual_matrix(fit)
  if (length(pk) != nrow(X)) stop("pk length does not match residual rows.", call. = FALSE)
  denom <- sum(pk^2)
  if (denom < .Machine$double.eps) {
    return(matrix(NA_real_, ncol(X), ncol(X)))
  }
  crossprod(X, pk * X) / denom
}

#' Deconvolve psychological regressors into neural-domain "sticks"
#' 
#' Converts the psychological portions of the design matrix to neural-space
#' predictors using the same DCT deconvolution used inside `mppi_fit`. When
#' groups are supplied the resulting sticks are grouped/averaged by condition
#' (useful for HRF basis expansions).
#'
#' @param X Full design matrix used in the MPPI fit.
#' @param psych_idx Integer indices of the psychological columns in `X`.
#' @param h Haemodynamic response function vector.
#' @param K Number of DCT components to retain (defaults to 64 or `T/2`).
#' @param method Deconvolution method (`"gcv"` or `"fixed"`).
#' @param lambda Ridge parameter when `method = "fixed"`.
#' @param groups Optional list grouping columns (relative to `psych_idx`).
#' @return List with `S` (orthogonalised neural sticks), `names`, and `lambda`.
#' @export
mppi_psych_neural_from_X <- function(X, psych_idx, h, K = NULL,
                                     method = c("gcv", "fixed"), lambda = 1e-1,
                                     groups = NULL) {
  method <- match.arg(method)
  Xp <- X[, psych_idx, drop = FALSE]
  if (is.null(K)) K <- min(64L, floor(nrow(Xp) / 2L))
  dec <- mppi_deconv_dct(Xp, h = as.numeric(h), K = K, method = method, lambda = lambda)
  U <- dec$U
  if (is.null(groups)) {
    S <- U
    colnames(S) <- if (!is.null(colnames(Xp))) paste0("s:", colnames(Xp)) else paste0("s", seq_len(ncol(U)))
  } else {
    Slist <- vector("list", length(groups))
    nms   <- character(length(groups))
    for (g in seq_along(groups)) {
      idx <- groups[[g]]
      idx <- idx[idx >= 1 & idx <= ncol(U)]
      if (!length(idx)) stop("Empty group in 'groups'.")
      Ug <- U[, idx, drop = FALSE]
      norms <- sqrt(colSums(Ug^2)); norms[norms == 0] <- 1
      Ug <- sweep(Ug, 2, norms, "/")
      Slist[[g]] <- rowMeans(Ug)
      if (!is.null(colnames(Xp))) {
        nms[g] <- paste0("s:", paste(colnames(Xp)[idx], collapse = "+"))
      } else {
        nms[g] <- paste0("s:grp", g)
      }
    }
    S <- do.call(cbind, Slist)
    colnames(S) <- nms
  }
  S_res <- S
  for (ii in seq_len(ncol(S))) {
    Qs <- cbind(1, S[, setdiff(seq_len(ncol(S)), ii), drop = FALSE])
    S_res[, ii] <- S[, ii] - Qs %*% qr.coef(qr(Qs), S[, ii])
  }
  list(S = S_res, names = colnames(S_res), lambda = dec$lambda)
}

#' Convert an existing bold-domain fit to neural domain
#' @export
mppi_neural_from_fit <- function(fit, X, psych_idx, h, K = NULL,
                                 method = c("gcv", "fixed"), lambda = 1e-1, groups = NULL) {
  method <- match.arg(method)
  if (is.null(groups)) {
    groups <- tryCatch(mppi_group_hrf_columns(X[, psych_idx, drop = FALSE]),
                       error = function(e) NULL)
  }
  ps <- mppi_psych_neural_from_X(X, psych_idx, h, K, method, lambda, groups)
  S <- ps$S
  if (!is.null(fit$basis)) {
    if (is.null(fit$Z)) stop("fit must store basis residuals in $Z for conversion.")
    U <- mppi_deconv_dct(fit$Z, h = h, K = K, method = method, lambda = lambda)$U
    out <- fit
    out$Delta <- lapply(seq_len(ncol(S)), function(ii) {
      denom <- sum(S[, ii]^2)
      if (denom < .Machine$double.eps) matrix(NA_real_, ncol(fit$Z), ncol(fit$Z)) else {
        Mk <- crossprod(U, S[, ii] * U) / denom
        diag(Mk) <- 0
        Mk
      }
    })
    out$names <- ps$names
    out$U <- U
    out$pk <- lapply(seq_len(ncol(S)), function(ii) S[, ii])
    out$domain <- "neural"
    out
  } else {
    if (is.null(fit$R)) stop("fit must store residuals in $R for conversion.")
    Ufull <- mppi_deconv_dct(fit$R, h = h, K = K, method = method, lambda = lambda)$U
    out <- fit
    out$Delta <- lapply(seq_len(ncol(S)), function(ii) {
      denom <- sum(S[, ii]^2)
      if (denom < .Machine$double.eps) matrix(NA_real_, ncol(fit$R), ncol(fit$R)) else {
        Dk <- crossprod(Ufull, S[, ii] * Ufull) / denom
        diag(Dk) <- 0
        Dk
      }
    })
    out$names <- ps$names
    out$U <- Ufull
    out$pk <- lapply(seq_len(ncol(S)), function(ii) S[, ii])
    out$domain <- "neural"
    out
  }
}

#' Compare bold vs neural-domain fits (Δ-gap, AIC difference)
#' @export
mppi_compare_models <- function(fit_bold, fit_neural, resid_bold = NULL, resid_neural = NULL, pk = NULL) {
  stopifnot(length(fit_bold$names) == length(fit_neural$names))
  gap <- numeric(length(fit_bold$names))
  for (i in seq_along(fit_bold$names)) {
    B <- mppi_get_M(fit_bold, i)
    N <- mppi_get_M(fit_neural, i)
    gap[i] <- .mppi_frob2(B - N) / (sqrt(.mppi_frob2(N)) + 1e-12)
  }
  out <- list(names = fit_bold$names, delta_gap = gap)
  if (!is.null(resid_bold) && !is.null(resid_neural) && !is.null(pk)) {
    rss_b <- rss_n <- numeric(length(fit_bold$names))
    for (i in seq_along(fit_bold$names)) {
      denom <- sum(pk[[i]]^2)
      Bb <- crossprod(resid_bold, pk[[i]] * resid_bold) / denom
      Bn <- crossprod(resid_neural, pk[[i]] * resid_neural) / denom
      rss_b[i] <- sum((Bb - mppi_get_M(fit_bold, i))^2, na.rm = TRUE)
      rss_n[i] <- sum((Bn - mppi_get_M(fit_neural, i))^2, na.rm = TRUE)
    }
    n <- nrow(resid_bold)
    AIC_b <- n * log(rss_b / n)
    AIC_n <- n * log(rss_n / n)
    out$AIC_bold <- AIC_b
    out$AIC_neural <- AIC_n
    out$AIC_diff <- AIC_b - AIC_n
  }
  out
}

#' Evidence-weighted HRF ensemble average
#' @export
mppi_hrf_ensemble <- function(fits, weights = NULL) {
  stopifnot(is.list(fits), length(fits) >= 2)
  fit_names <- names(fits)
  method_tag <- "user"
  aic_scores <- NULL
  aic_list <- lapply(fits, function(f) f$AIC_total)
  len <- vapply(aic_list, length, integer(1))
  have_aic <- length(len) && length(unique(len)) == 1L && len[1] > 0L
  aic_mat <- if (have_aic) do.call(cbind, aic_list) else NULL
  if (is.null(weights)) {
    method_tag <- "uniform"
    if (have_aic) {
      if (all(is.finite(aic_mat))) {
        aic_scores <- colSums(aic_mat)
        w <- exp(-0.5 * (aic_scores - min(aic_scores)))
        if (sum(w) > 0) {
          weights <- w / sum(w)
          method_tag <- "aic"
        }
      }
    }
    if (is.null(weights)) {
      weights <- rep(1 / length(fits), length(fits))
    }
  } else {
    weights <- as.numeric(weights)
  }
  if (anyNA(weights) || any(weights < 0)) {
    stop("weights must be non-negative and finite.", call. = FALSE)
  }
  if (sum(weights) == 0) stop("At least one weight must be positive.", call. = FALSE)
  weights <- weights / sum(weights)
  if (is.null(fit_names)) {
    fit_names <- paste0("fit", seq_along(fits))
  }
  names(weights) <- fit_names
  out <- fits[[1]]
  combine_matrix <- function(idx) {
    Mk <- Reduce(`+`, Map(function(w, f) w * mppi_get_M(f, idx), weights, fits))
    if (isTRUE(out$packed)) .mppi_pack_upper(Mk) else Mk
  }
  out$Delta <- lapply(seq_along(out$names), combine_matrix)
  if (have_aic && all(dim(aic_mat))) {
    if (is.null(aic_scores)) aic_scores <- colSums(aic_mat)
    out$AIC_total <- as.numeric(aic_mat %*% weights)
  }
  out$ensemble <- list(weights = weights, method = method_tag, scores = aic_scores)
  out
}

#' Gain/precision index from ΔTheta
#' @export
mppi_gain <- function(fit, k = 1L, lambda = 1e-3, roi_idx = NULL) {
  idx <- .mppi_match_regressor(fit, k)
  X <- .mppi_residual_matrix(fit)
  S0 <- crossprod(X) / nrow(X)
  Mk <- .mppi_full_slope(fit, idx)
  if (all(is.na(Mk))) {
    comp_gain <- rep(NA_real_, ncol(S0))
    dTheta <- matrix(NA_real_, ncol(S0), ncol(S0))
  } else {
    Theta0 <- solve(S0 + diag(lambda, ncol(S0)))
    dTheta <- - Theta0 %*% Mk %*% Theta0
    comp_gain <- diag(dTheta)
  }
  if (is.null(fit$basis)) {
    if (!is.null(roi_idx)) comp_gain <- comp_gain[roi_idx]
    list(gain = comp_gain, space = "roi")
  } else {
    if (!is.null(roi_idx)) {
      V <- fit$basis$V[roi_idx, , drop = FALSE]
      roi_gain <- rowSums((V %*% dTheta) * V)
      list(gain_component = comp_gain, gain_roi = roi_gain, idx = roi_idx, space = "roi+basis")
    } else {
      list(gain_component = comp_gain, space = "basis")
    }
  }
}

#' Routing asymmetry index using lagged fits and a hierarchy vector
#' @export
mppi_routing_index <- function(fits_by_lag, k = 1L, hierarchy,
                               space = c("auto", "basis", "roi"),
                               pos = c(1, 2), neg = c(-1, -2), eps = 1e-8) {
  space <- match.arg(space)
  use_single_fit <- inherits(fits_by_lag, "mppi_fit")
  if (use_single_fit) {
    fit_ref <- fits_by_lag
    if (is.null(fit_ref$lags) || is.null(fit_ref$lagged)) {
      stop("Fit does not contain lagged outputs; refit with lags specified.", call. = FALSE)
    }
    lag_vals <- as.integer(fit_ref$lags)
    lag_vals <- sort(unique(lag_vals))
    if (space == "auto") space <- if (!is.null(fit_ref$basis)) "basis" else "roi"
    X0 <- .mppi_residual_matrix(fit_ref)
    fetch_matrix <- function(lag) mppi_get_M_lag(fit_ref, k, lag)
  } else {
    if (!length(fits_by_lag)) stop("Provide at least one lagged fit.")
    lag_names <- names(fits_by_lag)
    if (is.null(lag_names)) {
      stop("fits_by_lag must be a named list of lagged fits.", call. = FALSE)
    }
    lag_vals <- suppressWarnings(as.integer(lag_names))
    if (any(is.na(lag_vals))) {
      stop("Lag names must coerce to integers (e.g., '-2', '1').", call. = FALSE)
    }
    lag_vals <- sort(unique(lag_vals))
    fit_ref <- fits_by_lag[[1]]
    if (space == "auto") space <- if (!is.null(fit_ref$basis)) "basis" else "roi"
    X0 <- .mppi_residual_matrix(fit_ref)
    fit_lookup <- fits_by_lag
    fetch_matrix <- function(lag) {
      fit <- fit_lookup[[as.character(lag)]]
      if (is.null(fit)) {
        stop(sprintf("No fit supplied for lag %s", lag), call. = FALSE)
      }
      mppi_get_M(fit, k)
    }
  }
  u <- as.numeric(hierarchy)
  if (length(u) != ncol(X0)) stop("Hierarchy vector length must match fit dimension.")
  Wdir <- tcrossprod(u, u)
  pos_lags <- intersect(lag_vals, pos)
  neg_lags <- intersect(lag_vals, neg)
  proj_energy <- function(lag) {
    Mk <- fetch_matrix(lag)
    sum(Mk * Wdir, na.rm = TRUE)
  }
  Epos <- if (length(pos_lags)) sum(vapply(pos_lags, proj_energy, numeric(1))) else 0
  Eneg <- if (length(neg_lags)) sum(vapply(neg_lags, proj_energy, numeric(1))) else 0
  R <- (Epos - Eneg) / (Epos + Eneg + eps)
  list(routing = R, energy_pos = Epos, energy_neg = Eneg,
       pos = pos, neg = neg, lag_values = lag_vals)
}

#' Project an interaction matrix onto hypothesis templates
#'
#' @param fit An `mppi_fit` object (ROI or basis).
#' @param k Regressor index or name.
#' @param templates Named list of template matrices matching the fit dimension.
#' @param normalize Logical; divide by the Frobenius norm of each template.
#' @return Named numeric vector of template weights.
#' @export
mppi_project_templates <- function(fit, k = 1L, templates, normalize = TRUE) {
  if (!length(templates)) stop("templates must be a non-empty list.")
  idx <- .mppi_match_regressor(fit, k)
  Mk <- .mppi_full_slope(fit, idx)
  dim_fit <- ncol(Mk)
  apply_template <- function(W) {
    W <- as.matrix(W)
    if (!all(dim(W) == c(dim_fit, dim_fit))) stop("Template dimensions must match fit dimension.")
    num <- sum(Mk * W, na.rm = TRUE)
    if (!normalize) return(num)
    denom <- sqrt(sum(W^2, na.rm = TRUE))
    if (denom < .Machine$double.eps) return(NA_real_)
    num / denom
  }
  vapply(templates, apply_template, numeric(1))
}

#' Construct within/between-network templates
#'
#' @param labels Factor or character vector labelling each component.
#' @return Named list with `within` and `between` templates (unit Frobenius norm).
#' @export
mppi_templates_within_between <- function(labels) {
  labs <- as.character(labels)
  n <- length(labs)
  same <- outer(labs, labs, `==`)
  diag_mask <- diag(1, n)
  within <- same & !diag_mask
  between <- (!same) & !diag_mask
  normalize <- function(M) {
    denom <- sqrt(sum(M^2))
    if (denom < .Machine$double.eps) matrix(0, n, n) else M / denom
  }
  list(within = normalize(within), between = normalize(between))
}

#' Construct gradient-aligned and orthogonal templates
#'
#' @param u Numeric hierarchy/gradient vector.
#' @return List with `dir` (rank-1 projector) and `ortho` components.
#' @export
mppi_templates_gradient <- function(u) {
  u <- as.numeric(u)
  if (anyNA(u)) stop("Gradient vector contains NA values.")
  if (all(u == 0)) stop("Gradient vector must have non-zero length.")
  u <- u / sqrt(sum(u^2))
  W_dir <- tcrossprod(u, u)
  W_ortho <- diag(length(u)) - W_dir
  normalize <- function(M) {
    denom <- sqrt(sum(M^2))
    if (denom < .Machine$double.eps) matrix(0, nrow(M), ncol(M)) else M / denom
  }
  list(dir = normalize(W_dir), ortho = normalize(W_ortho))
}

#' Compile mechanistic gain/routing/template summaries
#'
#' @param fit `mppi_fit` object for the target regressor.
#' @param k Regressor index or name.
#' @param hierarchy Optional vector for routing index.
#' @param lag_fits Optional named list of lagged fits for routing.
#' @param templates Optional list of template matrices for projections.
#' @param lambda Ridge term for gain computation.
#' @param roi_idx Optional ROI indices for gain back-projection.
#' @param normalize_templates Logical; pass to `mppi_project_templates`.
#' @return List with gain, routing, and template summaries (any can be `NULL`).
#' @export
mppi_mechanism_report <- function(fit, k = 1L, hierarchy = NULL, lag_fits = NULL,
                                  templates = NULL, lambda = 1e-3, roi_idx = NULL,
                                  normalize_templates = TRUE) {
  gain <- mppi_gain(fit, k = k, lambda = lambda, roi_idx = roi_idx)
  routing <- if (!is.null(hierarchy) && !is.null(lag_fits)) {
    mppi_routing_index(lag_fits, k = k, hierarchy = hierarchy)
  } else NULL
  template_weights <- if (!is.null(templates)) {
    mppi_project_templates(fit, k = k, templates = templates, normalize = normalize_templates)
  } else NULL
  list(gain = gain, routing = routing, templates = template_weights)
}
</file>

<file path="R/mppi_partial.R">
# Partial connectivity / interpretation -----------------------------------

#' First-order precision update from covariance slope
#' @param Sigma0 baseline covariance (T^{-1} R'R) or correlation
#' @param DeltaSigma slope matrix for regressor k
#' @param lambda ridge parameter for invertibility
#' @return matrix ΔΘ
mppi_to_partial <- function(Sigma0, DeltaSigma, lambda = 1e-3) {
  V <- nrow(Sigma0); I <- diag(V)
  Theta0 <- solve(Sigma0 + lambda * I)
  - Theta0 %*% DeltaSigma %*% Theta0
}

#' Partial-correlation delta approximation
#' @param Theta0 baseline precision; @param DeltaTheta precision delta
mppi_delta_partial <- function(Theta0, DeltaTheta) {
  V <- nrow(Theta0)
  d <- 1/sqrt(diag(Theta0))
  S <- d %o% d
  - DeltaTheta * S
}
</file>

<file path="R/mppi_rank_cv.R">
# Low-rank selection / shrinkage ------------------------------------------

#' Cross-validated rank selection for ΔΣ (component space recommended)
#'
#' This helper recomputes task-modulated slopes on training/validation splits and
#' scores low-rank approximations via held-out Frobenius loss. It is agnostic to
#' whether you operate in voxel/ROI or basis space, but for high-dimensional
#' data you should supply the reduced residual matrix (e.g., `fit$Z`) together
#' with its corresponding slope matrix (`mppi_get_M(fit, k)`) so the SVD is
#' performed on an r × r matrix rather than a 50k × 50k object.
#'
#' @param R Residualized time series in the working space (T × V or T × r).
#' @param pk Residualized psychological regressor (length T).
#' @param Delta Optional observed slope matrix (V × V); retained for backward
#'   compatibility but recomputed internally from `R`/`pk` in each split.
#' @param holdout_frac Fraction of time points for hold-out blocks.
#' @param R_reps Number of random splits.
#' @return List with the selected rank `r`, per-rank losses, and the rank grid.
mppi_rank_cv <- function(R, pk, Delta, holdout_frac = 0.2, R_reps = 3) {
  Tn <- nrow(R); V <- ncol(R)
  rmax <- min(50L, V)
  ranks <- 0:rmax
  losses <- matrix(0, nrow = R_reps, ncol = length(ranks))
  for (rep in seq_len(R_reps)) {
    H <- sort(sample.int(Tn, floor(holdout_frac*Tn)))
    K <- setdiff(seq_len(Tn), H)
    denomK <- sum(pk[K]^2); denomH <- sum(pk[H]^2)
    DeltaK <- if (denomK < .Machine$double.eps) {
      matrix(0, V, V)
    } else {
      crossprod(R[K, , drop = FALSE], pk[K] * R[K, , drop = FALSE]) / denomK
    }
    targetH <- if (denomH < .Machine$double.eps) {
      matrix(0, V, V)
    } else {
      crossprod(R[H, , drop = FALSE], pk[H] * R[H, , drop = FALSE]) / denomH
    }
    sK <- svd(DeltaK, nu = min(rmax, V), nv = min(rmax, V))
    for (j in seq_along(ranks)) {
      r <- ranks[j]
      if (r == 0) {
        approx <- matrix(0, V, V)
      } else {
        approx <- sK$u[, 1:r, drop = FALSE] %*%
          diag(sK$d[1:r], nrow = r, ncol = r) %*%
          t(sK$u[, 1:r, drop = FALSE])
      }
      losses[rep, j] <- mean((targetH - approx)^2, na.rm = TRUE)
    }
  }
  rstar <- ranks[ which.min(colMeans(losses)) ]
  list(r = rstar, losses = as.numeric(colMeans(losses)), ranks = ranks)
}
</file>

<file path="R/mppi_rest.R">
# Resting-state multiPPI helpers --------------------------------------------

#' Extract time series, runs, and TR for resting-state analyses
#'
#' This utility accepts either a matrix (`T x V`) or an `fmri_dataset` and
#' returns the pieces required by the rest pipeline.
#'
#' @param data Matrix or fmri_dataset-like object.
#' @param runs Optional run labels (overrides dataset metadata when supplied).
#' @return List with `Y`, `runs`, and `TR` entries.
#' @keywords internal
mppi_rest_extract <- function(data, runs = NULL) {
  if (is.matrix(data)) {
    Y <- data
    TR <- attr(data, "TR")
    runs_ds <- runs %||% attr(data, "runs")
  } else if (inherits(data, "fmri_dataset") && requireNamespace("fmridataset", quietly = TRUE)) {
    Y <- fmridataset::get_data_matrix(data)
    TR <- tryCatch(fmridataset::get_TR(data), error = function(e) NULL)
    runs_ds <- runs %||% tryCatch(fmridataset::get_run_lengths(data), error = function(e) NULL)
    if (length(runs_ds) && length(runs_ds) != nrow(Y)) {
      runs_ds <- rep(seq_along(runs_ds), runs_ds)
    }
    if (!length(runs_ds)) {
      runs_ds <- tryCatch(fmridataset::blockids(data), error = function(e) NULL)
    }
  } else {
    Y <- data$Y %||% data$timeseries %||% stop("Provide a matrix or fmri_dataset-like object.", call. = FALSE)
    TR <- runs <- NULL
    runs_ds <- runs %||% data$runs %||% attr(data, "runs")
  }
  if (!is.null(runs_ds) && length(runs_ds) != nrow(Y)) {
    stop("Runs vector length must match number of time points.", call. = FALSE)
  }
  list(
    Y = as.matrix(Y),
    runs = if (is.null(runs_ds)) NULL else as.integer(runs_ds),
    TR = TR %||% attr(data, "TR")
  )
}

#' Endogenous microstate modulators
#'
#' Builds a list of T-length modulators describing latent states obtained from a
#' PCA basis time-series. Methods include k-means (default) and an optional
#' sticky HMM (via `depmixS4`).
#'
#' @param U Low-rank time-series matrix (`T x r`).
#' @param K Number of states.
#' @param method "kmeans" (default) or "hmm" (requires depmixS4).
#' @param soft Return soft posteriors (TRUE) or hard one-hot sticks (FALSE).
#' @param sticky Self-transition boost for the HMM (ignored for kmeans).
#' @param seed Seed for reproducibility.
#' @param zscore Whether to z-score columns of `U` before clustering.
#' @return Named list of modulators.
mppi_rest_states <- function(U, K = 6L, method = c("kmeans", "hmm"),
                             soft = TRUE, sticky = 2, seed = 1L, zscore = TRUE) {
  method <- match.arg(method)
  set.seed(seed)
  X <- if (zscore) scale(U) else U
  if (method == "kmeans") {
    km <- stats::kmeans(X, centers = K, nstart = 8L)
    sticks <- stats::model.matrix(~ 0 + factor(km$cluster))
    colnames(sticks) <- paste0("state", seq_len(ncol(sticks)))
    if (!soft) return(as.list(as.data.frame(sticks)))
    # simple temporal smoothing for pseudo-soft output
    smooth <- vapply(seq_len(ncol(sticks)), function(j) {
      sm <- stats::filter(sticks[, j], rep(1/3, 3), sides = 2)
      sm[is.na(sm)] <- 0
      as.numeric(sm)
    }, numeric(nrow(sticks)))
    colnames(smooth) <- colnames(sticks)
    return(as.list(as.data.frame(smooth)))
  }
  if (!requireNamespace("depmixS4", quietly = TRUE)) {
    stop("Install depmixS4 to enable HMM-based microstates.", call. = FALSE)
  }
  responses <- lapply(seq_len(ncol(X)), function(j) X[, j] ~ 1)
  fams <- replicate(ncol(X), depmixS4::gaussian(), simplify = FALSE)
  mod <- depmixS4::depmix(response = responses, data = as.data.frame(X),
                          nstates = K, family = fams)
  fit <- suppressWarnings(depmixS4::fit(mod, verbose = FALSE))
  post <- depmixS4::posterior(fit)
  gamma <- as.matrix(post[, paste0("S", seq_len(K)), drop = FALSE])
  colnames(gamma) <- paste0("state", seq_len(K))
  if (soft) return(as.list(as.data.frame(gamma)))
  hard <- stats::model.matrix(~ 0 + factor(max.col(gamma)))
  colnames(hard) <- paste0("state", seq_len(ncol(hard)))
  as.list(as.data.frame(hard))
}

#' Innovation burst modulators
#'
#' Builds sparse stick functions marking high-magnitude innovations derived from
#' AR residuals across basis time-series.
#'
#' @param U Low-rank time-series matrix (`T x r`).
#' @param ar_order AR order used when computing residuals.
#' @param thresholds Quantile thresholds used to define bursts.
#' @return Named list of binary modulators.
mppi_rest_bursts <- function(U, ar_order = 4L, thresholds = c(0.90, 0.95, 0.98)) {
  Tn <- nrow(U); r <- ncol(U)
  eps <- matrix(0, Tn, r)
  for (j in seq_len(r)) {
    ts <- U[, j]
    if (sd(ts) == 0) next
    fit <- try(stats::ar(ts, order.max = ar_order, aic = FALSE, method = "yw"), silent = TRUE)
    if (inherits(fit, "try-error") || !length(fit$ar)) {
      eps[, j] <- ts
    } else {
      res <- ts
      for (lag in seq_along(fit$ar)) {
        res[(lag + 1):Tn] <- res[(lag + 1):Tn] - fit$ar[lag] * ts[seq_len(Tn - lag)]
      }
      eps[, j] <- res
    }
  }
  mag <- sqrt(rowSums(eps^2))
  lapply(thresholds, function(q) as.numeric(mag >= stats::quantile(mag, q, na.rm = TRUE))) |>
    setNames(paste0("burst_q", sprintf("%02d", round(100 * thresholds))))
}

#' Envelope modulators
#'
#' Creates continuous modulators reflecting power or amplitude envelopes of
#' chosen component groups.
#'
#' @param U Low-rank time-series matrix (`T x r`).
#' @param groups Named list of column indices. `NULL` uses all columns.
#' @param transform "power" (default) or "abs" for absolute-value envelopes.
#' @param zscore Whether to z-score the resulting envelope.
#' @return Named list of continuous modulators.
mppi_rest_envelopes <- function(U, groups = list(all = NULL), transform = c("power", "abs"),
                                zscore = TRUE) {
  transform <- match.arg(transform)
  out <- list()
  cols <- seq_len(ncol(U))
  for (nm in names(groups)) {
    idx <- groups[[nm]] %||% cols
    block <- U[, idx, drop = FALSE]
    env <- switch(transform,
                  power = rowSums(block^2),
                  abs = rowSums(abs(block)))
    if (zscore) env <- as.numeric(scale(env))
    out[[paste0("env_", nm)]] <- env
  }
  out
}

#' Assemble endogenous modulators for rest multiPPI
#'
#' @param U Low-rank time-series matrix (`T x r`).
#' @param include Character vector selecting which families to include.
#' @param states,bursts,envelopes Named lists of arguments passed to the
#'   respective helper.
#' @param extra Optional list of additional modulators to append.
#' @return Named list of modulators ready for design construction.
mppi_rest_modulators <- function(U,
                                 include = c("states", "bursts", "envelopes"),
                                 states = list(),
                                 bursts = list(),
                                 envelopes = list(),
                                 extra = NULL) {
  include <- intersect(include, c("states", "bursts", "envelopes"))
  pk <- list()
  if ("states" %in% include) {
    pk <- c(pk, do.call(mppi_rest_states, c(list(U = U), states)))
  }
  if ("bursts" %in% include) {
    pk <- c(pk, do.call(mppi_rest_bursts, c(list(U = U), bursts)))
  }
  if ("envelopes" %in% include) {
    pk <- c(pk, do.call(mppi_rest_envelopes, c(list(U = U), envelopes)))
  }
  if (!is.null(extra)) pk <- c(pk, extra)
  if (!length(pk)) stop("No modulators were created.", call. = FALSE)
  stopifnot(all(vapply(pk, length, 1L) == nrow(U)))
  pk
}

#' Build a gPPI-style design for endogenous modulators
#'
#' Residualizes each modulator against all others, optional nuisance regressors,
#' and an intercept to span the full context space (gPPI logic).
#'
#' @param pk Named list of modulators.
#' @param nuisance Optional nuisance matrix (`T x q`).
#' @param runs Optional run labels used for within-run centering.
#' @param include_intercept Include an intercept column (default TRUE).
#' @param scale_mod Normalize each modulator to unit L2 norm after residualizing.
#' @return List containing design matrix `X`, psychological indices, and the
#'   residualized modulators.
mppi_rest_design <- function(pk, nuisance = NULL, runs = NULL,
                             include_intercept = TRUE, scale_mod = TRUE) {
  pk <- lapply(pk, as.numeric)
  Tn <- length(pk[[1L]])
  stopifnot(all(vapply(pk, length, 1L) == Tn))
  if (!is.null(nuisance)) {
    nuisance <- as.matrix(nuisance)
    if (nrow(nuisance) != Tn) stop("Nuisance rows must match data length.", call. = FALSE)
  }
  N <- length(pk)
  resid_pk <- vector("list", N)
  intercept <- if (include_intercept) matrix(1, Tn, 1) else NULL
  base_Q <- if (is.null(nuisance) && is.null(intercept)) NULL else cbind(nuisance, intercept)
  for (j in seq_len(N)) {
    others <- pk[setdiff(seq_len(N), j)]
    Q <- do.call(cbind, c(others, list(base_Q)))
    if (!is.null(Q)) {
      resid <- .mppi_residualize_vec(pk[[j]], as.matrix(Q))
    } else {
      resid <- pk[[j]]
    }
    if (!is.null(runs)) resid <- .mppi_center_by_run(resid, runs)
    if (scale_mod) {
      sdv <- sqrt(sum(resid^2))
      if (sdv < .Machine$double.eps) {
        warning(sprintf("Modulator '%s' has near-zero variance after residualization.", names(pk)[j]), call. = FALSE)
      }
      resid <- resid / max(sdv, .Machine$double.eps)
    }
    resid_pk[[j]] <- resid
  }
  names(resid_pk) <- names(pk)
  P <- do.call(cbind, resid_pk)
  colnames(P) <- names(resid_pk)
  X <- if (is.null(nuisance)) P else cbind(nuisance, P)
  if (include_intercept) {
    X <- cbind(`(Intercept)` = 1, X)
  }
  psych_idx <- seq(ncol(X) - length(resid_pk) + 1L, ncol(X))
  list(X = X, psych_idx = psych_idx, pk = resid_pk)
}

#' Resting-state multiPPI wrapper
#'
#' @param data Matrix or fmri_dataset providing the time series.
#' @param runs Optional run labels.
#' @param modulators Optional pre-built modulators; if NULL they are derived from
#'   the basis time-series.
#' @param include Which modulator families to construct when `modulators` is NULL.
#' @param basis Basis specification passed to `.mppi_resolve_basis()`.
#' @param modulator_domain Domain for building modulators ("auto", "bold", "neural").
#' @param domain Domain for the final mPPI fit.
#' @param prewhiten Use fmriAR prewhitening (default TRUE when available).
#' @param ar_method,ar_order Controls for fmriAR noise modelling.
#' @param nuisance Optional nuisance regressors aligned with the data.
#' @param attach_pk Attach residualized modulator list to the returned fit.
#' @param ... Passed through to `mppi_fit()` / `mppi_fit_whitened()`.
#' @return `mppi_fit` object.
mppi_rest <- function(data,
                      runs = NULL,
                      modulators = NULL,
                      include = c("states", "bursts", "envelopes"),
                      basis = list(type = "pca", r = 120L),
                      modulator_domain = c("auto", "bold", "neural"),
                      domain = c("neural", "bold", "innovations"),
                      prewhiten = TRUE,
                      ar_method = "ar",
                      ar_order = "auto",
                      nuisance = NULL,
                      attach_pk = TRUE,
                      ...) {
  dom <- match.arg(domain)
  mod_dom <- match.arg(modulator_domain)
  info <- mppi_rest_extract(data, runs = runs)
  Y <- info$Y
  runs_vec <- info$runs
  if (is.null(runs_vec)) runs_vec <- runs %||% attr(data, "runs")
  basis_obj <- .mppi_resolve_basis(Y, basis = basis, dataset = if (is.list(data)) data else NULL)
  U_bold <- if (is.null(basis_obj)) Y else Y %*% basis_obj$V
  U_for_pk <- U_bold
  if (identical(mod_dom, "auto")) {
    mod_dom <- if (!is.null(info$TR) && dom == "neural") "neural" else "bold"
  }
  if (identical(mod_dom, "neural")) {
    hrf <- mppi_default_hrf(tr = info$TR %||% 1, duration = 32)
    U_for_pk <- mppi_deconv(U_bold, TR = info$TR %||% 1, hrf = hrf, lambda = 10)
  }
  pk <- modulators %||% mppi_rest_modulators(U_for_pk, include = include)
  design <- mppi_rest_design(pk, nuisance = nuisance, runs = runs_vec, include_intercept = TRUE)
  X <- design$X
  psych_idx <- design$psych_idx
  fit <- if (prewhiten) {
    mppi_fit_whitened(Y = Y, X = X, runs = runs_vec,
                      psych_idx = psych_idx, ar_method = ar_method, p = ar_order,
                      basis = basis_obj, domain = dom, ...)
  } else {
    mppi_fit(Y = Y, X = X, psych_idx = psych_idx, runs = runs_vec,
             basis = basis_obj, domain = dom, ...)
  }
  if (attach_pk) {
    attr(fit, "pk") <- design$pk
    attr(fit, "runs") <- runs_vec
    attr(fit, "basis_timecourses") <- U_for_pk
    attr(fit, "TR") <- info$TR
  }
  fit
}

#' Subject-level features for resting-state traits
#'
#' Aggregates Gain, Routing, and mode energies across contexts for a list of
#' rest fits.
#'
#' @param fits List of `mppi_fit` objects.
#' @param lags Lags used when computing routing.
#' @param modes Number of communication modes to retain.
#' @param aggregate "mean" to average over contexts per subject, otherwise
#'   returns long-format rows.
#' @return Data frame of subject-level features.
mppi_rest_features <- function(fits, lags = -2:2, modes = 10L, aggregate = c("mean", "none")) {
  aggregate <- match.arg(aggregate)
  rows <- vector("list", length(fits))
  for (i in seq_along(fits)) {
    fit <- fits[[i]]
    ax <- mppi_axes(fit, lags = lags)
    if (!"G" %in% names(ax) && "gain" %in% names(ax)) ax$G <- ax$gain
    if (!"R" %in% names(ax) && "routing" %in% names(ax)) ax$R <- ax$routing
    md <- mppi_modes(fit, r = modes)
    proj <- md$projected
    mag <- vapply(proj, function(M) sqrt(sum(M * M)), 0)
    ax$mag <- mag[match(ax$condition, names(mag))]
    ax$subj <- i
    rows[[i]] <- ax
  }
  feats <- do.call(rbind, rows)
  if (aggregate == "mean") {
    cols <- intersect(c("G", "R", "mag"), names(feats))
    stats::aggregate(feats[, cols, drop = FALSE],
                     by = list(subj = feats$subj),
                     FUN = mean)
  } else {
    feats
  }
}

#' Simple nested CV ridge for trait prediction
#'
#' @param features Output from `mppi_rest_features(aggregate = "none")`.
#' @param y Named numeric trait vector (names correspond to subject indices).
#' @param covariates Optional covariate matrix keyed by subject name.
#' @param k Number of outer CV folds.
#' @param seed RNG seed.
#' @param lambda Ridge penalty.
#' @return List with predictions, observed values, and CV R^2.
mppi_rest_trait_cv <- function(features, y, covariates = NULL,
                               k = 5L, seed = 1L, lambda = 1e-2) {
  stopifnot(is.numeric(y))
  subj_ids <- sort(unique(features$subj))
  if (is.null(names(y))) names(y) <- subj_ids
  if (length(y) != length(subj_ids)) {
    stop("Trait vector length must equal number of subjects in features.", call. = FALSE)
  }
  y <- y[order(as.numeric(names(y)))]
  set.seed(seed)
  folds <- split(sample(subj_ids), rep_len(seq_len(k), length(subj_ids)))
  Xwide <- stats::reshape(features,
                          idvar = "subj", timevar = "condition",
                          direction = "wide")
  rownames(Xwide) <- Xwide$subj
  pred_cols <- grepl("^(G|R|mag)\\.", colnames(Xwide))
  X <- as.matrix(Xwide[, pred_cols, drop = FALSE])
  y_aligned <- y[match(rownames(X), names(y))]
  if (!is.null(covariates)) {
    covariates <- covariates[match(rownames(X), rownames(covariates)), , drop = FALSE]
    X <- cbind(X, covariates)
  }
  preds <- rep(NA_real_, length(y_aligned)); names(preds) <- rownames(X)
  for (fold in seq_len(k)) {
    test_ids <- folds[[fold]]
    train_ids <- setdiff(subj_ids, test_ids)
    Xtr <- X[as.character(train_ids), , drop = FALSE]
    ytr <- y_aligned[match(as.character(train_ids), names(y_aligned))]
    XtX <- crossprod(Xtr)
    beta <- solve(XtX + diag(lambda, ncol(Xtr)), crossprod(Xtr, ytr))
    preds[as.character(test_ids)] <- X[as.character(test_ids), , drop = FALSE] %*% beta
  }
  cv_r2 <- 1 - sum((y_aligned - preds)^2, na.rm = TRUE) /
    sum((y_aligned - mean(y_aligned, na.rm = TRUE))^2, na.rm = TRUE)
  list(pred = preds, observed = y_aligned, cv_r2 = cv_r2)
}
</file>

<file path="R/mppi_s3.R">
# S3 interface ---------------------------------------------------------------

#' MultiPPI generic
mppi <- function(x, ...) {
  UseMethod("mppi")
}

#' @export
mppi.matrix <- function(x, X, psych_idx, runs = NULL, prewhiten = FALSE,
                        basis = NULL, domain = c("bold","neural"),
                        deconv = NULL, lags = 0L, lag_blocklens = NULL, ...) {
  domain <- match.arg(domain)
  if (prewhiten) {
    if (is.null(runs)) stop("'runs' must be supplied when prewhiten = TRUE.")
    res <- mppi_fit_whitened(Y = x, X = X, runs = runs, psych_idx = psych_idx,
                             basis = basis, domain = domain, deconv = deconv,
                             lags = lags, lag_blocklens = lag_blocklens, ...)
  } else {
    res <- mppi_fit(Y = x, X = X, psych_idx = psych_idx, runs = runs,
                    basis = basis, domain = domain, deconv = deconv,
                    lags = lags, lag_blocklens = lag_blocklens, ...)
  }
  res
}

#' @export
mppi.mppi_design <- function(x, Y, runs = NULL, prewhiten = FALSE,
                             basis = NULL, domain = c("bold","neural"),
                             deconv = NULL, lags = 0L, lag_blocklens = NULL, ...) {
  if (!is.matrix(Y)) stop("'Y' must be a matrix (time x V).")
  domain <- match.arg(domain)
  basis <- basis %||% x$basis
  if (is.null(basis)) {
    basis_obj <- NULL
    basis_source <- NULL
  } else {
    basis_obj <- .mppi_resolve_basis(Y, basis = basis, design = x)
    if (is.null(basis_obj)) {
      basis_source <- if (is.character(basis)) tolower(basis[[1L]]) else NULL
    } else {
      basis_source <- basis_obj$source %||% "provided"
    }
  }
  runs <- runs %||% x$runs
  if (is.null(runs) && !is.null(x$event_model)) {
    runs <- mppi_runs(x$event_model, T = nrow(Y))
  }
  if (prewhiten) {
    if (is.null(runs)) runs <- x$runs
    if (is.null(runs)) stop("'runs' must be provided for prewhitening.")
    res <- mppi_fit_whitened(Y = Y, X = x$X, runs = runs, psych_idx = x$psych_idx,
                             basis = basis_obj, domain = domain, deconv = deconv,
                             lags = lags, lag_blocklens = lag_blocklens, ...)
  } else {
    res <- mppi_fit(Y = Y, X = x$X, psych_idx = x$psych_idx, runs = runs,
                    basis = basis_obj, domain = domain, deconv = deconv,
                    lags = lags, lag_blocklens = lag_blocklens, ...)
  }
  if (!is.null(basis_source)) {
    res$basis_source <- basis_source
    if (!is.null(res$basis)) res$basis$source <- basis_source
  }
  res
}

#' @export
mppi.event_model <- function(x, Y = NULL, baseline_model = NULL, nuisance = NULL, dataset = NULL,
                             runs = NULL, prewhiten = FALSE, include_intercept = TRUE, basis = NULL,
                             domain = c("bold","neural"), deconv = NULL,
                             lags = 0L, lag_blocklens = NULL, ...) {
  domain <- match.arg(domain)
  design <- as_mppi_design(event = x, baseline = baseline_model, confounds = nuisance,
                           include_intercept = include_intercept, runs = runs, basis = basis)
  basis <- basis %||% design$basis
  runs <- runs %||% design$runs
  if (!is.null(dataset) && is.null(Y)) {
    return(mppi(dataset, design, runs = runs, prewhiten = prewhiten,
                basis = basis, domain = domain, deconv = deconv,
                lags = lags, lag_blocklens = lag_blocklens, ...))
  }
  if (is.null(Y)) stop("Provide either 'Y' or 'dataset' when calling mppi() with an event_model.")
  mppi(design, Y = Y, runs = runs, prewhiten = prewhiten,
       basis = basis, domain = domain, deconv = deconv,
       lags = lags, lag_blocklens = lag_blocklens, ...)
}

#' @export
mppi.fmridesign <- function(x, Y, basis = NULL, domain = c("bold","neural"),
                            prewhiten = FALSE, runs = NULL, deconv = NULL, ...) {
  if (!is.matrix(Y)) stop("'Y' must be a matrix (time x V).")
  domain <- match.arg(domain)
  T <- nrow(Y)
  info <- mppi_design(x, T = T)
  basis_input <- basis %||% x$basis
  if (!is.null(basis_input)) {
    basis_obj <- .mppi_resolve_basis(Y, basis = basis_input, design = x)
  } else {
    basis_obj <- NULL
  }
  runs_vec <- runs %||% info$runs
  if (is.null(runs_vec)) runs_vec <- rep_len(1L, T)
  if (length(runs_vec) != T) stop("Length of 'runs' must match number of time points.")

  nuisance_mat <- info$nuisance
  if (is.null(nuisance_mat)) nuisance_mat <- matrix(0, T, 0)
  X_task <- info$X_task
  if (nrow(X_task) != T) stop("Task design has incompatible number of rows.")
  X <- if (ncol(nuisance_mat)) cbind(nuisance_mat, X_task) else X_task
  psych_idx <- if (ncol(nuisance_mat)) seq.int(ncol(nuisance_mat) + 1L, ncol(X)) else seq_len(ncol(X))

  design_obj <- structure(list(X = X,
                               psych_idx = psych_idx,
                               runs = runs_vec,
                               basis = NULL),
                          class = "mppi_design")

  deconv_args <- deconv %||% list()
  if (!is.null(info$hrf) && is.null(deconv_args$hrf)) deconv_args$hrf <- info$hrf
  if (!is.null(info$TR)) {
    if (is.null(deconv_args$TR)) deconv_args$TR <- info$TR
    if (is.null(deconv_args$tr)) deconv_args$tr <- info$TR
  }

  fit <- mppi(design_obj, Y = Y, runs = runs_vec, prewhiten = prewhiten,
              basis = basis_obj, domain = domain, deconv = deconv_args, ...)
  fit$design <- info
  fit$design_source <- x
  if (!is.null(basis_obj)) {
    source_tag <- basis_obj$source %||% "provided"
    if (!is.null(fit$basis)) fit$basis$source <- source_tag
    fit$basis_source <- source_tag
  } else if (!is.null(basis_input) && is.character(basis_input)) {
    fit$basis_source <- tolower(basis_input[[1L]])
  }
  fit
}

#' @export
mppi.fmri_dataset <- function(x, fd, basis = NULL, domain = c("bold","neural"),
                              prewhiten = FALSE, runs = NULL, deconv = NULL,
                              r = NULL, ...) {
  domain <- match.arg(domain)
  Y <- NULL
  TR_ds <- NULL
  runs_ds <- runs
  if (inherits(x, "fmri_dataset") && requireNamespace("fmridataset", quietly = TRUE)) {
    Y <- fmridataset::get_data_matrix(x)
    TR_ds <- tryCatch(fmridataset::get_TR(x), error = function(e) NULL)
    if (is.null(runs_ds)) {
      run_lengths <- tryCatch(fmridataset::get_run_lengths(x), error = function(e) NULL)
      if (!is.null(run_lengths)) {
        runs_ds <- rep(seq_along(run_lengths), run_lengths)
      } else {
        runs_ds <- tryCatch(fmridataset::blockids(x), error = function(e) NULL)
      }
    }
  }
  if (is.null(Y)) {
    Y <- x$Y %||% x$timeseries %||% x$X
  }
  if (!is.matrix(Y)) stop("fmri_dataset must supply a matrix field (or support fmridataset accessors).")
  T <- nrow(Y)
  if (!is.null(runs_ds) && length(runs_ds) != T) stop("Dataset runs have incompatible length.")
  if (is.null(runs_ds)) runs_ds <- x$runs %||% attr(x, "runs")
  if (!is.null(runs_ds) && length(runs_ds) != T) stop("Dataset runs have incompatible length.")
  if (!is.null(runs_ds)) runs_ds <- as.integer(runs_ds)
  TR_ds <- TR_ds %||% x$TR %||% attr(x, "TR")
  TR_fd <- tryCatch(mppi_tr(fd), error = function(e) NULL)
  if (!is.null(TR_ds) && !is.null(TR_fd) && abs(TR_ds - TR_fd) > 1e-6) {
    stop("TR mismatch between dataset and design.", call. = FALSE)
  }
  basis_res <- .mppi_resolve_basis(Y, basis = basis, r = r, dataset = x, design = fd)
  basis_obj <- basis_res
  basis_source <- if (is.null(basis_obj)) {
    if (is.character(basis)) tolower(basis[[1L]]) else if (is.list(basis) && !is.null(basis$type)) tolower(basis$type) else "roi"
  } else {
    basis_obj$source %||% "provided"
  }
  fit <- mppi(fd, Y = Y, basis = basis_obj, domain = domain,
              prewhiten = prewhiten, runs = runs_ds, deconv = deconv, ...)
  fit$dataset <- x
  fit$basis_source <- basis_source
  if (!is.null(fit$basis)) fit$basis$source <- basis_source
  fit
}

#' @export
mppi.default <- function(x, ...) {
  stop(sprintf("No mppi() method for objects of class %s", paste(class(x), collapse = ", ")), call. = FALSE)
}

"%||%" <- function(a, b) if (is.null(a)) b else a

# Constructors --------------------------------------------------------------

# Print / summary ----------------------------------------------------------

print.mppi_design <- function(x, ...) {
  cat(sprintf("mppi_design: %d time points x %d regressors (%d psychological)\n",
              nrow(x$X), ncol(x$X), length(x$psych_idx)))
  if (!is.null(colnames(x$X))) {
    preview <- head(colnames(x$X)[x$psych_idx], 5L)
    cat("Psychological columns: ", paste(preview, collapse = ", "))
    if (length(x$psych_idx) > length(preview)) cat(", ...")
    cat("\n")
  }
  invisible(x)
}

print.mppi_fit <- function(x, ...) {
  cat(sprintf("mppi_fit: %d time points, %d regions, %d regressors\n",
              x$n_used, ncol(x$R), length(x$names)))
  basis_txt <- if (!is.null(x$basis)) sprintf(", basis=%s (r=%d)", x$basis$name, x$basis$r) else ""
  domain_txt <- sprintf(", domain=%s", x$domain %||% "bold")
  cat(sprintf("scale = %s, backend = %s, packed = %s%s%s\n",
              x$scale, x$backend, isTRUE(x$packed), basis_txt, domain_txt))
  energies <- vapply(x$Delta, .mppi_frob2, numeric(1))
  cat("Frobenius energy per regressor:\n")
  cat(paste0("  ", names(energies), ": ", format(energies, digits = 3)), sep = "\n")
  first <- x$Delta[[1]]
  if (!is.null(first)) {
    full <- if (is.list(first)) .mppi_unpack_upper(first) else first
    if (!all(is.na(full))) {
      eig <- eigen((full + t(full))/2, only.values = TRUE)$values
      cat("Top eigenvalues (regressor 1): ", paste(format(head(eig, 3), digits = 3), collapse = ", "), "\n")
    }
  }
  invisible(x)
}

summary.mppi_fit <- function(object, ...) {
  energies <- vapply(object$Delta, .mppi_frob2, numeric(1))
  res <- list(
    timepoints = object$n_used,
    regions = ncol(object$R),
    regressors = length(object$names),
    scale = object$scale,
    backend = object$backend,
    packed = isTRUE(object$packed),
    domain = object$domain %||% "bold",
    basis = if (!is.null(object$basis)) object$basis$name else NULL,
    basis_rank = if (!is.null(object$basis)) object$basis$r else NULL,
    energy = energies
  )
  class(res) <- "summary.mppi_fit"
  res
}

print.summary.mppi_fit <- function(x, ...) {
  cat(sprintf("mppi_fit summary: T=%d, V=%d, K=%d\n",
              x$timepoints, x$regions, x$regressors))
  base_line <- if (!is.null(x$basis)) sprintf(", basis=%s (r=%d)", x$basis, x$basis_rank) else ""
  cat(sprintf("scale=%s, backend=%s, packed=%s%s, domain=%s\n",
              x$scale, x$backend, x$packed, base_line, x$domain))
  cat("Frobenius energy:\n")
  cat(paste0("  ", names(x$energy), ": ", format(x$energy, digits = 3)), sep = "\n")
  invisible(x)
}

# HRF grouping --------------------------------------------------------------

mppi_group_hrf_columns <- function(design) {
  if (inherits(design, "mppi_design")) {
    idx <- design$psych_idx
    names_vec <- colnames(design$X)[idx]
  } else if (is.matrix(design)) {
    idx <- seq_len(ncol(design))
    names_vec <- colnames(design)
    if (is.null(names_vec)) stop("Provide column names when design is a matrix.")
  } else {
    stop("design must be an mppi_design or matrix with column names.")
  }
  keyfun <- function(nm) {
    if (grepl("^hrf", nm)) {
      if (grepl("\\(", nm)) {
        inside <- sub("^hrf[^\\(]*\\(([^\\)]+)\\).*", "\\1", nm)
        if (!identical(inside, nm) && nzchar(inside)) return(inside)
      }
      stripped <- sub("^hrf[TtDd]*", "", nm)
      stripped <- sub("^[\\._:]+", "", stripped)
      stripped <- sub("[\\._].*$", "", stripped)
      if (nzchar(stripped)) return(stripped)
    }
    sub("[\\._].*$", "", nm)
  }
  keys <- vapply(names_vec, keyfun, character(1))
split(idx, keys)
}
</file>

<file path="R/mppi_scale.R">
# Scale-aware helpers -------------------------------------------------------

#' Internal: compute scale factors for component time courses
#' @keywords internal
.mppi_sigma_cols <- function(X) {
  if (is.null(X)) stop("Scale factors unavailable: residual matrix missing.", call. = FALSE)
  sigma <- matrixStats::colSds(X)
  sigma[is.na(sigma) | sigma < 1e-12] <- 1e-12
  sigma
}

#' Internal: apply Edin-style scaling transforms
#' @keywords internal
.mppi_scale_matrix <- function(M, sigma, mode) {
  mode <- match.arg(mode, c("raw", "amplitude", "normalized"))
  if (mode == "raw") return(M)
  if (is.null(sigma)) stop("Scale factors unavailable for rescaling interaction matrix.", call. = FALSE)
  Sinv <- diag(1 / sigma, length(sigma), length(sigma))
  if (mode == "amplitude") {
    M %*% Sinv
  } else {
    Sinv %*% M %*% Sinv
  }
}

#' Retrieve an interaction matrix in a selected scale
#'
#' @param fit `mppi_fit` object
#' @param k regressor index or name
#' @param mode scale view: `"raw"`, `"amplitude"`, or `"normalized"`
#' @return matrix in the requested scale
#' @export
mppi_get_M_scaled <- function(fit, k, mode = c("raw", "amplitude", "normalized")) {
  mode <- match.arg(mode)
  Mk_raw <- mppi_get_M(fit, k)
  if (mode == "raw") return(Mk_raw)
  sigma <- fit$sigma
  if (is.null(sigma)) {
    base_matrix <- if (!is.null(fit$R_raw)) fit$R_raw else fit$R
    sigma <- .mppi_sigma_cols(base_matrix)
  }
  .mppi_scale_matrix(Mk_raw, sigma, mode)
}
</file>

<file path="R/mppi_sim_rest.R">
# Synthetic rest-state generators ----------------------------------------------

#' Simulate low-rank neural time-series with known modulators
#'
#' Generates latent component activity that depends linearly on supplied
#' oscillator-like modulators. The simulator constructs modulators with zero mean
#' and unit variance and injects symmetric coupling patterns so that
#' `mppi_rest()` can recover them.
#'
#' @param T Number of time points.
#' @param r Latent dimensionality (components).
#' @param contexts Character vector of context names.
#' @param amp Vector of coupling amplitudes per context.
#' @param freq Vector of temporal frequencies (in cycles / TR) for modulators.
#' @param noise_sd Standard deviation of additive white noise on latent series.
#' @param seed Optional seed for reproducibility.
#' @param templates Optional list of r x r matrices (one per context) specifying
#'   the coupling templates. Each matrix is symmetrised and scaled to unit
#'   Frobenius norm. When omitted, random symmetric templates are generated.
#' @return List with latent series `U`, modulators, and true coupling matrices.
#' @export
mppi_sim_rest_neural <- function(T = 600L, r = 6L,
                                 contexts = c("ctx1", "ctx2"),
                                 amp = rep(0.4, length(contexts)),
                                 freq = seq(0.01, length.out = length(contexts), by = 0.005),
                                 noise_sd = 0.02,
                                 seed = NULL,
                                 templates = NULL) {
  stopifnot(T > 0, r > 0)
  if (length(contexts) != length(amp)) {
    stop("Length of 'amp' must equal number of contexts.", call. = FALSE)
  }
  if (length(freq) != length(contexts)) {
    stop("Length of 'freq' must equal number of contexts.", call. = FALSE)
  }
  if (!is.null(seed)) set.seed(seed)
  K <- length(contexts)
  t_idx <- seq_len(T)
  # Build zero-mean unit-variance modulators (sine waves with random phases)
  phases <- runif(K, 0, 2 * pi)
  g_raw <- vapply(seq_len(K), function(k) {
    g <- sin(2 * pi * freq[k] * t_idx + phases[k])
    as.numeric(scale(g))
  }, numeric(T))
  colnames(g_raw) <- contexts
  modulators <- as.list(as.data.frame(g_raw))

  # Symmetric coupling templates (unit Frobenius)
  B_list <- vector("list", K)
  if (!is.null(templates)) {
    if (length(templates) != K) {
      stop("templates list must match number of contexts.", call. = FALSE)
    }
  }
  for (k in seq_len(K)) {
    if (!is.null(templates)) {
      Tk <- templates[[k]]
      if (!is.matrix(Tk) || any(dim(Tk) != c(r, r))) {
        stop("Each template must be an r x r matrix.", call. = FALSE)
      }
      S <- 0.5 * (Tk + t(Tk))
    } else {
      A <- matrix(rnorm(r * r), r, r)
      S <- 0.5 * (A + t(A))
    }
    fnorm <- sqrt(sum(S * S))
    if (fnorm < .Machine$double.eps) {
      S <- diag(r)
      fnorm <- sqrt(sum(S * S))
    }
    B_list[[k]] <- S / fnorm
  }
  names(B_list) <- contexts

  # Generate latent activity
  Z <- matrix(rnorm(T * r), T, r)
  U <- Z
  for (k in seq_len(K)) {
    U <- U + amp[k] * g_raw[, k] * (Z %*% B_list[[k]])
  }
  if (noise_sd > 0) {
    U <- U + matrix(rnorm(T * r, sd = noise_sd), T, r)
  }
  list(U = U,
       modulators = modulators,
       coupling = B_list,
       amp = amp,
       freq = freq)
}

#' Simulate observed resting-state dataset from latent components
#'
#' @param T Number of time points.
#' @param V Observed dimensionality (voxels/ROIs).
#' @param r Latent dimensionality.
#' @param hrf Optional HRF vector to convolve each latent component.
#' @param obs_noise Standard deviation of observation noise.
#' @param templates Optional list of coupling templates forwarded to
#'   [mppi_sim_rest_neural()].
#' @param ... Passed to [mppi_sim_rest_neural()].
#' @return List with observed matrix `Y`, latent `U`, modulators, loadings, and truth.
#' @export
mppi_sim_rest_dataset <- function(T = 600L, V = 40L, r = 6L,
                                  hrf = NULL, obs_noise = 0.05,
                                  templates = NULL, ...) {
  sim <- mppi_sim_rest_neural(T = T, r = r, templates = templates, ...)
  U <- sim$U
  if (!is.null(hrf)) {
    h <- as.numeric(hrf)
    if (!length(h)) stop("HRF must be a numeric vector.", call. = FALSE)
    conv_col <- function(x) stats::filter(c(x, rep(0, length(h))), h, sides = 1)[seq_len(length(x))]
    U <- apply(U, 2, conv_col)
  }
  L <- qr.Q(qr(matrix(rnorm(V * r), V, r)))
  Y <- U %*% t(L)
  if (obs_noise > 0) {
    Y <- Y + matrix(rnorm(T * V, sd = obs_noise), T, V)
  }
  mods <- sim$modulators
  truth <- list(coupling = sim$coupling,
                amp = sim$amp,
                freq = sim$freq,
                U = sim$U)
  list(Y = Y,
       U = sim$U,
       loadings = L,
       modulators = mods,
       truth = truth)
}

#' Simulate a cohort of resting datasets with trait-linked coupling
#'
#' @param n_subj Number of subjects.
#' @param trait Optional numeric vector of length `n_subj`.
#' @param trait_effect Numeric vector of per-context slopes mapping trait to
#'        coupling amplitude.
#' @param amp_base Baseline coupling amplitudes per context.
#' @param amp_noise SD of subject-level amplitude noise.
#' @param seed Optional seed for reproducibility.
#' @param templates Optional list of coupling templates applied to every subject.
#' @param ... Additional arguments passed to [mppi_sim_rest_dataset()] (shared across subjects).
#' @return List with `datasets`, `trait`, and subject-level amplitude table.
#' @export
mppi_sim_rest_cohort <- function(n_subj = 10L,
                                 trait = NULL,
                                 contexts = NULL,
                                 trait_effect = c(0.5, 0),
                                 amp_base = rep(0.3, length(trait_effect)),
                                 amp_noise = 0.05,
                                 seed = NULL,
                                 templates = NULL,
                                 ...) {
  if (!is.null(seed)) set.seed(seed)
  if (is.null(trait)) trait <- scale(rnorm(n_subj))[, 1]
  if (length(trait) != n_subj) stop("Trait length must equal n_subj.", call. = FALSE)
  if (is.null(contexts)) {
    contexts <- paste0("ctx", seq_along(trait_effect))
  }
  if (length(contexts) != length(trait_effect)) {
    stop("contexts and trait_effect must have the same length.", call. = FALSE)
  }
  if (length(amp_base) != length(trait_effect)) {
    stop("amp_base and trait_effect must have same length.", call. = FALSE)
  }
  amps <- matrix(NA_real_, n_subj, length(trait_effect), dimnames = list(NULL, contexts))
  datasets <- vector("list", n_subj)
  for (i in seq_len(n_subj)) {
    subj_amp <- amp_base + trait_effect * trait[i] + rnorm(length(trait_effect), sd = amp_noise)
    amps[i, ] <- subj_amp
    datasets[[i]] <- mppi_sim_rest_dataset(amp = subj_amp,
                                          contexts = contexts,
                                          templates = templates,
                                          ...)
  }
  list(datasets = datasets,
       trait = as.numeric(trait),
       amplitudes = amps)
}
</file>

<file path="R/mppi_utils.R">
# Internal helpers ---------------------------------------------------------

# Residualize a matrix Y on design Z using QR
.mppi_residualize <- function(Y, Z) {
  stopifnot(is.matrix(Y), is.matrix(Z), nrow(Y) == nrow(Z))
  qr_obj <- qr(Z)
  Y - qr.fitted(qr_obj, Y)
}

# Residualize a vector pk on Q using QR
.mppi_residualize_vec <- function(pk, Q) {
  stopifnot(is.numeric(pk), is.matrix(Q), length(pk) == nrow(Q))
  qr_obj <- qr(Q)
  as.numeric(pk - qr.fitted(qr_obj, pk))
}

# Center a vector within runs (if provided)
.mppi_center_by_run <- function(pk, runs) {
  if (is.null(runs)) return(pk)
  stopifnot(length(pk) == length(runs))
  split_idx <- split(seq_along(pk), runs)
  for (idx in split_idx) {
    pk[idx] <- pk[idx] - mean(pk[idx])
  }
  pk
}

.mppi_check_basis <- function(basis, V_dim) {
  if (is.null(basis)) return(NULL)
  if (inherits(basis, "mppi_basis")) {
    V <- basis$V
    if (nrow(V) != V_dim) stop(sprintf("basis$V must have %d rows to match data columns (got %d).", V_dim, nrow(V)))
    return(basis)
  }
  V <- if (is.list(basis) && !is.null(basis$V)) as.matrix(basis$V) else as.matrix(basis)
  if (nrow(V) != V_dim) stop(sprintf("basis$V must have %d rows to match data columns (got %d).", V_dim, nrow(V)))
  name <- if (is.list(basis) && !is.null(basis$name)) basis$name else "basis"
  # Orthonormalize columns (QR) for stability
  qrV <- qr(V)
  Q <- qr.Q(qrV)
  rank <- qrV$rank
  Q <- Q[, seq_len(rank), drop = FALSE]
  structure(list(V = Q, name = name, r = ncol(Q)), class = "mppi_basis")
}

.mppi_project_basis <- function(R, V, backend = c("blas","chunked"), chunk_cols = NULL) {
  backend <- match.arg(backend)
  if (backend == "blas" || is.null(chunk_cols)) {
    return(R %*% V)
  }
  if (chunk_cols <= 0) chunk_cols <- min(2048L, ncol(R))
  Z <- matrix(0, nrow(R), ncol(V))
  starts <- seq.int(1L, ncol(R), by = chunk_cols)
  for (st in starts) {
    ed <- min(ncol(R), st + chunk_cols - 1L)
    idx <- st:ed
    Z <- Z + R[, idx, drop = FALSE] %*% V[idx, , drop = FALSE]
  }
  Z
}

# Handle missing values across Y and X according to na_action
.mppi_handle_na <- function(Y, X, runs = NULL, na_action = c("omit_tr", "error")) {
  na_action <- match.arg(na_action)
  na_y <- which(rowSums(!is.na(Y)) != ncol(Y))
  na_x <- which(rowSums(!is.na(X)) != ncol(X))
  bad <- sort(unique(c(na_y, na_x)))
  n_drop <- length(bad)
  if (n_drop == 0) {
    return(list(Y = Y, X = X, runs = runs, dropped = 0L, dropped_idx = integer(0)))
  }
  if (na_action == "error") {
    stop(sprintf("mPPI inputs contain NA values in %d time points.", n_drop))
  }
  keep <- setdiff(seq_len(nrow(Y)), bad)
  list(
    Y = Y[keep, , drop = FALSE],
    X = X[keep, , drop = FALSE],
    runs = if (is.null(runs)) NULL else runs[keep],
    dropped = n_drop,
    dropped_idx = bad
  )
}

# Weighted crossproduct: R' diag(w) R
.mppi_wcp <- function(R, w) {
  stopifnot(is.matrix(R))
  w_vec <- as.numeric(w)
  stopifnot(length(w_vec) == nrow(R))
  crossprod(R, w_vec * R)
}

.mppi_crossprod <- function(R, pk, backend = c("blas", "accumulate", "chunked"), chunk_size = NULL) {
  backend <- match.arg(backend)
  if (backend == "blas") {
    return(.mppi_wcp(R, pk))
  }
  V <- ncol(R)
  D <- matrix(0, V, V)
  if (backend == "accumulate") {
    for (t in seq_len(nrow(R))) {
      rt <- R[t, , drop = FALSE]
      D <- D + pk[t] * crossprod(rt)
    }
  } else {
    if (is.null(chunk_size) || chunk_size <= 0) chunk_size <- min(2048L, nrow(R))
    starts <- seq.int(1L, nrow(R), by = chunk_size)
    for (st in starts) {
      ed <- min(st + chunk_size - 1L, nrow(R))
      idx <- st:ed
      Rblock <- R[idx, , drop = FALSE]
      D <- D + crossprod(Rblock, pk[idx] * Rblock)
    }
  }
  D <- (D + t(D)) / 2
  D
}

.mppi_crossprod_lagged <- function(R, pk, lag, blocklens = NULL,
                                    backend = c("blas", "accumulate", "chunked"),
                                    chunk_size = NULL) {
  lag <- as.integer(lag)
  if (lag == 0L) return(.mppi_crossprod(R, pk, match.arg(backend), chunk_size))
  backend <- match.arg(backend)
  Tn <- nrow(R)
  V <- ncol(R)
  if (abs(lag) >= Tn) {
    return(matrix(NA_real_, V, V))
  }
  if (is.null(blocklens)) {
    if (lag > 0L) {
      idx <- seq_len(Tn - lag)
      R0 <- R[idx, , drop = FALSE]
      R1 <- R[idx + lag, , drop = FALSE]
      wk <- pk[idx]
    } else {
      shift <- abs(lag)
      idx <- seq_len(Tn - shift)
      R0 <- R[idx + shift, , drop = FALSE]
      R1 <- R[idx, , drop = FALSE]
      wk <- pk[idx]
    }
    denom <- sum(wk^2)
    if (denom < .Machine$double.eps) {
      return(matrix(NA_real_, V, V))
    }
    return(crossprod(R0, wk * R1) / denom)
  }
  blocklens <- as.integer(blocklens)
  accum <- matrix(0, V, V)
  denom_total <- 0
  start <- 1L
  for (L in blocklens) {
    if (lag > 0L) {
      if (L > lag) {
        rng <- seq.int(start, start + L - lag - 1L)
        R0 <- R[rng, , drop = FALSE]
        R1 <- R[rng + lag, , drop = FALSE]
        wk <- pk[rng]
        accum <- accum + crossprod(R0, wk * R1)
        denom_total <- denom_total + sum(wk^2)
      }
    } else {
      shift <- abs(lag)
      if (L > shift) {
        rng <- seq.int(start + shift, start + L - 1L)
        R0 <- R[rng, , drop = FALSE]
        R1 <- R[rng - shift, , drop = FALSE]
        wk <- pk[rng - shift]
        accum <- accum + crossprod(R0, wk * R1)
        denom_total <- denom_total + sum(wk^2)
      }
    }
    start <- start + L
  }
  if (denom_total < .Machine$double.eps) {
    return(matrix(NA_real_, V, V))
  }
  accum / denom_total
}

.mppi_pack_upper <- function(M) {
  stopifnot(is.matrix(M), nrow(M) == ncol(M))
  V <- ncol(M)
  idx <- upper.tri(M, diag = TRUE)
  list(values = M[idx], dim = V)
}

.mppi_unpack_upper <- function(packed) {
  V <- packed$dim
  M <- matrix(0, V, V)
  idx <- upper.tri(M, diag = TRUE)
  M[idx] <- packed$values
  M[lower.tri(M)] <- t(M)[lower.tri(M)]
  M
}

.mppi_row_outer_packed <- function(R) {
  V <- ncol(R)
  idx <- upper.tri(matrix(0, V, V), diag = TRUE)
  P <- sum(idx)
  out <- matrix(0, nrow(R), P)
  for (t in seq_len(nrow(R))) {
    Rt <- R[t, , drop = FALSE]
    out[t, ] <- (crossprod(Rt))[idx]
  }
  out
}

.mppi_frob2 <- function(M) {
  if (is.list(M) && all(c("values","dim") %in% names(M))) {
    sum(M$values^2, na.rm = TRUE)
  } else {
    sum(M^2, na.rm = TRUE)
  }
}

.mppi_phase_randomize_seg <- function(x) {
  n <- length(x)
  if (n <= 2L) return(x)
  Fx <- fft(x)
  half <- floor(n / 2)
  for (k in seq.int(2L, half)) {
    angle <- runif(1, 0, 2 * pi)
    mag <- Mod(Fx[k])
    Fx[k] <- mag * exp(1i * angle)
    conj_idx <- n - k + 2L
    if (conj_idx <= length(Fx)) {
      Fx[conj_idx] <- Conj(Fx[k])
    }
  }
  if (n %% 2 == 0) {
    idx <- half + 1L
    Fx[idx] <- Mod(Fx[idx]) * exp(1i * runif(1, 0, 2 * pi))
  }
  Re(fft(Fx, inverse = TRUE) / n)
}

.mppi_phase_randomize <- function(pk, runs = NULL) {
  if (is.null(runs)) runs <- rep(1L, length(pk))
  stopifnot(length(pk) == length(runs))
  out <- pk
  idx <- split(seq_along(pk), runs)
  for (g in idx) {
    out[g] <- .mppi_phase_randomize_seg(pk[g])
  }
  out
}

# Internal: detect if a design already contains an intercept-like column
.mppi_has_intercept <- function(X) {
  stopifnot(is.matrix(X))
  if ("(Intercept)" %in% colnames(X)) return(TRUE)
  any(apply(X, 2, function(z) {
    sd_z <- stats::sd(z)
    (is.na(sd_z) || sd_z < .Machine$double.eps) && abs(mean(z) - 1) < 1e-8
  }))
}

# Prepare a design matrix, ensuring an intercept column and adjusting indices
.mppi_prepare_design_matrix <- function(X, psych_idx = NULL) {
  stopifnot(is.matrix(X))
  if (.mppi_has_intercept(X)) {
    return(list(X = X,
                psych_idx = if (is.null(psych_idx)) psych_idx else sort(unique(as.integer(psych_idx))),
                intercept_added = FALSE))
  }
  X_new <- cbind(`(Intercept)` = 1, X)
  idx_new <- if (is.null(psych_idx)) psych_idx else sort(unique(as.integer(psych_idx))) + 1L
  list(X = X_new, psych_idx = idx_new, intercept_added = TRUE)
}

# Backwards-compatible helper used by legacy code paths
.mppi_with_intercept <- function(X) {
  .mppi_prepare_design_matrix(X)$X
}

# Public helper: select psychological regressors by name or regex
#' Select psychological regressors from a design matrix
#' @param X design matrix (T x q)
#' @param patterns character vector of regex patterns (applied to colnames(X))
#' @param names_or_idx specific names or integer indices
#' @return integer vector of column indices
mppi_select_psych <- function(X, patterns = NULL, names_or_idx = NULL) {
  stopifnot(is.matrix(X))
  if (!is.null(names_or_idx)) {
    if (is.character(names_or_idx)) return(match(names_or_idx, colnames(X)))
    if (is.numeric(names_or_idx))   return(names_or_idx)
  }
  if (is.null(patterns)) stop("Provide either names_or_idx or patterns to select psychological regressors.")
  keep <- unique(unlist(lapply(patterns, function(p) grep(p, colnames(X), perl = TRUE))))
  if (length(keep) == 0) stop("No design columns matched your patterns.")
  keep
}

# Shift a vector within run blocks by an integer lag
.mppi_shift_by_run <- function(x, lag, blocklens) {
  if (lag == 0 || length(blocklens) == 0) return(x)
  out <- x
  start <- 1L
  for (L in blocklens) {
    rng <- start:(start + L - 1L)
    seg <- x[rng]
    if (abs(lag) >= L) {
      out[rng] <- 0
    } else if (lag > 0) {
      out[rng] <- c(rep(0, lag), seg[1:(L - lag)])
    } else {
      out[rng] <- c(seg[(1 - lag):L], rep(0, -lag))
    }
    start <- start + L
  }
  out
}
</file>

<file path="R/mppi_viz.R">
# Visualization helpers ----------------------------------------------------

#' Leading eigenmodes of interaction structure
#'
#' For matrix inputs the symmetric eigenmodes are returned. When supplied with an
#' `mppi_fit`, the communication subspace across conditions is estimated using the
#' requested scale view and optional ridge penalty.
#'
#' @param Delta interaction matrix or `mppi_fit`
#' @param r number of modes to retain
#' @param view scale view when `Delta` is an `mppi_fit`
#' @param penalty aggregate penalty for the communication subspace
#' @param lambda ridge strength when `penalty = "ridge"`
#' @return list containing eigenvalues/vectors and, for fits, per-condition projections
mppi_modes <- function(Delta, r = 3L, view = c("normalized", "raw", "amplitude"),
                       penalty = c("none", "ridge"), lambda = 1e-4) {
  if (inherits(Delta, "mppi_fit")) {
    view <- match.arg(view)
    penalty <- match.arg(penalty)
    mats <- lapply(seq_along(Delta$names), function(idx) mppi_get_M_scaled(Delta, idx, mode = view))
    if (!length(mats)) stop("Fit does not contain interaction matrices.", call. = FALSE)
    A <- Reduce(`+`, lapply(mats, function(M) M %*% t(M)))
    A <- 0.5 * (A + t(A))
    if (penalty == "ridge") {
      A <- A + lambda * diag(nrow(A))
    }
    ev <- eigen(A, symmetric = TRUE)
    keep <- seq_len(min(r, length(ev$values)))
    W <- ev$vectors[, keep, drop = FALSE]
    base_names <- rownames(mats[[1]])
    if (!is.null(base_names)) rownames(W) <- base_names
    colnames(W) <- paste0("mode", seq_along(keep))
    k <- length(keep)
    lab <- colnames(W)
    projected <- lapply(mats, function(M) {
      P <- crossprod(W, M %*% W)
      if (!is.matrix(P) || nrow(P) != k || ncol(P) != k) {
        P <- matrix(P, nrow = k, ncol = k)
      }
      if (!is.null(lab) && length(lab) == k) {
        dimnames(P) <- list(lab, lab)
      }
      P
    })
    names(projected) <- Delta$names
    list(values = ev$values[keep], vectors = W,
         projected = projected, view = view, penalty = penalty)
  } else {
    r <- max(1L, r)
    ev <- eigen((Delta + t(Delta))/2, symmetric = TRUE)
    keep <- seq_len(min(r, length(ev$values)))
    list(values = ev$values[keep], vectors = ev$vectors[, keep, drop = FALSE])
  }
}

#' Nodewise degree of modulation (L1 or L2)
mppi_degree <- function(Delta, type = c("L1","L2")) {
  type <- match.arg(type)
  A <- abs(Delta)
  if (type == "L1") rowSums(A, na.rm = TRUE) else sqrt(rowSums(A^2, na.rm = TRUE))
}

#' Project ΔΣ onto a hypothesis mask W (VxV)
mppi_project <- function(Delta, W) {
  stopifnot(all(dim(Delta) == dim(W)))
  sum(Delta * W, na.rm = TRUE)
}
</file>

<file path="R/RcppExports.R">
# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

deconv_dct_multi <- function(Y, h, K = 64L, q_in = NULL, method = "gcv", lambda_fixed = 1e-1, ngrid = 30L, lam_lo = 1e-6, lam_hi = 1e+6) {
    .Call(`_multiPPI_deconv_dct_multi`, Y, h, K, q_in, method, lambda_fixed, ngrid, lam_lo, lam_hi)
}

mppi_deconv_map <- function(Y, h, lambda) {
    .Call(`_multiPPI_mppi_deconv_map`, Y, h, lambda)
}
</file>

<file path="R/zzz.R">
# Package hooks ---------------------------------------------------------------

#' @useDynLib multiPPI, .registration = TRUE
#' @importFrom Rcpp sourceCpp
NULL
</file>

<file path="tests/testthat/test_adv_methods.R">
context("Advanced mechanistic methods")

make_fit <- function(U, pk) {
  structure(list(U = U, pk = list(pk), names = "task"), class = "mppi_fit")
}

test_that("mppi_innovations respects AR order and low-frequency protection", {
  set.seed(1)
  U <- matrix(rnorm(80), nrow = 40, ncol = 2)
  E <- mppi_innovations(U, protect = "none", ar_order = "fixed", p = 0L, center = FALSE)
  expect_equal(E, U, check.attributes = FALSE)

  slow <- rep(1, 40)
  fast <- sin(seq(0, 4 * pi, length.out = 40))
  U2 <- cbind(slow, fast)
  E2 <- mppi_innovations(U2, protect = "lowK", K_keep = 1L,
                         ar_order = "fixed", p = 0L, center = FALSE)
  expect_equal(E2[, 1], slow, tolerance = 1e-10)

  expect_error(mppi_innovations(U2, protect = "lowHz", f_cut = 0.05,
                                ar_order = "auto"),
               "TR required", fixed = TRUE)

  Eauto <- mppi_innovations(U2, TR = 0.8, protect = "lowHz", f_cut = 0.05,
                            ar_order = "auto", center = TRUE)
  expect_equal(attr(Eauto, "orders") >= 0L, rep(TRUE, ncol(U2)))
})

test_that("spectral and precision summaries recover analytical values", {
  U <- matrix(c(1, 0,
                0, 1), nrow = 2, byrow = TRUE)
  pk <- c(1, 0)
  fit <- make_fit(U, pk)
  spec <- mppi_spectral_summary(fit, 1L)
  expect_equal(spec$lambda1_share, 1, tolerance = 1e-10)
  expect_equal(spec$effrank, 1, tolerance = 1e-8)
  expect_equal(spec$sign_balance, 1)

  prec <- mppi_precision_delta(fit, 1L, lambda = 1e-3)
  Mk <- crossprod(U, pk * U) / sum(pk^2)
  S0 <- crossprod(U) / nrow(U)
  Theta0 <- solve(S0 + diag(1e-3, ncol(S0)))
  dTheta <- -Theta0 %*% Mk %*% Theta0
  expect_equal(prec$dTheta, dTheta)
  expect_equal(prec$offdiag_energy, 0, tolerance = 1e-12)
})

test_that("lagged summaries match manual calculations", {
  U <- matrix(c(1, 0,
                0, 1), nrow = 2, byrow = TRUE)
  pk <- c(1, 0)
  fit <- make_fit(U, pk)
  attr(fit$U, "TR") <- 1

  lag_neural <- mppi_lagged(fit, 1L, lags = -1:1, mode = "neural")
  expect_equal(lag_neural$M_lag[["0"]], crossprod(U, pk * U) / sum(pk^2))
  expect_equal(lag_neural$M_lag[["1"]][1, 2], 1)
  expect_equal(lag_neural$M_lag[["-1"]][2, 1], 1)
  expect_equal(lag_neural$R, 0)

  lag_innov <- mppi_lagged(fit, 1L, lags = -1:1, mode = "innov",
                           protect = "none", ar_order = "fixed", p = 0L)
  expect_equal(lag_innov$M_lag, lag_neural$M_lag)
})

test_that("mppi_classify captures gain-dominated patterns", {
  set.seed(2)
  Tn <- 40L
  pk <- rep(c(1, 0), length.out = Tn)
  U <- cbind(pk, rnorm(Tn, sd = 1e-3))
  fit <- make_fit(U, pk)
  lab <- mppi_classify(fit, 1L, lambda = 1e-3, lags = -1:1,
                       mode = "neural", B = 30L, seed = 11)
  expect_true(lab$G > 0.8)
  expect_lt(lab$C, 1e-2)
  expect_lt(abs(lab$R), 1e-6)
  expect_equal(lab$lagged$R, lab$R)

  lab_innov <- mppi_classify(fit, 1L, lambda = 1e-3, lags = -1:1,
                             mode = "innov", B = 30L, seed = 12)
  expect_equal(lab_innov$label, lab$label)
})

test_that("state-dependent PPI returns trial summaries with nuisances", {
  set.seed(3)
  Tn <- 60L
  U <- matrix(rnorm(Tn * 3), nrow = Tn, ncol = 3)
  pk <- rep(c(1, -1), length.out = Tn)
  fit <- make_fit(U, pk)
  runs <- rep(1:3, each = 20)
  onsets <- c(10L, 20L, 30L, 40L, 50L)
  gs <- sin(seq(0, 2 * pi, length.out = Tn))
  sd <- mppi_sdppi_fit(fit, 1L, onsets_idx = onsets, runs = runs,
                       Wpre = 4L, Wpost = 4L, mode = "neural",
                       nuisance_ts = list(GS = gs))
  expect_equal(nrow(sd$data), length(onsets))
  expect_true(all(c("pre_lambda1_share", "ppi_energy", "run") %in% colnames(sd$data)))
  expect_true(ncol(sd$data) >= 10)
  expect_s3_class(sd$model_ppi, "lm")
  expect_true(is.numeric(sd$cv_r))

  attr(fit$U, "TR") <- 0.8
  sd_innov <- mppi_sdppi_fit(fit, 1L, onsets_idx = onsets, runs = runs,
                             Wpre = 4L, Wpost = 4L, mode = "innov",
                             protect = "lowHz", f_cut = 0.05)
  expect_equal(nrow(sd_innov$data), length(onsets))
})

test_that("null onsets avoid guarded windows", {
  set.seed(4)
  obs <- c(10L, 30L)
  guard <- 4L
  null_idx <- mppi_make_null_onsets(60L, obs, guard = guard)
  expect_equal(length(null_idx), length(obs))
  expect_true(all(abs(outer(null_idx, obs, "-")) > guard))

  expect_error(mppi_make_null_onsets(12L, c(4L, 8L), guard = 5L),
               "Not enough candidate TRs", fixed = TRUE)
})

test_that("state predictors provide cross-validated performance", {
  set.seed(5)
  Tn <- 60L
  U <- matrix(rnorm(Tn * 2), nrow = Tn, ncol = 2)
  pk <- rep(c(1, 0), length.out = Tn)
  fit <- make_fit(U, pk)
  runs <- rep(1:3, each = 20)
  onsets <- c(12L, 24L, 36L, 48L)
  sd <- mppi_sdppi_fit(fit, 1L, onsets_idx = onsets, runs = runs,
                       Wpre = 4L, Wpost = 4L, mode = "neural")
  res_gauss <- mppi_state_predict(sd$data, sd$data$ppi_energy, runs = sd$data$run,
                                  family = "gaussian")
  expect_true(is.numeric(res_gauss$cv_r))
  y_bin <- as.integer(sd$data$ppi_energy > median(sd$data$ppi_energy))
  res_bin <- mppi_state_predict(sd$data, y_bin, runs = sd$data$run,
                                family = "binomial")
  expect_true(is.numeric(res_bin$cv_auc) || is.na(res_bin$cv_auc))

  res_bin_flat <- mppi_state_predict(sd$data, rep(1L, nrow(sd$data)),
                                     runs = sd$data$run, family = "binomial")
  expect_true(is.na(res_bin_flat$cv_auc))
})

test_that("theta metrics and gating provide interpretable summaries", {
  Theta0 <- matrix(c(2, -1,
                     -1, 2), nrow = 2, byrow = TRUE)
  mts <- mppi_theta_metrics(Theta0)
  expect_true(mts$alg_conn >= 0)
  expect_true(mts$effrankA >= 1)
  expect_true(is.na(mts$Qmax) || mts$Qmax >= 0)
  expect_true(mts$comm_avg >= 0)

  set.seed(6)
  fits <- replicate(3, {
    base <- rnorm(30)
    U <- cbind(base, base + rnorm(30, sd = 0.2))
    pk <- rnorm(30)
    make_fit(U, pk)
  }, simplify = FALSE)
  gate <- mppi_gate_by_theta(fits, 1L, controls = data.frame(tSNR = c(90, 100, 110)))
  expect_equal(nrow(gate$data), length(fits))
  expect_true(all(c("G", "C", "alg_conn", "effrankA") %in% names(gate$data)))
  expect_s3_class(gate$model_G, "lm")
  expect_s3_class(gate$model_C, "lm")
})
</file>

<file path="tests/testthat/test_algorithms.R">
test_that("mppi_fit reproduces closed-form covariance regression", {
  set.seed(42)
  Tn <- 60L; V <- 4L
  conf <- as.numeric(scale(rnorm(Tn), scale = FALSE))
  psych <- as.numeric(scale(rnorm(Tn), scale = FALSE))
  X <- cbind(Intercept = 1, conf = conf, psych = psych)
  Y <- matrix(rnorm(Tn * V), Tn, V)

  fit <- mppi_fit(Y, X, psych_idx = 3L, zero_diag = FALSE, scale = "cov")

  R_manual <- multiPPI:::`.mppi_residualize`(Y, X)
  Q <- X[, 1:2, drop = FALSE]
  pk_manual <- multiPPI:::`.mppi_residualize_vec`(X[, 3], Q)
  Delta_manual <- multiPPI:::`.mppi_wcp`(R_manual, pk_manual) / sum(pk_manual^2)

  expect_equal(fit$Delta[[1]], Delta_manual, tolerance = 1e-10)
  expect_equal(fit$R, R_manual, tolerance = 1e-10)
  expect_equal(fit$pk[[1]], pk_manual, tolerance = 1e-10)
})

test_that("HRF adaptive combination follows dominant energy direction", {
  Delta1 <- diag(c(1, 0))
  Delta2 <- diag(c(0, 4))
  combo <- mppi_hrf_adapt(list(Delta1, Delta2), pk_norms = c(1, 1), normalize = TRUE)
  expect_equal(combo$weights[1], 0, tolerance = 1e-10)
  scale_factor <- sum(combo$Delta * Delta2) / sum(Delta2^2)
  expect_equal(abs(scale_factor), 1, tolerance = 1e-8)
})

test_that("mppi_modes handles requested ranks", {
  Delta <- matrix(c(2, 1, 1, 2), 2, 2)
  res1 <- mppi_modes(Delta, r = 5L)
  expect_length(res1$values, 2L)
  expect_equal(ncol(res1$vectors), 2L)

  res2 <- mppi_modes(Delta, r = 1L)
  expect_length(res2$values, 1L)
  expect_equal(ncol(res2$vectors), 1L)
})

test_that("mppi_degree returns L1 and L2 summaries", {
  Delta <- matrix(c(0, 2, -3, 4), 2, 2)
  d1 <- mppi_degree(Delta, type = "L1")
  d2 <- mppi_degree(Delta, type = "L2")
  expect_equal(d1, rowSums(abs(Delta)))
  expect_equal(d2, sqrt(rowSums(Delta^2)))
})

test_that("accumulate backend matches blas backend", {
  set.seed(555)
  Tn <- 50L; V <- 4L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  fit_blas <- mppi_fit(Y, X, psych_idx = 2L, backend = "blas")
  fit_acc  <- mppi_fit(Y, X, psych_idx = 2L, backend = "accumulate")
  expect_equal(fit_blas$Delta[[1]], fit_acc$Delta[[1]], tolerance = 1e-10)
})

test_that("chunked backend matches blas backend", {
  set.seed(556)
  Tn <- 80L; V <- 5L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  fit_blas <- mppi_fit(Y, X, psych_idx = 2L, backend = "blas")
  fit_chunk <- mppi_fit(Y, X, psych_idx = 2L, backend = "chunked", chunk_size = 16L)
  expect_equal(fit_blas$Delta[[1]], fit_chunk$Delta[[1]], tolerance = 1e-8)
})

test_that("chunked basis projection matches blas projection", {
  set.seed(557)
  Tn <- 50L; V <- 6L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  basis <- as_mppi_basis(qr.Q(qr(matrix(rnorm(V * 4L), V, 4L))), name = "randPCA")
  fit_blas <- mppi_fit(Y, X, psych_idx = 2L, basis = basis,
                       backend = "blas", project_backend = "blas")
  fit_chunk <- mppi_fit(Y, X, psych_idx = 2L, basis = basis,
                        backend = "chunked", chunk_size = 16L,
                        project_backend = "chunked", project_chunk_cols = 2L)
  expect_equal(mppi_get_M(fit_blas, 1L), mppi_get_M(fit_chunk, 1L), tolerance = 1e-8)
})

test_that("variance decomposition and partial outputs present for cov scale", {
  set.seed(42)
  Tn <- 40L; V <- 3L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  fit <- mppi_fit(Y, X, psych_idx = 2L, scale = "cov")
  expect_true(!is.null(fit$Sigma0))
  expect_true(!is.null(fit$variance))
  expect_true(!is.null(fit$partial))
  expect_true("DeltaRho" %in% names(fit$partial[[1]]))
})

test_that("packed option stores upper triangle", {
  set.seed(77)
  Tn <- 30L; V <- 3L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  fit_packed <- mppi_fit(Y, X, psych_idx = 2L, packed = TRUE)
  expect_true(fit_packed$packed)
  packed_entry <- fit_packed$Delta[[1]]
  expect_type(packed_entry, "list")
  expect_true(all(c("values","dim") %in% names(packed_entry)))
  fit_full <- mppi_fit(Y, X, psych_idx = 2L, packed = FALSE)
  unpacked <- multiPPI:::`.mppi_unpack_upper`(packed_entry)
  expect_equal(unpacked, fit_full$Delta[[1]], tolerance = 1e-10)
  # round trip pack -> unpack -> pack
  repacked <- multiPPI:::`.mppi_pack_upper`(unpacked)
  expect_equal(repacked$values, packed_entry$values)
  expect_equal(repacked$dim, packed_entry$dim)
})

test_that("mppi matrix method returns mppi_fit", {
  set.seed(88)
  Tn <- 40L; V <- 3L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  pidx <- 2L
  fit <- mppi(Y, X, psych_idx = pidx)
  expect_s3_class(fit, "mppi_fit")
})

test_that("basis projection matches full-space Δ", {
  set.seed(101)
  Tn <- 60L; V <- 8L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  pidx <- 2L
  full <- mppi_fit(Y, X, psych_idx = pidx, backend = "blas")
  Vbasis <- as_mppi_basis(diag(V), name = "identity")
  fit_basis <- mppi_fit(Y, X, psych_idx = pidx, basis = Vbasis,
                        backend = "chunked", chunk_size = 16L,
                        project_backend = "chunked", project_chunk_cols = 4L)
  M <- mppi_get_M(fit_basis, 1L)
  Delta_full <- mppi_get_M(full, 1L)
  recon <- Vbasis$V %*% M %*% t(Vbasis$V)
  diag(recon) <- 0
  diag(Delta_full) <- 0
  expect_equal(recon, Delta_full, tolerance = 1e-6)
  submat <- mppi_reconstruct_delta(fit_basis, 1L, rows = 1:3, cols = 5:7)
  expect_equal(submat, recon[1:3, 5:7], tolerance = 1e-6)
})

test_that("Precision update matches first-order matrix inverse", {
  Sigma0 <- matrix(c(2, 0.3, 0.3, 1.5), 2, 2)
  DeltaSigma <- matrix(c(0.2, -0.1, -0.1, 0.3), 2, 2)
  lambda <- 1e-3
  Theta0 <- solve(Sigma0 + lambda * diag(2))

  DeltaTheta <- mppi_to_partial(Sigma0, DeltaSigma, lambda = lambda)

  eps <- 1e-4
  Theta_exact <- solve(Sigma0 + eps * DeltaSigma + lambda * diag(2))
  Theta_linear <- Theta0 + eps * DeltaTheta
  expect_equal(Theta_linear, Theta_exact, tolerance = 1e-6)
})

test_that("Variance decomposition reconstructs DeltaSigma", {
  set.seed(99)
  Tn <- 80L; V <- 3L
  pk <- as.numeric(scale(rnorm(Tn), scale = FALSE))
  base <- matrix(rnorm(Tn * V), Tn, V)
  R <- sweep(base, 1, 1 + 0.3 * pk, `*`)
  DeltaSigma <- multiPPI:::`.mppi_wcp`(R, pk) / sum(pk^2)

  parts <- mppi_decompose_variance(R, pk, DeltaSigma)
  recon <- (apply(R, 2, sd) %o% apply(R, 2, sd)) * parts$Delta_rho + parts$variance_terms
  expect_equal(recon, DeltaSigma, tolerance = 1e-8)
})

test_that("Rank CV prefers low-rank structure", {
  set.seed(2024)
  Tn <- 70L; V <- 5L
  tvec <- seq_len(Tn) / Tn
  coeff <- runif(V, 0.5, 1.5)
  R <- as.matrix(tvec %o% coeff)
  pk <- rep(1, Tn)
  Delta <- multiPPI:::`.mppi_wcp`(R, pk) / sum(pk^2)

  cv <- mppi_rank_cv(R, pk, Delta, holdout_frac = 0.25, R_reps = 3)
  expect_equal(cv$r, 1L)
})
</file>

<file path="tests/testthat/test_band_beta_hrf.R">
context("Bandpass, beta-series, HRF adaptive helpers")

set.seed(123)

# Bandpass -----------------------------------------------------------------

test_that("mppi_bandpass preserves dimensions and attenuates highs", {
  Tn <- 120
  t <- seq(0, 2*pi, length.out = Tn)
  slow <- sin(t)
  fast <- sin(10 * t)
  X <- cbind(slow = slow + fast, fast = fast)
  X_lp <- mppi_bandpass(X, low = NULL, high = 0.2)
  expect_equal(dim(X_lp), dim(X))
  # Low-pass should retain more slow energy than fast column
  slow_var <- var(X_lp[,1])
  fast_var <- var(X_lp[,2])
  expect_gt(slow_var, fast_var)
})

test_that("mppi_fit_multi_band returns fits per band", {
  Tn <- 60; V <- 4
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(1, sin(seq(0, pi, length.out = Tn)))
  pidx <- 2L
  bands <- list(list(low = NULL, high = 0.1, name = "low"),
                list(low = 0.15, high = NULL, name = "high"))
  fits <- mppi_fit_multi_band(Y, X, psych_idx = pidx, bands = bands)
  expect_named(fits, c("low", "high"))
  expect_equal(length(fits$low$Delta), 1L)
  expect_equal(dim(fits$low$Delta[[1]]), c(V, V))
})

# Beta-series ---------------------------------------------------------------

test_that("mppi_fit_beta and permutations run on toy data", {
  n_trials <- 12; V <- 3
  B <- matrix(rnorm(n_trials * V), n_trials, V)
  runs <- rep(1:3, length.out = n_trials)
  Pbeta <- matrix(rnorm(n_trials), ncol = 1)
  colnames(Pbeta) <- "psych"
  fit_beta <- mppi_fit_beta(B, Pbeta, scale = "cov")
  expect_equal(length(fit_beta$Delta), 1L)
  perm_beta <- mppi_beta_permute(B, Pbeta, run_trial = runs, Bperm = 19)
  expect_equal(length(perm_beta), 1L)
  expect_true(is.finite(perm_beta[[1]]$p_global))
})

# HRF adaptive --------------------------------------------------------------

test_that("mppi_hrf_adapt outputs combined matrix and weights", {
  V <- 3
  Delta1 <- diag(V)
  Delta2 <- diag(V); Delta2[1,2] <- Delta2[2,1] <- 0.5
  combo <- mppi_hrf_adapt(list(Delta1, Delta2), pk_norms = c(2, 1))
  expect_equal(length(combo$weights), 2L)
  expect_true(any(combo$weights != 0))
  expect_equal(dim(combo$Delta), c(V, V))
})
</file>

<file path="tests/testthat/test_band_partial.R">
test_that("mppi_bandpass falls back to moving-average smoothing when signal missing", {
  set.seed(1)
  Tn <- 200L
  t <- seq_len(Tn)
  raw <- sin(2 * pi * t / 10) + 0.3 * sin(2 * pi * t / 2) # fast + slow
  X <- cbind(raw = raw)

  smoothed <- with_mocked_bindings(
    mppi_bandpass(X, low = NULL, high = 0.1, order = 2L),
    requireNamespace = function(pkg, quietly = TRUE) FALSE,
    .package = "base"
  )

  expect_equal(dim(smoothed), dim(X))
  # High-frequency energy should shrink after smoothing
  fft_raw <- Mod(stats::fft(X[,1]))
  fft_smooth <- Mod(stats::fft(smoothed[,1]))
  hf_idx <- 20:40
  expect_true(mean(fft_smooth[hf_idx]) < mean(fft_raw[hf_idx]))
})

test_that("mppi_fit_multi_band returns per-band fits", {
  set.seed(2)
  Tn <- 80L; V <- 3L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  bands <- list(list(low = NULL, high = 0.1, name = "low"),
                list(low = 0.1, high = 0.3, name = "mid"))

  fits <- mppi_fit_multi_band(Y, X, psych_idx = 2L, bands = bands, scale = "cov")
  expect_named(fits, c("low", "mid"))
  expect_true(all(vapply(fits, function(f) is.list(f) && length(f$Delta) == 1, logical(1))))
})

test_that("mppi_delta_partial rescales precision deltas to partial correlations", {
  set.seed(3)
  Sigma0 <- matrix(c(1, 0.2, 0.2, 1), 2, 2)
  DeltaSigma <- matrix(c(0.05, -0.04, -0.04, 0.03), 2, 2)
  lambda <- 1e-3
  DeltaTheta <- mppi_to_partial(Sigma0, DeltaSigma, lambda = lambda)
  Theta0 <- solve(Sigma0 + lambda * diag(2))
  DeltaRho <- mppi_delta_partial(Theta0, DeltaTheta)

  # approximate finite difference check
  eps <- 1e-4
  Theta_eps <- solve(Sigma0 + eps * DeltaSigma + lambda * diag(2))
  rho0 <- -Theta0[1,2] / sqrt(Theta0[1,1] * Theta0[2,2])
  rho_eps <- -Theta_eps[1,2] / sqrt(Theta_eps[1,1] * Theta_eps[2,2])
  expect_equal(rho_eps - rho0, eps * DeltaRho[1,2], tolerance = 1e-5)
})

test_that("chunked crossprod equals blas crossprod", {
  set.seed(6)
  Tn <- 70L; V <- 6L
  R <- matrix(rnorm(Tn * V), Tn, V)
  w <- rnorm(Tn)
  A <- .mppi_wcp(R, w)
  B <- .mppi_crossprod(R, w, backend = "chunked", chunk_size = 15L)
  expect_equal(A, B, tolerance = 1e-12)
})
</file>

<file path="tests/testthat/test_basis.R">
context("Basis handling and chunked ops")

test_that("as_mppi_basis orthonormalizes columns", {
  set.seed(1)
  V <- matrix(rnorm(30), nrow = 6, ncol = 5)
  B <- as_mppi_basis(V, name = "rand")
  XtX <- crossprod(B$V)
  expect_equal(diag(XtX), rep(1, ncol(XtX)), tolerance = 1e-8)
  expect_true(max(abs(XtX[upper.tri(XtX)])) < 1e-8)
  expect_equal(B$r, ncol(B$V))
})

test_that("mppi_edge matches reconstructed delta", {
  set.seed(2)
  Tn <- 40L; V <- 6L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  basis <- as_mppi_basis(diag(V), name = "id")
  fit <- mppi_fit(Y, X, psych_idx = 2L, basis = basis, backend = "blas")
  recon <- mppi_reconstruct_delta(fit, 1L)
  expect_equal(mppi_edge(fit, 1L, 2L, 5L), recon[2,5])
})

test_that("chunked projection matches blas projection", {
  set.seed(3)
  Tn <- 60L; V <- 7L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  basis <- as_mppi_basis(qr.Q(qr(matrix(rnorm(V * 4L), V, 4L))), name = "randPCA")
  fit_blas <- mppi_fit(Y, X, psych_idx = 2L, basis = basis,
                       backend = "blas", project_backend = "blas")
  fit_chunk <- mppi_fit(Y, X, psych_idx = 2L, basis = basis,
                        backend = "chunked", chunk_size = 16L,
                        project_backend = "chunked", project_chunk_cols = 3L)
  expect_equal(mppi_get_M(fit_chunk, 1L), mppi_get_M(fit_blas, 1L), tolerance = 1e-8)
})

test_that("neural domain matches direct conversion", {
  set.seed(7)
  Tn <- 60L; V <- 8L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  runs <- rep(1:3, each = 20)
  basis <- as_mppi_basis(diag(V), name = "id")
  h <- mppi_default_hrf(tr = 1)
  fit_neural <- mppi_fit(Y, X, psych_idx = 2L, runs = runs,
                         basis = basis, domain = "neural",
                         deconv = list(K = 32))
  fit_bold <- mppi_fit(Y, X, psych_idx = 2L, runs = runs,
                        basis = basis, domain = "bold")
  conv <- mppi_neural_from_fit(fit_bold, X, psych_idx = 2L, h = h, K = 32)
  expect_equal(mppi_get_M(fit_neural, 1L), mppi_get_M(conv, 1L), tolerance = 1e-6)
  expect_equal(fit_neural$deconv$hrf, h)
})

test_that("permutation seed is reproducible", {
  set.seed(4)
  Tn <- 45L; V <- 5L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  fit <- mppi_fit(Y, X, psych_idx = 2L)
  res1 <- mppi_omnibus(fit, blksize = 5L, B = 49L, seed = 123)
  res2 <- mppi_omnibus(fit, blksize = 5L, B = 49L, seed = 123)
  expect_equal(res1[[1]]$Qnull, res2[[1]]$Qnull)
  pm1 <- mppi_permute(fit, k = 1L, blksize = 5L, B = 49L, seed = 321)
  pm2 <- mppi_permute(fit, k = 1L, blksize = 5L, B = 49L, seed = 321)
  expect_equal(pm1, pm2)
})

test_that("freedman-lane permutation returns valid matrix", {
  set.seed(5)
  Tn <- 30L; V <- 4L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  fit <- mppi_fit(Y, X, psych_idx = 2L)
  pmat <- mppi_permute(fit, k = 1L, blksize = 5L, B = 29L,
                       method = "freedman_lane", seed = 77,
                       studentize = FALSE)
  expect_equal(dim(pmat), c(V, V))
  expect_true(all(is.na(diag(pmat))))
})
</file>

<file path="tests/testthat/test_beta_lag.R">
test_that("mppi_fit_beta exposes residual regressors and permutation works", {
  set.seed(123)
  ntr <- 40L; V <- 6L
  B <- matrix(rnorm(ntr * V), ntr, V)
  Pbeta <- cbind(cond = sample(c(0, 1), ntr, replace = TRUE),
                 mod  = as.numeric(scale(rnorm(ntr), center = TRUE, scale = FALSE)))
  colnames(Pbeta) <- c("cond", "mod")

  fit <- mppi_fit_beta(B, Pbeta, zero_diag = TRUE, scale = "cov")
  expect_equal(sort(names(fit$pk)), sort(colnames(Pbeta)))
  expect_true(all(vapply(fit$pk, length, integer(1)) == ntr))
  expect_true(all(vapply(fit$meta, function(x) all(c("Q", "qr", "raw", "is_binary") %in% names(x)), logical(1))))

  perms <- mppi_beta_permute(B, Pbeta, Bperm = 20L, blksize = 10L, zero_diag = TRUE)
  expect_named(perms, colnames(Pbeta))
  expect_true(all(vapply(perms, function(x) length(x$Qnull), integer(1)) == 20L))
  expect_true(all(vapply(perms, function(x) is.matrix(x$D) && nrow(x$D) == V, logical(1))))
  expect_true(all(vapply(perms, function(x) is.na(x$p_global) || (x$p_global >= 0 && x$p_global <= 1), logical(1))))
})

test_that("packed beta output can be unpacked", {
  set.seed(456)
  ntr <- 25L; V <- 4L
  B <- matrix(rnorm(ntr * V), ntr, V)
  Pbeta <- cbind(cond = sample(c(0, 1), ntr, replace = TRUE))
  fit <- mppi_fit_beta(B, Pbeta, packed = TRUE)
  expect_true(fit$packed)
  packed <- fit$Delta[[1]]
  full <- multiPPI:::`.mppi_unpack_upper`(packed)
  fit_full <- mppi_fit_beta(B, Pbeta, packed = FALSE)
  expect_equal(full, fit_full$Delta[[1]], tolerance = 1e-10)
})

test_that("mppi_lag_select handles multiple targets and per-target output", {
  set.seed(321)
  Tn <- 60L; V <- 5L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  p1 <- sin(seq_len(Tn) / 5)
  p2 <- cos(seq_len(Tn) / 7)
  X <- cbind(Intercept = 1, p1 = p1, p2 = p2)

  res_multi <- mppi_lag_select(Y, X, psych_idx = 2:3, lags = -1:1,
                                blocklens = c(30, 30), B = 20L, blksize = NULL,
                                targets = c("p1", "p2"))
  expect_named(res_multi, c("p1", "p2"))
  expect_true(all(vapply(res_multi, function(x) length(x$Qobs), integer(1)) == length(-1:1)))
  expect_true(all(vapply(res_multi, function(x) is.na(x$best_lag) || x$best_lag %in% -1:1, logical(1))))

  res_single <- mppi_lag_select(Y, X, psych_idx = 2:3, lags = -1:1,
                                 blocklens = c(30, 30), B = 10L, blksize = NULL,
                                 targets = "p1")
  expect_true(is.list(res_single))
  expect_true(all(c("best_lag", "Q", "Qnull", "p", "Qobs", "Dbest") %in% names(res_single)))
  expect_equal(length(res_single$Qnull), 10L)
})
</file>

<file path="tests/testthat/test_core.R">
context("Core mPPI shapes")

test_that("mppi_fit returns matrices of correct size", {
  set.seed(1)
  Tn <- 100; V <- 10
  Y <- matrix(rnorm(Tn*V), Tn, V)
  p <- rnorm(Tn)
  X <- cbind(1, p)
  fit <- mppi_fit(Y, X, psych_idx = 2L)
  expect_equal(length(fit$Delta), 1L)
  expect_equal(dim(fit$Delta[[1]]), c(V, V))
})
</file>

<file path="tests/testthat/test_design_interface.R">
context("Design interface generics")

skip_if_not_installed("fmridesign")

test_that("fmridesign helpers produce coherent bundles", {
  suppressPackageStartupMessages(library(fmridesign))
  set.seed(11)
  Tn <- 24L
  sf <- sampling_frame(blocklens = Tn, TR = 2)
  events <- data.frame(
    onset = c(seq(0, by = 4, length.out = Tn/4),
              seq(2, by = 4, length.out = Tn/4)),
    cond = factor(rep(c("taskA", "taskB"), each = Tn/4)),
    run = 1
  )
  events <- events[order(events$run, events$onset), ]
  emod <- event_model(onset ~ hrf(cond), data = events,
                      block = ~ run, sampling_frame = sf)
  runs_vec <- rep(1L, Tn)
  design <- mppi_model(emod, runs = runs_vec, include_intercept = FALSE)
  runs_vec <- design$runs
  S <- mppi_psych(design, T = Tn, TR = 2)
  X_task <- mppi_task(design)

  expect_equal(mppi_tr(emod), 2)
  expect_equal(mppi_runs(emod, T = Tn), runs_vec)
  expect_equal(mppi_psych(design, T = Tn, TR = 2), S)
  expect_equal(mppi_nuisance(design, T = Tn), matrix(0, Tn, 0))
  expect_true(is.function(mppi_hrf(design)))

})

test_that("mppi() handles fmridesign and fmri_dataset inputs", {
  skip_if_not_installed("fmridataset")
  suppressPackageStartupMessages(library(fmridesign))
  set.seed(22)
  Tn <- 24L
  V <- 4L
  sf <- sampling_frame(blocklens = Tn, TR = 1.5)
  events <- data.frame(
    onset = c(seq(0, by = 4, length.out = Tn/4),
              seq(2, by = 4, length.out = Tn/4)),
    cond = factor(rep(c("taskA", "taskB"), each = Tn/4)),
    run = 1
  )
  events <- events[order(events$run, events$onset), ]
  emod <- event_model(onset ~ hrf(cond), data = events,
                      block = ~ run, sampling_frame = sf)
  runs_vec <- rep(1L, Tn)
  design <- mppi_model(emod, runs = runs_vec, include_intercept = FALSE)
  runs_vec <- design$runs
  X_task <- mppi_task(design)
  Y <- matrix(rnorm(Tn * V), Tn, V)

  manual <- mppi_fit(Y = Y, X = X_task, psych_idx = 1:2, runs = runs_vec)
  via_design <- mppi(design, Y = Y, domain = "bold")

  expect_equal(via_design$Delta, manual$Delta)
  expect_equal(via_design$pk, manual$pk)

  ds <- fmridataset::matrix_dataset(datamat = Y, TR = 1.5, run_length = c(Tn))
  via_ds <- mppi(ds, design, domain = "bold", basis = "roi")

  expect_equal(via_ds$Delta, manual$Delta)
  expect_equal(via_ds$pk, manual$pk)

  via_ds_pca <- mppi(ds, design, domain = "bold")
  expect_true(!is.null(via_ds_pca$basis))
  expect_equal(nrow(via_ds_pca$basis$V), ncol(Y))
})
</file>

<file path="tests/testthat/test_gap_fill.R">
test_that("mppi_select_psych handles names, patterns, and errors", {
  set.seed(1L)
  X <- cbind(`(Intercept)` = 1,
             taskA = rnorm(12),
             taskB = rnorm(12),
             confound = rnorm(12))
  expect_equal(mppi_select_psych(X, names_or_idx = "taskA"), 2L)
  expect_equal(mppi_select_psych(X, names_or_idx = c(3L, 2L)), c(3L, 2L))
  expect_equal(sort(mppi_select_psych(X, patterns = "^task")), 2:3)
  expect_error(mppi_select_psych(X), "Provide either names_or_idx or patterns")
  expect_error(mppi_select_psych(X, patterns = "^missing"), "No design columns matched")
})

test_that("mppi_coerce_beta coerces frame and list inputs", {
  mat <- matrix(1:6, nrow = 3, byrow = TRUE)
  expect_identical(mppi_coerce_beta(mat), mat)

  df <- data.frame(trial = c(2, 1, 2, 1, 2, 1),
                   roi = rep(letters[1:3], each = 2),
                   beta = 1:6)
  coerced_df <- mppi_coerce_beta(df)
  expect_equal(dim(coerced_df), c(2, 3))
  expected_trial1 <- stats::setNames(df$beta[df$trial == 1], df$roi[df$trial == 1])
  expect_equal(coerced_df[1, ], expected_trial1[sort(names(expected_trial1))])

  lst <- list(c(1, 2, 3), c(4, 5, 6))
  coerced_list <- mppi_coerce_beta(lst)
  expect_equal(coerced_list, rbind(lst[[1]], lst[[2]]))

  bad_list <- list(1:3, 1:2)
  expect_error(mppi_coerce_beta(bad_list), "same length")
})

test_that("mppi_compare_models returns delta gaps and AIC differences", {
  fit_bold <- list(names = c("c1", "c2"),
                   Delta = list(matrix(c(1, 0, 0, 1), 2),
                                matrix(c(0, 1, 1, 2), 2)))
  fit_neural <- list(names = c("c1", "c2"),
                     Delta = list(matrix(c(0.5, 0, 0, 0.5), 2),
                                  matrix(c(0.5, 0.5, 0.5, 0.5), 2)))
  class(fit_bold) <- class(fit_neural) <- c("mppi_fit", "list")

  resid_bold <- matrix(c(1, 2, 3,
                         4, 5, 6), nrow = 3, byrow = TRUE)
  resid_neural <- resid_bold * 0.5
  pk <- list(c(1, 0, 1), c(0, 1, 1))

  res <- mppi_compare_models(fit_bold, fit_neural,
                             resid_bold = resid_bold,
                             resid_neural = resid_neural,
                             pk = pk)
  expect_equal(res$names, c("c1", "c2"))
  expect_equal(res$delta_gap, c(sqrt(0.5), 3), tolerance = 1e-7)
  expect_true(all(res$AIC_diff > 0))
})

test_that("mppi_hrf_ensemble blends fits with data-driven or manual weights", {
  fit1 <- list(names = "c1",
               Delta = list(matrix(c(1, 0, 0, 1), 2)),
               AIC_total = c(10),
               packed = FALSE)
  fit2 <- list(names = "c1",
               Delta = list(matrix(c(3, 0, 0, 3), 2)),
               AIC_total = c(12),
               packed = FALSE)
  class(fit1) <- class(fit2) <- c("mppi_fit", "list")

  ens_auto <- mppi_hrf_ensemble(list(fit1 = fit1, fit2 = fit2))
  weights_auto <- ens_auto$ensemble$weights
  expect_equal(sum(weights_auto), 1)
  expected_auto <- weights_auto[["fit1"]] * fit1$Delta[[1]] +
    weights_auto[["fit2"]] * fit2$Delta[[1]]
  expect_equal(ens_auto$Delta[[1]], expected_auto, tolerance = 1e-7)
  expect_equal(ens_auto$ensemble$method, "aic")

  ens_manual <- mppi_hrf_ensemble(list(fit1 = fit1, fit2 = fit2), weights = c(0.2, 0.8))
  expected_manual <- 0.2 * fit1$Delta[[1]] + 0.8 * fit2$Delta[[1]]
  expect_equal(ens_manual$Delta[[1]], expected_manual)
  expect_equal(ens_manual$ensemble$weights, c(fit1 = 0.2, fit2 = 0.8))
})

test_that("mppi_sim_rest_neural generates standardized modulators and templates", {
  sim <- mppi_sim_rest_neural(T = 60, r = 4,
                              contexts = c("ctxA", "ctxB"),
                              amp = c(0.2, 0.3),
                              freq = c(0.05, 0.08),
                              seed = 123)
  expect_equal(dim(sim$U), c(60, 4))
  expect_named(sim$modulators, c("ctxA", "ctxB"))
  mod_mat <- do.call(cbind, sim$modulators)
  expect_true(all(abs(colMeans(mod_mat)) < 1e-12))
  expect_true(all(abs(apply(mod_mat, 2, sd) - 1) < 1e-6))
  coupling_norms <- vapply(sim$coupling, function(M) sqrt(sum(M^2)), numeric(1))
  expect_true(all(abs(coupling_norms - 1) < 1e-8))
})
</file>

<file path="tests/testthat/test_group_glm.R">
context("Group-level wrappers")

set.seed(123)

build_fit <- function(seed_shift = 0) {
  set.seed(100 + seed_shift)
  Tn <- 16L; V <- 4L
  X <- cbind(1, seq_len(Tn))
  Y <- matrix(rnorm(Tn * V), Tn, V)
  mppi_fit(Y = Y, X = X, psych_idx = 2, lags = -1:1)
}

fits <- lapply(0:2, build_fit)
names(fits) <- paste0("subj", seq_along(fits))

stack_obj <- mppi_stack(fits, k = 1, lag = 0)

test_that("mppi_stack produces a complete edge matrix", {
  expect_equal(nrow(stack_obj$matrix), length(fits))
  expect_equal(ncol(stack_obj$matrix), choose(4, 2))
  expect_true(all(is.finite(stack_obj$matrix)))
})

glm_design <- cbind(Intercept = 1, group = c(-1, 0, 1))

res_glm <- mppi_group_glm(stack_obj, design = glm_design, method = "lm")

test_that("mppi_group_glm runs OLS without limma", {
  expect_equal(nrow(res_glm), ncol(stack_obj$matrix))
  expect_true(all(is.finite(res_glm$estimate)))
  expect_true(all(!is.na(res_glm$q)))
})

test_that("lagged accessors work", {
  M0 <- mppi_get_M(fits[[1]], 1)
  M1 <- mppi_get_M_lag(fits[[1]], 1, lag = 1)
  Mneg <- mppi_get_M_lag(fits[[1]], 1, lag = -1)
  expect_equal(dim(M0), dim(M1))
  expect_equal(dim(M0), dim(Mneg))
  expect_true(is.matrix(M1))
  expect_true(is.matrix(Mneg))
})
</file>

<file path="tests/testthat/test_group.R">
context("Group-level utilities")

test_that("mppi_group_ebayes detects signal", {
  set.seed(200)
  r <- 4L
  n_subj <- 6L
  # create small symmetric matrices with a common signal on edge (1,2)
  M_list <- vector("list", n_subj)
  for (s in seq_len(n_subj)) {
    base <- matrix(rnorm(r * r, sd = 0.1), r, r)
    base <- (base + t(base)) / 2
    base[1,2] <- base[2,1] <- base[1,2] + 0.5
    M_list[[s]] <- base
  }
  res <- mppi_group_ebayes(M_list, use_limma = FALSE)
  idx_mat <- matrix(FALSE, res$V, res$V)
  idx_mat[upper.tri(idx_mat)] <- res$p < 0.1
  expect_true(idx_mat[1,2])
})
</file>

<file path="tests/testthat/test_helpers.R">
library(testthat)

skip_if_not_installed("fmridesign")

suppressPackageStartupMessages(library(fmridesign))

set.seed(42)

Tn <- 60L
sf <- sampling_frame(blocklens = Tn, TR = 1)
enc_onsets <- seq(5, 45, by = 10)
rec_onsets <- seq(10, 50, by = 10)
trial_tbl <- data.frame(
  onset = c(enc_onsets, enc_onsets + 2, rec_onsets, rec_onsets + 2),
  cond = factor(c(rep("enc_vid01", length(enc_onsets)),
                  rep("enc_vid02", length(enc_onsets)),
                  rep("rec_vid01", length(rec_onsets)),
                  rep("rec_vid02", length(rec_onsets)))),
  run = 1
)
trial_tbl <- trial_tbl[order(trial_tbl$onset), ]
cond_names <- levels(trial_tbl$cond)
emod <- event_model(onset ~ hrf(cond), data = trial_tbl,
                    block = ~ run, sampling_frame = sf)
design <- mppi_model(emod, runs = rep(1L, Tn), include_intercept = FALSE)
runs <- design$runs
S_mat <- mppi_psych(design, T = Tn, TR = 1)

X <- cbind(`(Intercept)` = 1, S_mat)
Y <- matrix(rnorm(Tn * 8, sd = 0.5), Tn, 8)
fit_obj <- mppi_fit(Y, X, psych_idx = 2:5, runs = runs)


test_that("mppi_parametric produces gPPI-style modulators", {
  mods <- list(vivid = seq_len(Tn) / Tn)
  pk_mod <- mppi_parametric(design, T = Tn, mods = mods, select = "^cond_cond.rec")
  expect_named(pk_mod, c("cond_cond.rec_vid01::vivid", "cond_cond.rec_vid02::vivid"))
  expect_equal(length(pk_mod), 2L)
  expect_equal(length(pk_mod[[1]]), Tn)
  expect_true(all(abs(colMeans(do.call(cbind, pk_mod))) < 1e-6))
})


test_that("mppi_reinstatement returns within/between similarities", {
  rein <- mppi_reinstatement(fit_obj,
                             enc_pattern = "^cond_cond.enc_vid",
                             rec_pattern = "^cond_cond.rec_vid[0-9]{2}$",
                             mode = "raw")
  expect_length(rein$within, 2L)
  expect_length(rein$between, 1L)
  expect_true(is.finite(rein$stat))
})


test_that("mppi_sdppi yields per-trial summaries", {
  sd_df <- mppi_sdppi(fit_obj, design, select = "^cond_cond.rec",
                      pre_window = 3L, lags = -1:1, mode = "raw")
  expect_s3_class(sd_df, "data.frame")
  expect_gt(nrow(sd_df), 0L)
  expect_true(all(c("condition", "trial", "onset", "magnitude", "gain", "routing") %in% names(sd_df)))
})


test_that("mppi_precision_gate returns per-condition deltas", {
  gate <- mppi_precision_gate(fit_obj, mode = "raw", ridge = 1e-4)
  expect_equal(length(gate$Delta), length(cond_names))
  expect_s3_class(gate$summary, "data.frame")
  expect_true(all(c("condition", "dtheta_energy", "offdiag_ratio") %in% names(gate$summary)))
})
</file>

<file path="tests/testthat/test_hrf.R">
context("HRF grouping and adaptive blending")

test_that("HRF grouping matches expected names", {
  skip_if_not_installed("fmridesign")
  library(fmridesign)
  sframe <- sampling_frame(blocklens = 20, TR = 1)
  ev <- event_model(onset ~ hrf(cond) + hrfTD(cond),
                    data = data.frame(onset = c(0,5,10,15), cond = factor(c("A","A","B","B"))),
                    block = ~1, sampling_frame = sframe)
  D <- as_mppi_design(ev)
  groups <- mppi_group_hrf_columns(D)
  expect_true("cond" %in% names(groups))
  expect_equal(length(groups[["cond"]]), 2L)
})

test_that("HRF adaptive weights recover dominant basis", {
  skip_if_not_installed("fmridesign")
  library(fmridesign)
  V <- 4L
  Delta1 <- matrix(0, V, V); Delta1[1,2] <- Delta1[2,1] <- 3
  Delta2 <- matrix(0, V, V); Delta2[3,4] <- Delta2[4,3] <- 0.5
  deltas <- list(Delta1, Delta2)
  combo <- mppi_hrf_adapt(deltas, pk_norms = c(1, 1))
  expect_equal(which.max(abs(combo$weights)), 1L)
})
</file>

<file path="tests/testthat/test_mechanistic.R">
context("Mechanistic helpers")

mock_fit <- function(pk_vals) {
  R <- diag(length(pk_vals))
  denom <- sum(pk_vals^2)
  Delta <- if (denom < .Machine$double.eps) matrix(0, length(pk_vals), length(pk_vals))
           else crossprod(R, pk_vals * R) / denom
  structure(list(Delta = list(Delta), names = "task", pk = list(pk_vals),
                 R = R, basis = NULL), class = c("mppi_fit", "list"))
}

test_that("mppi_gain matches manual precision update", {
  set.seed(1)
  Tn <- 32L; V <- 3L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind("(Intercept)" = 1, task = rnorm(Tn))
  fit <- mppi_fit(Y, X, psych_idx = 2L, zero_diag = FALSE, scale = "cov")
  pk <- fit$pk[[1]]
  R <- fit$R
  S0 <- crossprod(R) / nrow(R)
  Mk <- crossprod(R, pk * R) / sum(pk^2)
  Theta0 <- solve(S0 + diag(1e-3, ncol(S0)))
  dTheta <- - Theta0 %*% Mk %*% Theta0
  gain <- mppi_gain(fit, 1L, lambda = 1e-3)
  expect_equal(gain$gain, diag(dTheta), tolerance = 1e-8)
})

test_that("mppi_routing_index detects feedforward bias", {
  fit_pos <- mock_fit(c(2, 0))
  fit_neg <- mock_fit(c(0, 2))
  routing <- mppi_routing_index(list("1" = fit_pos, "-1" = fit_neg),
                                hierarchy = c(1, 2))
  expect_equal(routing$routing, (0.5 - 2) / (0.5 + 2), tolerance = 1e-8)
  expect_true(routing$energy_neg > routing$energy_pos)
})

test_that("mppi_project_templates returns normalized weights", {
  fit <- mock_fit(c(2, 0))
  templates <- list(diag = diag(2), off = matrix(c(0, 1, 1, 0), 2, 2))
  w <- mppi_project_templates(fit, templates = templates)
  expect_equal(names(w), names(templates))
  expect_equal(w[["diag"]], (0.5) / sqrt(2), tolerance = 1e-8)
  expect_equal(w[["off"]], 0, tolerance = 1e-12)
})

test_that("template helpers build orthogonal patterns", {
  labs <- c("A", "A", "B")
  tmp <- mppi_templates_within_between(labs)
  expect_equal(dim(tmp$within), c(3L, 3L))
  expect_true(all(diag(tmp$within) == 0))
  grad <- mppi_templates_gradient(c(1, 2, 3))
  expect_equal(dim(grad$dir), c(3L, 3L))
  expect_true(abs(sum(grad$dir * grad$ortho)) < 1e-8)
})

test_that("mechanism report bundles gain, routing, templates", {
  fit <- mock_fit(c(2, 0))
  lag_fits <- list("1" = fit, "-1" = mock_fit(c(0, 2)))
  templates <- list(diag = diag(2))
  rep <- mppi_mechanism_report(fit, hierarchy = c(1, 2), lag_fits = lag_fits,
                               templates = templates)
  expect_true(is.list(rep$gain))
  expect_true(is.list(rep$routing))
  expect_true(is.numeric(rep$templates))
})
</file>

<file path="tests/testthat/test_neural.R">
context("Neural-domain defaults and grouping")

test_that("neural fit works with default HRF", {
  set.seed(101)
  Tn <- 48L; V <- 6L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind("(Intercept)" = 1, conf = rnorm(Tn), task = rnorm(Tn))
  fit <- mppi_fit(Y, X, psych_idx = 3L, domain = "neural")
  expect_equal(fit$domain, "neural")
  expect_equal(length(fit$names), 1L)
  expect_type(fit$deconv$sticks, "double")
  expect_equal(ncol(fit$deconv$sticks), 1L)
  expect_equal(fit$deconv$hrf, mppi_default_hrf())
  expect_equal(length(fit$pk), 1L)
  expect_false(any(is.na(fit$Delta[[1]])))
})

test_that("neural fit groups HRF basis columns", {
  set.seed(102)
  Tn <- 64L; V <- 5L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind("(Intercept)" = 1,
             nuisance = rnorm(Tn),
             hrf_A = rnorm(Tn),
             hrfTD_A = rnorm(Tn),
             hrf_B = rnorm(Tn),
             hrfTD_B = rnorm(Tn))
  fit <- mppi_fit(Y, X, psych_idx = 3:6, domain = "neural")
  expect_equal(length(fit$names), 2L)
  expect_true(all(grepl("^s:", fit$names)))
  expect_equal(ncol(fit$deconv$sticks), 2L)
  expect_equal(length(fit$pk), 2L)
  expect_false(anyNA(unlist(fit$Delta)))
})

test_that("neural fit supports MAP deconvolution backend", {
  set.seed(103)
  Tn <- 40L; V <- 4L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind("(Intercept)" = 1,
             conf = rnorm(Tn),
             taskA = rnorm(Tn),
             taskB = rnorm(Tn))
  fit_map <- mppi_fit(Y, X, psych_idx = 3:4, domain = "neural",
                      deconv = list(type = "map", lambda = 8, TR = 1))
  expect_equal(fit_map$deconv$type, "map")
  expect_equal(ncol(fit_map$deconv$sticks), length(fit_map$names))
  expect_true(all(vapply(fit_map$pk, function(v) length(v) == Tn, logical(1))))
  expect_false(any(is.na(fit_map$Delta[[1]])))
})
</file>

<file path="tests/testthat/test_permutation.R">
test_that("mppi_omnibus exposes RNG metadata", {
  set.seed(999)
  Tn <- 40L; V <- 3L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  fit <- mppi_fit(Y, X, psych_idx = 2L)
  res <- mppi_omnibus(fit, blksize = 5L, B = 19L, seed = 123)
  meta <- attr(res, "rng")
  expect_type(meta, "list")
  expect_equal(meta$seed_arg, 123)
  expect_true(length(meta$kind) >= 2)
})

test_that("mppi_permute phase method returns metadata", {
  set.seed(2025)
  Tn <- 30L; V <- 3L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = sin(seq_len(Tn)/4))
  fit <- mppi_fit(Y, X, psych_idx = 2L, runs = rep(1:3, each = 10))
  pm <- mppi_permute(fit, k = 1L, blksize = 5L, B = 11L, method = "phase", seed = 321)
  meta <- attr(pm, "rng")
  expect_type(meta, "list")
  expect_equal(meta$method, "phase")
})

test_that("freedman-lane omnibus runs and returns metadata", {
  set.seed(1234)
  Tn <- 24L; V <- 3L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  fit <- mppi_fit(Y, X, psych_idx = 2L)
  res <- mppi_omnibus(fit, blksize = 4L, B = 19L, method = "freedman_lane", seed = 42)
  meta <- attr(res, "rng")
  expect_equal(meta$method, "freedman_lane")
  expect_equal(length(res[[1]]$Qnull), 19L)
})

test_that("freedman-lane edgewise permutation yields matrix", {
  set.seed(567)
  Tn <- 20L; V <- 3L
  Y <- matrix(rnorm(Tn * V), Tn, V)
  X <- cbind(Intercept = 1, task = rnorm(Tn))
  fit <- mppi_fit(Y, X, psych_idx = 2L)
  pm <- mppi_permute(fit, k = 1L, blksize = 4L, B = 9L, method = "freedman_lane", seed = 99,
                     studentize = FALSE)
  expect_equal(dim(pm), c(V, V))
  expect_true(all(is.na(diag(pm))))
  meta <- attr(pm, "rng")
  expect_equal(meta$method, "freedman_lane")
})
</file>

<file path="tests/testthat/test_rest_misc.R">
test_that("mppi_rest_design returns normalized columns", {
  set.seed(11)
  Tn <- 200
  base <- sin(seq_len(Tn) / 10)
  pk <- list(
    ctx1 = base,
    ctx2 = base + rnorm(Tn, sd = 0.1)
  )
  design <- mppi_rest_design(pk, nuisance = matrix(rnorm(Tn), Tn, 1))
  Xc <- design$X[, design$psych_idx, drop = FALSE]
  expect_equal(ncol(Xc), length(pk))
  norms <- sqrt(colSums(Xc^2))
  expect_true(all(abs(norms - 1) < 1e-6))
  expect_true(all(design$X[, 1] == 1))
})

test_that("mppi_rest_trait_cv recovers linear trait relationship", {
  set.seed(12)
  subj <- 1:12
  trait <- scale(rnorm(length(subj)))[, 1]
  feats <- do.call(rbind, lapply(subj, function(s) {
    data.frame(
      condition = c("ctx1", "ctx2"),
      G = c(trait[s] + rnorm(1, sd = 0.01), rnorm(1, sd = 0.3)),
      R = rnorm(2, sd = 0.2),
      mag = rnorm(2, sd = 0.2),
      subj = s
    )
  }))
  cv <- mppi_rest_trait_cv(feats, y = setNames(trait, subj), k = 4)
  expect_true(is.list(cv))
  expect_gt(cv$cv_r2, 0.6)
  expect_equal(length(cv$pred), length(trait))
})

test_that("mppi_sim_rest_dataset respects custom templates", {
  set.seed(13)
  r <- 4
  template <- matrix(rnorm(r * r), r, r)
  template <- 0.5 * (template + t(template))
  sims <- mppi_sim_rest_dataset(T = 200, V = 20, r = r,
                                templates = list(template),
                                contexts = "ctx", amp = 0.5,
                                obs_noise = 0)
  truth_mat <- sims$truth$coupling[["ctx"]]
  fnorm <- sqrt(sum((0.5 * (template + t(template)))^2))
  expect_equal(truth_mat, (0.5 * (template + t(template))) / fnorm)
})

test_that("mppi_rest_modulators handles envelope groups", {
  set.seed(14)
  U <- matrix(rnorm(300), 100, 3)
  mods <- mppi_rest_modulators(U,
                               include = "envelopes",
                               envelopes = list(groups = list(a = 1:2, b = 3)))
  expect_named(mods, c("env_a", "env_b"))
  expect_equal(length(mods$env_a), nrow(U))
})

test_that("mppi_rest_extract handles matrices with attributes", {
  Y <- matrix(rnorm(100), 20, 5)
  attr(Y, "TR") <- 0.8
  attr(Y, "runs") <- rep(1:2, each = 10)
  info <- mppi_rest_extract(Y)
  expect_equal(info$TR, 0.8)
  expect_equal(nrow(info$Y), 20)
  expect_equal(info$runs, as.integer(rep(1:2, each = 10)))
})
</file>

<file path="tests/testthat/test_rest_sim.R">
test_that("simulated rest dataset yields recoverable coupling", {
  set.seed(42)
  sim <- mppi_sim_rest_dataset(T = 800, V = 50, r = 5,
                               amp = c(0.4, -0.35),
                               contexts = c("ctx1", "ctx2"),
                               obs_noise = 0.01)
  basis_mat <- sim[["loadings"]]
  mods <- sim[["modulators"]]
  fit <- mppi_rest(sim[["Y"]],
                   modulators = mods,
                   basis = basis_mat,
                   prewhiten = FALSE,
                   domain = "bold")
  # Ground truth from latent components (noise-free reference)
  fit_true <- mppi_rest(sim[["U"]],
                        modulators = mods,
                        basis = diag(ncol(sim[["U"]])),
                        prewhiten = FALSE,
                        domain = "bold")
  ctx_names <- names(mods)
  delta_est <- fit[["Delta"]]
  truth <- sim[["truth"]]
  for (nm in ctx_names) {
    est <- delta_est[[nm]]
    amp_val <- truth$amp[match(nm, names(truth$coupling))]
    ref <- truth$coupling[[nm]] * amp_val
    diag(ref) <- 0
    expect_equal(dim(est), dim(ref))
    cc <- stats::cor(as.vector(est), as.vector(ref), use = "pairwise.complete.obs")
    expect_gt(cc, 0.8)
  }
})

test_that("trait effect correlates with recovered gain", {
  skip_if_not_installed("fmriAR")
  set.seed(7)
  cohort <- mppi_sim_rest_cohort(n_subj = 8,
                                 contexts = c("ctx1", "ctx2"),
                                 amp_base = c(0.3, 0.2),
                                 trait_effect = c(0.5, 0),
                                 amp_noise = 0.01,
                                 obs_noise = 0.005,
                                 T = 800, V = 40, r = 5)
  datasets <- cohort[["datasets"]]
  fits <- lapply(datasets, function(ds) {
    mods <- ds[["modulators"]]
    basis_mat <- ds[["loadings"]]
    mppi_rest(ds[["Y"]],
              modulators = mods,
              basis = basis_mat,
              prewhiten = FALSE,
              domain = "bold")
  })
  feats <- mppi_rest_features(fits, aggregate = "none")
  ctx1_rows <- feats[feats$condition == "ctx1", ]
  trait <- cohort[["trait"]][ctx1_rows[["subj"]]]
  expect_gt(cor(ctx1_rows[["mag"]], trait), 0.8)
})

test_that("gain metric tracks template-directed coupling", {
  skip_if_not_installed("fmriAR")
  set.seed(2027)
  r <- 6
  v <- matrix(rnorm(r), r, 1)
  v <- v / sqrt(sum(v^2))
  gain_template <- v %*% t(v)
  null_template <- diag(r)
  templates <- list(gain = gain_template, control = null_template)
  cohort <- mppi_sim_rest_cohort(n_subj = 12,
                                 contexts = c("gain", "control"),
                                 amp_base = c(0.2, 0.2),
                                 trait_effect = c(0.6, 0),
                                 amp_noise = 0.005,
                                 obs_noise = 0.003,
                                 T = 900, V = 50, r = r,
                                 templates = templates)
  fits <- lapply(cohort$datasets, function(ds) {
    mppi_rest(ds[["Y"]],
              modulators = ds[["modulators"]],
              basis = ds[["loadings"]],
              prewhiten = FALSE,
              domain = "bold")
  })
  feats <- mppi_rest_features(fits, aggregate = "none")
  gain_rows <- feats[feats$condition == "gain", ]
  control_rows <- feats[feats$condition == "control", ]
  trait <- cohort$trait
  cor_gain <- cor(gain_rows$G, trait[gain_rows$subj])
  cor_control <- cor(control_rows$G, trait[control_rows$subj])
  expect_gt(cor_gain, 0.6)
  expect_gt(abs(cor_gain), abs(cor_control) + 0.2)
})
</file>

<file path="tests/testthat/test_rest.R">
test_that("mppi_rest_modulators produces aligned sticks", {
  set.seed(1)
  U <- matrix(rnorm(300), 100, 3)
  mods <- mppi_rest_modulators(U,
                               include = c("states", "bursts", "envelopes"),
                               states = list(K = 3L, method = "kmeans", soft = FALSE),
                               bursts = list(ar_order = 2L, thresholds = 0.9),
                               envelopes = list(transform = "power"))
  expect_gt(length(mods), 0)
  expect_true(all(vapply(mods, length, 1L) == nrow(U)))
  expect_true(all(vapply(mods, function(v) all(is.finite(v)), TRUE)))
})

test_that("mppi_rest returns an mppi_fit with attached modulators", {
  set.seed(2)
  Y <- matrix(rnorm(2000), 100, 20)
  fit <- mppi_rest(Y,
                   basis = list(type = "pca", r = 6L),
                   include = c("states", "bursts", "envelopes"),
                   prewhiten = FALSE,
                   modulator_domain = "bold",
                   domain = "bold")
  expect_s3_class(fit, "mppi_fit")
  pk <- attr(fit, "pk")
  expect_true(is.list(pk))
  expect_gt(length(pk), 0)
  expect_true(all(vapply(pk, length, 1L) == nrow(Y)))
})

test_that("mppi_rest_features aggregates by subject", {
  skip_if_not_installed("fmriAR")
  set.seed(3)
  Y <- matrix(rnorm(600), 100, 6)
  runs <- rep(1:2, each = 50)
  fits <- list(
    mppi_rest(Y, runs = runs, basis = list(type = "pca", r = 4),
              prewhiten = TRUE, include = c("states", "bursts"),
              modulator_domain = "bold", domain = "bold"),
    mppi_rest(Y, runs = runs, basis = list(type = "pca", r = 4),
              prewhiten = TRUE, include = c("states", "envelopes"),
              modulator_domain = "bold", domain = "bold")
  )
  feats <- mppi_rest_features(fits, aggregate = "mean")
  expect_equal(nrow(feats), length(fits))
  expect_true(all(c("G", "R", "mag") %in% colnames(feats)))
})
</file>

<file path="tests/testthat/test_scale_axes.R">
test_that("scaled interaction matrices are scale-invariant", {
  set.seed(101)
  Tn <- 60L
  V <- 4L
  X <- cbind(1, rnorm(Tn))
  colnames(X) <- c("(Intercept)", "task")
  Y <- matrix(rnorm(Tn * V), Tn, V)

  fit1 <- mppi_fit(Y, X, psych_idx = 2L, lags = c(-1L, 0L, 1L))
  fit2 <- mppi_fit(2 * Y, X, psych_idx = 2L, lags = c(-1L, 0L, 1L))

  M_norm1 <- mppi_get_M_scaled(fit1, 1L, mode = "normalized")
  M_norm2 <- mppi_get_M_scaled(fit2, 1L, mode = "normalized")
  expect_equal(M_norm1, M_norm2, tolerance = 1e-6)

  M_amp1 <- mppi_get_M_scaled(fit1, 1L, mode = "amplitude")
  M_amp2 <- mppi_get_M_scaled(fit2, 1L, mode = "amplitude")
  expect_equal(norm(M_amp2, type = "F") / norm(M_amp1, type = "F"), 2, tolerance = 1e-6)
})

test_that("gain and routing axes return bounded summaries", {
  set.seed(202)
  Tn <- 80L
  V <- 5L
  X <- cbind(1, rnorm(Tn), rnorm(Tn))
  colnames(X) <- c("(Intercept)", "cond1", "cond2")
  Y <- matrix(rnorm(Tn * V), Tn, V)

  fit <- mppi_fit(Y, X, psych_idx = 2:3, lags = -1:1)
  axes <- mppi_axes(fit, lags = -1:1)

  expect_equal(nrow(axes), length(fit$names))
  expect_true(all(!is.na(axes$gain)))
  expect_true(all(abs(axes$gain) <= 1 + 1e-8))
  expect_true(all(abs(axes$routing) <= 1 + 1e-8 | is.na(axes$routing)))
})

test_that("communication modes return projected matrices for fits", {
  set.seed(303)
  Tn <- 50L
  V <- 6L
  X <- cbind(1, rnorm(Tn))
  colnames(X) <- c("(Intercept)", "cond")
  Y <- matrix(rnorm(Tn * V), Tn, V)

  fit <- mppi_fit(Y, X, psych_idx = 2L)
  modes <- mppi_modes(fit, r = 3L)

  expect_equal(ncol(modes$vectors), 3L)
  expect_equal(length(modes$projected), length(fit$names))
  expect_true(all(vapply(modes$projected, function(M) nrow(M) == 3, logical(1))))
})
</file>

<file path="tests/testthat/test_sim_multippi.R">
context("Simulation diagnostics for multiPPI")

testthat::skip_if_not_installed("fmrihrf")

`%||%` <- function(a, b) if (!is.null(a)) a else b
zscore <- function(x) { sx <- sd(x); if (sx == 0) x*0 else (x - mean(x))/sx }

# Canonical HRF via fmrihrf (SPM-like double gamma)
h_spm <- function(TR = 2, L = 32) {
  t <- seq(0, L, by = TR)
  fmrihrf::hrf_spmg1(t)
}

conv_hrf <- function(x, h) {
  y <- stats::filter(x, filter = h, method = "convolution", sides = 1)
  y <- y[seq_along(x)]
  y[is.na(y)] <- 0
  y
}

lag_vec <- function(x, tau) {
  T <- length(x)
  if (tau > 0) c(rep(0, tau), x[1:(T - tau)])
  else if (tau < 0) c(x[(1 - tau):T], rep(0, -tau))
  else x
}

make_events <- function(T, K, n_events = rep(20L, K), seed = 1L) {
  set.seed(seed)
  if (length(n_events) == 1L) n_events <- rep(n_events, K)
  times <- seq(4, T - 4, length.out = sum(n_events))
  times <- sample(times)
  S <- matrix(0, T, K)
  idx <- 1
  for (k in seq_len(K)) {
    tk <- sort(round(times[idx:(idx + n_events[k] - 1)]))
    tk <- pmax(1, pmin(T, tk))
    S[tk, k] <- 1
    idx <- idx + n_events[k]
  }
  colnames(S) <- paste0("cond", seq_len(K))
  S
}

simulate_pair <- function(T = 300, TR = 2, S, gamma, baseline = 0, tau = 0,
                          seed_sd = 1, targ_sd = 1, drift_amp = 0, jitter_sd = 0) {
  K <- ncol(S)
  x1 <- zscore(as.numeric(arima.sim(n = T, list(ar = 0.3), sd = seed_sd)))
  if (jitter_sd > 0) {
    j <- stats::filter(rnorm(T, 0, jitter_sd), rep(1/3, 3), sides = 2)
    j[is.na(j)] <- 0
    x1j <- zscore(x1 + j)
  } else x1j <- x1
  seedd <- lag_vec(x1j, tau)
  g_t <- as.numeric(S %*% gamma)
  eps <- as.numeric(arima.sim(n = T, list(ar = 0.2), sd = targ_sd))
  slow <- if (drift_amp > 0) drift_amp * sin(2*pi*(1:T) / (T/3)) else 0
  x2 <- eps + slow + seedd * (baseline + g_t)
  x1 <- zscore(x1); x2 <- zscore(x2)
  h  <- h_spm(TR)
  y1 <- zscore(conv_hrf(x1, h) + rnorm(T, 0, 0.2))
  y2 <- zscore(conv_hrf(x2, h) + rnorm(T, 0, 0.2))
  list(U = cbind(x1, x2), Y = cbind(y1, y2), S = S, TR = TR)
}

Mk <- function(U, s) {
  den <- sum(s^2) + 1e-12
  crossprod(U, s * U) / den
}

assert_close <- function(x, target, tol, msg) {
  testthat::expect_true(all(is.finite(x)), info = paste(msg, "non-finite"))
  diff <- max(abs(x - target))
  testthat::expect_true(diff < tol, info = sprintf("%s | diff=%.3f target=%.3f tol=%.3f", msg, diff, target, tol))
}

context("Simulation diagnostics for neural vs BOLD PPI, gPPI, lagged routing, iPPI")

test_that("Neural vs BOLD PPI recovers stronger effect", {
  T  <- 240; TR <- 2
  S  <- make_events(T, K = 2, n_events = c(18, 18), seed = 13)
  gamma <- c(0.8, 0.0)
  sim <- simulate_pair(T, TR, S, gamma, baseline = 0, tau = 0, jitter_sd = 0.5)
  sA <- S[,1]; U <- sim$U; Y <- sim$Y
  M_neu <- Mk(U, sA); M_bld <- Mk(Y, sA)
  neu <- abs(M_neu[1,2]); bld <- abs(M_bld[1,2])
  testthat::expect_gt(neu, bld + 0.05)
})

test_that("No PPI vs PPI (two conditions)", {
  T <- 260; TR <- 2; S <- make_events(T, 2, n_events = c(20, 20), seed = 7)
  sim0 <- simulate_pair(T, TR, S, gamma = c(0,0), baseline = 0, tau = 0)
  M0A  <- Mk(sim0$U, S[,1])[1,2]; M0B <- Mk(sim0$U, S[,2])[1,2]
  sim1 <- simulate_pair(T, TR, S, gamma = c(1.2,0), baseline = 0, tau = 0, seed_sd = 0.5, targ_sd = 0.4)
  M1A <- Mk(sim1$U, S[,1])[1,2]; M1B <- Mk(sim1$U, S[,2])[1,2]
  testthat::expect_gt(abs(M1A), abs(M0A) + 0.15)
  testthat::expect_lt(abs(M1B), abs(M0B) + 0.05)
})

test_that("gPPI vs sPPI (three conditions)", {
  T <- 200; TR <- 2; S <- make_events(T, 3, n_events = c(15, 15, 15), seed = 11)
  gamma <- c(0.6, 0.3, 0.5)
  sim <- simulate_pair(T, TR, S, gamma = gamma, baseline = 0, tau = 0)
  U <- sim$U
  MA <- Mk(U, S[,1]); MB <- Mk(U, S[,2])
  gppi_est <- (MA - MB)[1,2]
  target   <- gamma[1] - gamma[2]
  assert_close(gppi_est, target, tol = 0.08, msg = "gPPI estimate of A-B")
  s_coll <- S[,1] - S[,2]
  sppi_est <- Mk(U, s_coll)[1,2]
  err_gppi <- abs(gppi_est - target)
  err_sppi <- abs(sppi_est - target)
  testthat::expect_gt(err_sppi, err_gppi)
})

test_that("Lagged routing energy distinguishes direction", {
  T <- 200
  set.seed(99)
  seed <- zscore(arima.sim(n = T, list(ar = 0.4), sd = 1))
  target_ff <- zscore(lag_vec(seed, 1) + rnorm(T, 0, 0.1))
  target_fb <- zscore(lag_vec(seed, -1) + rnorm(T, 0, 0.1))
  U_ff <- cbind(seed, target_ff)
  U_fb <- cbind(seed, target_fb)
  lag_energy <- function(U, lags = -2:2) {
    pos <- neg <- 0
    for (tau in lags) {
      if (tau == 0) next
      if (tau > 0) {
        idx <- seq_len(T - tau)
        M <- crossprod(U[idx, , drop = FALSE], U[idx + tau, , drop = FALSE]) / length(idx)
        pos <- pos + sqrt(sum(M^2))
      } else {
        idx <- seq_len(T + tau)
        M <- crossprod(U[idx - tau, , drop = FALSE], U[idx, , drop = FALSE]) / length(idx)
        neg <- neg + sqrt(sum(M^2))
      }
    }
    list(pos = pos, neg = neg)
  }
  e_ff <- lag_energy(U_ff)
  e_fb <- lag_energy(U_fb)
  testthat::expect_gt(e_ff$pos, e_fb$pos)
  testthat::expect_true(e_fb$neg + 0.05 >= e_ff$neg)
})

test_that("Innovations reduce slow-drift bias", {
  skip_if_not(exists("mppi_innovations"))
  T <- 220; TR <- 2; S <- make_events(T, 1, n_events = 20, seed = 33)
  gamma <- 0.5
  sim <- simulate_pair(T, TR, S, gamma = gamma, baseline = 0, tau = 0, drift_amp = 1.0)
  U <- sim$U; s <- S[,1]
  M_raw <- Mk(U, s)[1,2]
  U_i <- mppi_innovations(U, TR = TR, protect = "lowHz", f_cut = 0.03,
                          ar_order = "auto", p = 4)
  M_i <- Mk(U_i, s)[1,2]
  err_raw <- abs(M_raw - gamma)
  err_ipi <- abs(M_i   - gamma)
  testthat::expect_true(err_ipi <= err_raw + 0.01)
})
</file>

<file path="tests/testthat/test_utils_extra.R">
library(testthat)

test_that(".mppi_handle_na drops incomplete rows and still errors when requested", {
  Y <- matrix(seq_len(12), nrow = 4)
  X <- matrix(seq(2, 24, by = 2), nrow = 4)
  runs <- c(1L, 1L, 2L, 2L)
  Y[2, 1] <- NA_real_
  X[4, 2] <- NA_real_

  res <- multiPPI:::`.mppi_handle_na`(Y, X, runs = runs, na_action = "omit_tr")
  expect_equal(res$dropped, 2L)
  expect_equal(res$dropped_idx, c(2L, 4L))
  expect_equal(res$Y, Y[c(1L, 3L), ], ignore_attr = TRUE)
  expect_equal(res$X, X[c(1L, 3L), ], ignore_attr = TRUE)
  expect_equal(res$runs, runs[c(1L, 3L)])

  expect_error(
    multiPPI:::`.mppi_handle_na`(Y, X, runs = runs, na_action = "error"),
    "mPPI inputs contain NA values"
  )
})


test_that(".mppi_prepare_design_matrix adds intercepts only when needed", {
  X_no_int <- matrix(c(0, 1, 0, 1, 0, 1), nrow = 3, byrow = FALSE)
  colnames(X_no_int) <- c("taskA", "taskB")
  prep_no_int <- multiPPI:::`.mppi_prepare_design_matrix`(X_no_int, psych_idx = c(1L, 2L))
  expect_true(prep_no_int$intercept_added)
  expect_equal(colnames(prep_no_int$X)[1], "(Intercept)")
  expect_equal(prep_no_int$psych_idx, c(2L, 3L))

  X_with_int <- cbind(`(Intercept)` = 1, X_no_int)
  prep_with_int <- multiPPI:::`.mppi_prepare_design_matrix`(X_with_int, psych_idx = c(2L, 3L))
  expect_false(prep_with_int$intercept_added)
  expect_identical(prep_with_int$X, X_with_int)
  expect_equal(prep_with_int$psych_idx, c(2L, 3L))
})


test_that(".mppi_project_basis chunked path matches BLAS product", {
  set.seed(123)
  R <- matrix(rnorm(60), nrow = 10)
  V <- matrix(rnorm(12), nrow = 6)
  direct <- R %*% V
  chunked <- multiPPI:::`.mppi_project_basis`(R, V, backend = "chunked", chunk_cols = 3L)
  expect_equal(chunked, direct, tolerance = 1e-10)
})


test_that(".mppi_crossprod_lagged handles run-aware lags", {
  set.seed(99)
  R <- matrix(rnorm(40), nrow = 8)
  pk <- runif(8)
  blocklens <- c(5L, 3L)

  pos_res <- multiPPI:::`.mppi_crossprod_lagged`(R, pk, lag = 1L, blocklens = blocklens)
  start <- 1L
  accum <- matrix(0, ncol(R), ncol(R))
  denom <- 0
  for (L in blocklens) {
    if (L > 1L) {
      rng <- seq.int(start, start + L - 1L - 1L)
      R0 <- R[rng, , drop = FALSE]
      R1 <- R[rng + 1L, , drop = FALSE]
      wk <- pk[rng]
      accum <- accum + crossprod(R0, wk * R1)
      denom <- denom + sum(wk^2)
    }
    start <- start + L
  }
  expect_equal(pos_res, accum / denom, tolerance = 1e-10)

  neg_res <- multiPPI:::`.mppi_crossprod_lagged`(R, pk, lag = -1L, blocklens = blocklens)
  start <- 1L
  accum <- matrix(0, ncol(R), ncol(R))
  denom <- 0
  for (L in blocklens) {
    shift <- 1L
    if (L > shift) {
      rng <- seq.int(start + shift, start + L - 1L)
      R0 <- R[rng, , drop = FALSE]
      R1 <- R[rng - shift, , drop = FALSE]
      wk <- pk[rng - shift]
      accum <- accum + crossprod(R0, wk * R1)
      denom <- denom + sum(wk^2)
    }
    start <- start + L
  }
  expect_equal(neg_res, accum / denom, tolerance = 1e-10)
})


test_that("mppi_fuse_time_beta returns precision-weighted average", {
  D_time <- matrix(c(2, 1, 1, 3), nrow = 2)
  D_beta <- matrix(c(4, 0, 0, 2), nrow = 2)
  fused <- mppi_fuse_time_beta(D_time, D_beta, var_time = 0.5, var_beta = 2)
  w_time <- 1 / 0.5
  w_beta <- 1 / 2
  expected <- (w_time * D_time + w_beta * D_beta) / (w_time + w_beta)
  expect_equal(fused, expected)
})
</file>

<file path="DESCRIPTION">
Package: multiPPI
Type: Package
Title: Seedless Task-Modulated Connectivity (Matrix-PPI) for fMRI
Version: 0.1.0
Authors@R: 
    c(person(given="Johnny", family="", role=c("aut","cre"), email="johnny@example.org"))
Description: Closed-form, seedless psychophysiological interactions (Matrix-PPI)
    with fast per-regressor slope matrices, lagged/directed variants, HRF-adaptive
    weights, permutation inference, partial connectivity updates, and bridges to
    fmrireg/fmriAR/fmrilss design-building and trial-level fits.
License: MIT + file LICENSE
Encoding: UTF-8
Depends: R (>= 4.1)
Imports:
    stats,
    methods,
    matrixStats,
    Rcpp,
    RcppArmadillo
LinkingTo:
    Rcpp,
    RcppArmadillo
Suggests:
    fmrireg,
    fmriAR,
    fmrihrf,
    fmrilss,
    signal,
    igraph,
    limma,
    knitr,
    rmarkdown
Roxygen: list(markdown = TRUE)
RoxygenNote: 7.3.2.9000
</file>

</files>
